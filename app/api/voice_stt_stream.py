"""
ë‹¨ì¼ ì–¸ì–´ STT ì „ìš© WebSocket API (ë²ˆì—­ ì—†ìŒ, ê³ ì„±ëŠ¥)

ì—”ë“œí¬ì¸íŠ¸:
- WS /api/ai/voice/stt-stream: ë‹¨ì¼ ì–¸ì–´ ì‹¤ì‹œê°„ ìŒì„± ì¸ì‹

ìš©ë„:
- ì‹¤ë¬´ ì‹œë‚˜ë¦¬ì˜¤ íšŒí™”ì—°ìŠµ í˜ì´ì§€
- Speaking Tutor Learning Mode
- ë²ˆì—­ì´ í•„ìš” ì—†ëŠ” ìˆœìˆ˜ STT ì‘ì—…

ì°¨ì´ì  (/api/ai/voice/realtime ëŒ€ë¹„):
- ìë™ ì–¸ì–´ ê°ì§€ ì—†ìŒ (ë‹¨ì¼ ì–¸ì–´ë§Œ ì¸ì‹)
- ë²ˆì—­ ì—†ìŒ (STT ê²°ê³¼ë§Œ ë°˜í™˜)
- ë” ë¹ ë¥¸ ì‘ë‹µ ì†ë„
"""
from fastapi import APIRouter, WebSocket, WebSocketDisconnect
from typing import Dict, Optional
import json
import uuid
import logging
import time
import asyncio

from agent.stt_translation.stt_agent import STTAgent
import azure.cognitiveservices.speech as speechsdk

# ë¡œê±° ì„¤ì •
logger = logging.getLogger(__name__)

# ë¼ìš°í„° ìƒì„±
router = APIRouter()

# í™œì„± WebSocket ì—°ê²° ê´€ë¦¬
active_connections: Dict[str, WebSocket] = {}

# ì„¸ì…˜ë³„ Session ì¸ìŠ¤í„´ìŠ¤ ê´€ë¦¬
session_instances: Dict[str, 'STTOnlySession'] = {}


# ============================================================
# í‘œì¤€ WebSocket ë©”ì‹œì§€ í”„ë¡œí† ì½œ ë˜í¼
# ============================================================
async def send_message(websocket: WebSocket, message_type: str, **kwargs):
    """
    WebSocket ë©”ì‹œì§€ ì „ì†¡ ë˜í¼ í•¨ìˆ˜

    ë©”ì‹œì§€ íƒ€ì…:
    - recognizing: ì¤‘ê°„ ì¸ì‹ ê²°ê³¼
    - recognized: ìµœì¢… ì¸ì‹ ê²°ê³¼
    - error: ì—ëŸ¬ ë©”ì‹œì§€
    - end: ì—°ê²° ì¢…ë£Œ

    Args:
        websocket: WebSocket ì—°ê²°
        message_type: ë©”ì‹œì§€ íƒ€ì…
        **kwargs: ë©”ì‹œì§€ ë°ì´í„°
    """
    ALLOWED_TYPES = {"recognizing", "recognized", "error", "end", "pong"}

    if message_type not in ALLOWED_TYPES:
        logger.warning(f"Unknown message type: {message_type}")
        return

    message = {"type": message_type, **kwargs}
    await websocket.send_json(message)
    logger.debug(f"Sent message: type={message_type}")


class STTOnlySession:
    """
    ë‹¨ì¼ ì–¸ì–´ STT ì „ìš© ì„¸ì…˜ (ë²ˆì—­ ì—†ìŒ)

    íšŒí™”ì—°ìŠµ, Learning Mode ë“± ë²ˆì—­ì´ í•„ìš” ì—†ëŠ” ê²½ìš° ì‚¬ìš©
    ìë™ ì–¸ì–´ ê°ì§€ ì—†ì´ ì§€ì •ëœ ì–¸ì–´ë¡œë§Œ ì¸ì‹í•˜ì—¬ ì„±ëŠ¥ ìµœì í™”
    """

    def __init__(self, session_id: str, websocket: WebSocket, loop: asyncio.AbstractEventLoop):
        self.session_id = session_id
        self.websocket = websocket
        self.loop = loop  # ë©”ì¸ ì´ë²¤íŠ¸ ë£¨í”„ (ìŠ¤ë ˆë“œ ê°„ ë¹„ë™ê¸° í˜¸ì¶œìš©)

        # STT Agent (ì‹±ê¸€í†¤)
        self.agent = STTAgent.get_instance()

        # Azure Speech ë¦¬ì†ŒìŠ¤
        self.recognizer: Optional[speechsdk.SpeechRecognizer] = None
        self.push_stream: Optional[speechsdk.audio.PushAudioInputStream] = None

        # ì„¸ì…˜ ì„¤ì •
        self.language: str = "en-US"
        self.auto_segment: bool = False  # ìë™ ë¶„ì ˆ ëª¨ë“œ (ì¹¨ë¬µ ê°ì§€)

        # í†µê³„
        self.processed_chunks = 0
        self.start_time = time.time()

        logger.info(f"STTOnlySession created: session_id={session_id}")

    async def initialize(self, language: str, auto_segment: bool = False):
        """
        ì„¸ì…˜ ì´ˆê¸°í™” ë° Azure Speech ë‹¨ì¼ ì–¸ì–´ ì„¤ì •

        Args:
            language: ì¸ì‹ ì–¸ì–´ (BCP-47 ì½”ë“œ, ì˜ˆ: "en-US", "ko-KR")
            auto_segment: ìë™ ë¶„ì ˆ ëª¨ë“œ (True: ì¹¨ë¬µ ê°ì§€ë¡œ ìë™ ë¬¸ì¥ ë¶„ë¦¬)
        """
        # ì–¸ì–´ ìœ íš¨ì„± ê²€ì‚¬
        if not language or not isinstance(language, str):
            await send_message(
                self.websocket, "error",
                error="language must be a string (e.g., 'en-US')"
            )
            return False

        self.language = language
        self.auto_segment = auto_segment

        try:
            logger.info(f"Setting up STT stream: language={language}, auto_segment={auto_segment}")

            # STT Agentë¥¼ í†µí•´ ë‹¨ì¼ ì–¸ì–´ ìŠ¤íŠ¸ë¦¼ ì„¤ì •
            self.recognizer, self.push_stream = await self.agent.process_stream(
                language=language,
                auto_segment=auto_segment
            )

            # ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ ë“±ë¡
            self.recognizer.recognizing.connect(self._on_recognizing)
            self.recognizer.recognized.connect(self._on_recognized)
            self.recognizer.canceled.connect(self._on_canceled)

            # ì—°ì† ì¸ì‹ ì‹œì‘
            self.recognizer.start_continuous_recognition_async()
            logger.info(f"STT stream started: session_id={self.session_id}, language={language}")

            return True

        except Exception as e:
            logger.error(f"Session initialization failed: {str(e)}", exc_info=True)
            await send_message(
                self.websocket, "error",
                error=f"STT initialization failed: {str(e)}"
            )
            return False

    def _on_recognizing(self, evt: speechsdk.SpeechRecognitionEventArgs):
        """ì¤‘ê°„ ì¸ì‹ ê²°ê³¼ í•¸ë“¤ëŸ¬"""
        if evt.result.reason == speechsdk.ResultReason.RecognizingSpeech:
            text = evt.result.text
            if text and text.strip():
                asyncio.run_coroutine_threadsafe(
                    send_message(
                        self.websocket,
                        "recognizing",
                        text=text
                    ),
                    self.loop
                )

    def _on_recognized(self, evt: speechsdk.SpeechRecognitionEventArgs):
        """ìµœì¢… ì¸ì‹ ê²°ê³¼ í•¸ë“¤ëŸ¬"""
        # NoMatchëŠ” ë¬´ì‹œ
        if evt.result.reason == speechsdk.ResultReason.NoMatch:
            logger.debug("No speech detected")
            return

        if evt.result.reason == speechsdk.ResultReason.RecognizedSpeech:
            text = evt.result.text
            if text and text.strip():
                logger.info(f"Recognized: '{text}'")
                asyncio.run_coroutine_threadsafe(
                    send_message(
                        self.websocket,
                        "recognized",
                        text=text,
                        language=self.language
                    ),
                    self.loop
                )

    def _on_canceled(self, evt: speechsdk.SpeechRecognitionCanceledEventArgs):
        """ì¸ì‹ ì·¨ì†Œ/ì—ëŸ¬ í•¸ë“¤ëŸ¬"""
        try:
            cancellation = getattr(evt, 'cancellation_details', None)
            if cancellation:
                cancel_reason = getattr(cancellation, 'reason', None)
                if cancel_reason == speechsdk.CancellationReason.EndOfStream:
                    return  # ì •ìƒ ì¢…ë£Œ

                error_details = getattr(cancellation, 'error_details', '')
                if error_details:
                    asyncio.run_coroutine_threadsafe(
                        send_message(
                            self.websocket, "error",
                            error=f"Recognition error: {error_details}"
                        ),
                        self.loop
                    )
        except Exception as e:
            logger.error(f"Error in canceled handler: {str(e)}")

    async def process_audio_chunk(self, audio_bytes: bytes):
        """
        ì˜¤ë””ì˜¤ ì²­í¬ë¥¼ Azure Speech PushStreamì— ì „ì†¡

        Args:
            audio_bytes: PCM 16kHz 16bit Mono ì˜¤ë””ì˜¤ ë°ì´í„°
        """
        if not self.push_stream:
            logger.warning("PushStream not initialized")
            return

        if not audio_bytes or len(audio_bytes) == 0:
            return

        try:
            self.push_stream.write(audio_bytes)
            self.processed_chunks += 1

            # ì²˜ìŒ 5ê°œ ì²­í¬ë§Œ ë¡œê·¸
            if self.processed_chunks <= 5:
                logger.info(f"Audio chunk #{self.processed_chunks}: {len(audio_bytes)} bytes")

        except Exception as e:
            logger.error(f"Audio processing failed: {str(e)}")
            await send_message(
                self.websocket, "error",
                error=f"Audio processing error: {str(e)}"
            )

    async def cleanup(self):
        """ì„¸ì…˜ ì •ë¦¬ (Azure Speech ë¦¬ì†ŒìŠ¤ í•´ì œ)"""
        try:
            if self.recognizer:
                self.recognizer.stop_continuous_recognition()
                logger.info(f"Recognizer stopped: session_id={self.session_id}")

            if self.push_stream:
                self.push_stream.close()
                logger.info(f"PushStream closed: session_id={self.session_id}")

        except Exception as e:
            logger.error(f"Cleanup failed: {str(e)}")

    def get_stats(self) -> Dict:
        """ì„¸ì…˜ í†µê³„ ë°˜í™˜"""
        elapsed_time = time.time() - self.start_time
        return {
            "session_id": self.session_id,
            "elapsed_time": round(elapsed_time, 2),
            "processed_chunks": self.processed_chunks,
            "language": self.language
        }


@router.websocket("/api/ai/voice/stt-stream")
async def voice_stt_stream_websocket(websocket: WebSocket):
    """
    ë‹¨ì¼ ì–¸ì–´ STT WebSocket ì—”ë“œí¬ì¸íŠ¸ (ë²ˆì—­ ì—†ìŒ, ê³ ì„±ëŠ¥)

    íšŒí™”ì—°ìŠµ, Learning Mode ë“± ë²ˆì—­ì´ í•„ìš” ì—†ëŠ” ê²½ìš° ì‚¬ìš©í•©ë‹ˆë‹¤.
    ìë™ ì–¸ì–´ ê°ì§€ ì—†ì´ ì§€ì •ëœ ì–¸ì–´ë¡œë§Œ ì¸ì‹í•˜ì—¬ ë” ë¹ ë¥¸ ì‘ë‹µì„ ì œê³µí•©ë‹ˆë‹¤.

    í”„ë¡œí† ì½œ:
    Client â†’ Server:
    1. {"language": "en-US", "auto_segment": false}  # ë‹¨ì¼ ì–¸ì–´ (BCP-47, string)
       - auto_segment: trueë©´ ì¹¨ë¬µ ê°ì§€ë¡œ ìë™ ë¬¸ì¥ ë¶„ë¦¬ (ê¸°ë³¸: false)
    2. [Binary: PCM 16kHz 16bit Mono]
    3. {"type": "end"}

    Server â†’ Client:
    1. {"type": "recognizing", "text": "..."}
    2. {"type": "recognized", "text": "...", "language": "en-US"}
    3. {"type": "error", "error": "..."}
    4. {"type": "end"}
    """
    logger.info("STT-only WebSocket connection requested")

    # WebSocket ì—°ê²° ìˆ˜ë½
    await websocket.accept()
    logger.info("STT-only WebSocket connection accepted")

    # ì„¸ì…˜ ID ìƒì„±
    session_id = str(uuid.uuid4())
    session: Optional[STTOnlySession] = None

    # í™œì„± ì—°ê²° ë“±ë¡
    active_connections[session_id] = websocket

    logger.info(f"STT-only session created: session_id={session_id}")

    try:
        # ë©”ì‹œì§€ ìˆ˜ì‹  ë£¨í”„
        while True:
            message = await websocket.receive()

            # JSON ë©”ì‹œì§€ ì²˜ë¦¬ (ì„¸ì…˜ ì´ˆê¸°í™” ë˜ëŠ” ì¢…ë£Œ)
            if "text" in message:
                logger.info(f"JSON message received: {message['text']}")
                try:
                    data = json.loads(message["text"])
                except json.JSONDecodeError as e:
                    logger.error(f"JSON parse error: {e}")
                    await send_message(websocket, "error", error="Invalid JSON format")
                    continue

                # languageë¡œ ì„¸ì…˜ ì´ˆê¸°í™”
                if "language" in data:
                    language = data["language"]
                    auto_segment = data.get("auto_segment", False)  # ìë™ ë¶„ì ˆ ëª¨ë“œ (ê¸°ë³¸: False)

                    # ë°°ì—´ì´ ì•„ë‹Œ ë¬¸ìì—´ì¸ì§€ í™•ì¸
                    if isinstance(language, list):
                        # ë°°ì—´ì´ë©´ ì²« ë²ˆì§¸ ìš”ì†Œ ì‚¬ìš© (í•˜ìœ„ í˜¸í™˜)
                        language = language[0] if language else "en-US"
                        logger.warning(f"Array received, using first element: {language}")

                    logger.info(f"Initializing STT session: language={language}, auto_segment={auto_segment}")

                    # ì„¸ì…˜ ìƒì„± ë° ì´ˆê¸°í™”
                    loop = asyncio.get_event_loop()
                    session = STTOnlySession(session_id, websocket, loop)
                    success = await session.initialize(language, auto_segment=auto_segment)

                    if success:
                        session_instances[session_id] = session
                        logger.info(f"STT session initialized: session_id={session_id}")
                    else:
                        logger.error(f"STT session initialization failed")

                # ì¢…ë£Œ ë©”ì‹œì§€
                elif data.get("type") == "end":
                    logger.info(f"End signal received: session_id={session_id}")
                    await send_message(websocket, "end")
                    break

                # Heartbeat ping ì²˜ë¦¬ - pong ì‘ë‹µ
                elif data.get("type") == "ping":
                    logger.debug(f"ğŸ’“ [STT-Stream] Heartbeat ping received: session_id={session_id}")
                    await send_message(websocket, "pong")

                else:
                    # ì•Œ ìˆ˜ ì—†ëŠ” ë©”ì‹œì§€ëŠ” ê²½ê³ ë§Œ ë‚¨ê¸°ê³  ì—°ê²° ìœ ì§€
                    logger.warning(f"Unknown message type (ignored): {data}")

            # Binary ë©”ì‹œì§€ ì²˜ë¦¬ (ì˜¤ë””ì˜¤ ì²­í¬)
            elif "bytes" in message:
                audio_bytes = message["bytes"]

                if not session:
                    await send_message(
                        websocket, "error",
                        error="Session not initialized. Send language first."
                    )
                    continue

                if audio_bytes and len(audio_bytes) > 0:
                    await session.process_audio_chunk(audio_bytes)

    except WebSocketDisconnect:
        logger.info(f"WebSocket disconnected: session_id={session_id}")

    except Exception as e:
        logger.error(f"WebSocket error: session_id={session_id}, error={str(e)}", exc_info=True)
        try:
            await send_message(websocket, "error", error=f"Server error: {str(e)}")
        except:
            pass

    finally:
        # ì—°ê²° ì •ë¦¬
        if session_id in active_connections:
            del active_connections[session_id]

        if session_id in session_instances:
            session = session_instances[session_id]
            await session.cleanup()
            del session_instances[session_id]

        logger.info(f"Session cleaned up: session_id={session_id}")


@router.get("/api/ai/voice/stt-stream/sessions")
async def get_active_stt_sessions():
    """
    í˜„ì¬ í™œì„± STT ì„¸ì…˜ ëª©ë¡ ì¡°íšŒ (ëª¨ë‹ˆí„°ë§ìš©)

    Returns:
        {
            "success": true,
            "data": {
                "active_sessions": 3,
                "sessions": [...]
            }
        }
    """
    sessions_info = []

    for session_id, session in session_instances.items():
        sessions_info.append(session.get_stats())

    return {
        "success": True,
        "data": {
            "active_sessions": len(active_connections),
            "sessions": sessions_info
        }
    }

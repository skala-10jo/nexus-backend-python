"""
ì‹¤ì‹œê°„ ìŒì„± ë²ˆì—­ WebSocket API (Azure Speech + Azure Translator)

ì—”ë“œí¬ì¸íŠ¸:
- WS /api/ai/voice/realtime: ì‹¤ì‹œê°„ ìŒì„± ë²ˆì—­ WebSocket ì—°ê²°

ìµœì í™”:
- Azure Speech SDK ìë™ ì–¸ì–´ ê°ì§€
- Azure Translator API ë©€í‹° íƒ€ê²Ÿ ë²ˆì—­
- WebSocket ì••ì¶• (permessage-deflate)
- ë¹„ë™ê¸° ì²˜ë¦¬ (asyncio)
- ì—ëŸ¬ ì²˜ë¦¬ ê°•í™”
"""
from fastapi import APIRouter, WebSocket, WebSocketDisconnect
from typing import Dict, Optional, List
import json
import uuid
import logging
import time
import asyncio

from app.services.voice_translation_service import VoiceTranslationService
import azure.cognitiveservices.speech as speechsdk

# ë¡œê±° ì„¤ì •
logger = logging.getLogger(__name__)

# ë¼ìš°í„° ìƒì„±
router = APIRouter()

# í™œì„± WebSocket ì—°ê²° ê´€ë¦¬
active_connections: Dict[str, WebSocket] = {}

# ì„¸ì…˜ë³„ Session ì¸ìŠ¤í„´ìŠ¤ ê´€ë¦¬
session_instances: Dict[str, 'VoiceTranslationSession'] = {}


# ============================================================
# ì–¸ì–´ ì½”ë“œ ë³€í™˜ í—¬í¼
# ============================================================
def bcp47_to_iso639(bcp47_code: str) -> str:
    """BCP-47 â†’ ISO 639-1 ë³€í™˜ (ko-KR â†’ ko)"""
    return bcp47_code.split('-')[0]


def iso639_to_bcp47(iso_code: str) -> str:
    """ISO 639-1 â†’ BCP-47 ë³€í™˜ (ko â†’ ko-KR)"""
    mapping = {
        "ko": "ko-KR",
        "en": "en-US",
        "ja": "ja-JP",
        "vi": "vi-VN",
        "zh": "zh-CN"
    }
    return mapping.get(iso_code, f"{iso_code}-XX")


# ============================================================
# í‘œì¤€ WebSocket ë©”ì‹œì§€ í”„ë¡œí† ì½œ ë˜í¼
# ============================================================
async def send_standard_message(websocket: WebSocket, message_type: str, **kwargs):
    """
    í‘œì¤€ WebSocket ë©”ì‹œì§€ ì „ì†¡ ë˜í¼ í•¨ìˆ˜

    ì˜¤ì§ 4ê°€ì§€ ë©”ì‹œì§€ íƒ€ì…ë§Œ í—ˆìš©:
    - recognizing: ì¤‘ê°„ ì¸ì‹ ê²°ê³¼
    - recognized: ìµœì¢… ì¸ì‹ ê²°ê³¼ + ë²ˆì—­
    - error: ì—ëŸ¬ ë©”ì‹œì§€
    - end: ì—°ê²° ì¢…ë£Œ

    Args:
        websocket: WebSocket ì—°ê²°
        message_type: ë©”ì‹œì§€ íƒ€ì… (recognizing, recognized, error, endë§Œ í—ˆìš©)
        **kwargs: ë©”ì‹œì§€ ë°ì´í„°
    """
    ALLOWED_TYPES = {"recognizing", "recognized", "error", "end"}

    if message_type not in ALLOWED_TYPES:
        logger.warning(f"âš ï¸ ë¹„í‘œì¤€ ë©”ì‹œì§€ ì°¨ë‹¨: type={message_type}")
        return

    message = {"type": message_type, **kwargs}
    await websocket.send_json(message)
    logger.debug(f"ğŸ“¤ í‘œì¤€ ë©”ì‹œì§€ ì „ì†¡: type={message_type}, keys={list(kwargs.keys())}")


class VoiceTranslationSession:
    """ì‹¤ì‹œê°„ ìŒì„± ë²ˆì—­ ì„¸ì…˜ ê´€ë¦¬ (Azure Speech + Azure Translator)"""

    def __init__(self, session_id: str, websocket: WebSocket):
        self.session_id = session_id
        self.websocket = websocket

        # Service ì´ˆê¸°í™” (AI Agent ì•„í‚¤í…ì²˜ ê°€ì´ë“œ ì¤€ìˆ˜: API â†’ Service â†’ Agent)
        self.service = VoiceTranslationService()

        # Azure Speech ë¦¬ì†ŒìŠ¤
        self.recognizer: Optional[speechsdk.SpeechRecognizer] = None
        self.push_stream: Optional[speechsdk.audio.PushAudioInputStream] = None

        # ì„¸ì…˜ ì„¤ì •
        self.selected_languages: List[str] = []  # BCP-47 ì½”ë“œ (ko-KR, en-US, ja-JP)

        # í†µê³„
        self.processed_chunks = 0
        self.total_translations = 0
        self.start_time = time.time()

        logger.info(f"âœ… VoiceTranslationSession ìƒì„±: session_id={session_id}")

    async def initialize(self, selected_languages: List[str]):
        """
        ì„¸ì…˜ ì´ˆê¸°í™” ë° Azure Speech ìë™ ì–¸ì–´ ê°ì§€ ì„¤ì •

        Args:
            selected_languages: ì„ íƒëœ ì–¸ì–´ ëª©ë¡ (BCP-47 ì½”ë“œ)
                ì˜ˆ: ["ko-KR", "en-US", "ja-JP"]
        """
        if not selected_languages or len(selected_languages) < 2:
            await send_standard_message(
                self.websocket, "error",
                error="ìµœì†Œ 2ê°œ ì´ìƒì˜ ì–¸ì–´ë¥¼ ì„ íƒí•´ì•¼ í•©ë‹ˆë‹¤"
            )
            return

        self.selected_languages = selected_languages

        try:
            # Azure Speech ìë™ ì–¸ì–´ ê°ì§€ ìŠ¤íŠ¸ë¦¼ ìƒì„± (Serviceë¥¼ í†µí•´ Agent í˜¸ì¶œ)
            logger.info(f"ğŸ”§ Azure Speech ìë™ ì–¸ì–´ ê°ì§€ ì„¤ì •: {selected_languages}")
            self.recognizer, self.push_stream = await self.service.setup_stream_with_auto_detect(
                candidate_languages=selected_languages
            )

            # ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ ë“±ë¡
            self.recognizer.recognizing.connect(self._on_recognizing)
            self.recognizer.recognized.connect(self._on_recognized)
            self.recognizer.canceled.connect(self._on_canceled)

            # ì—°ì† ì¸ì‹ ì‹œì‘
            self.recognizer.start_continuous_recognition()
            logger.info(f"ğŸ¤ Azure Speech ì—°ì† ì¸ì‹ ì‹œì‘: session_id={self.session_id}")

        except Exception as e:
            logger.error(f"âŒ ì„¸ì…˜ ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}", exc_info=True)
            await send_standard_message(
                self.websocket, "error",
                error=f"ì„¸ì…˜ ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}"
            )

    def _on_recognizing(self, evt: speechsdk.SpeechRecognitionEventArgs):
        """
        ì¤‘ê°„ ì¸ì‹ ê²°ê³¼ í•¸ë“¤ëŸ¬ (recognizing)

        Azure Speech SDKê°€ ì‹¤ì‹œê°„ìœ¼ë¡œ ë¶€ë¶„ ì¸ì‹ ê²°ê³¼ë¥¼ ë°˜í™˜í•  ë•Œ í˜¸ì¶œë©ë‹ˆë‹¤.
        ë²ˆì—­ì€ ìˆ˜í–‰í•˜ì§€ ì•Šê³  ì›ë³¸ í…ìŠ¤íŠ¸ë§Œ ì „ì†¡í•©ë‹ˆë‹¤.
        """
        if evt.result.reason == speechsdk.ResultReason.RecognizingSpeech:
            text = evt.result.text
            if text and text.strip():
                logger.debug(f"ğŸ” Recognizing: '{text}'")

                # ë¹„ë™ê¸°ë¡œ ë©”ì‹œì§€ ì „ì†¡ (ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ëŠ” ë™ê¸° í•¨ìˆ˜)
                asyncio.create_task(
                    send_standard_message(
                        self.websocket,
                        "recognizing",
                        text=text
                    )
                )

    def _on_recognized(self, evt: speechsdk.SpeechRecognitionEventArgs):
        """
        ìµœì¢… ì¸ì‹ ê²°ê³¼ í•¸ë“¤ëŸ¬ (recognized)

        Azure Speech SDKê°€ ìµœì¢… ì¸ì‹ ê²°ê³¼ë¥¼ ë°˜í™˜í•  ë•Œ í˜¸ì¶œë©ë‹ˆë‹¤.
        1. ìë™ ê°ì§€ëœ ì–¸ì–´ í™•ì¸
        2. ê°ì§€ëœ ì–¸ì–´ë¥¼ ì œì™¸í•œ íƒ€ê²Ÿ ì–¸ì–´ë¡œ ë²ˆì—­
        3. recognized ë©”ì‹œì§€ ì „ì†¡
        """
        if evt.result.reason == speechsdk.ResultReason.RecognizedSpeech:
            text = evt.result.text

            # í…ìŠ¤íŠ¸ê°€ ë¹„ì–´ìˆìœ¼ë©´ ë¬´ì‹œ
            if not text or not text.strip():
                logger.debug("âšª ë¬´ìŒ êµ¬ê°„ ê°ì§€ (recognized)")
                return

            # ìë™ ê°ì§€ëœ ì–¸ì–´ ì¶”ì¶œ
            detected_lang_bcp47 = evt.result.properties.get(
                speechsdk.PropertyId.SpeechServiceConnection_AutoDetectSourceLanguageResult
            )

            if not detected_lang_bcp47:
                logger.warning("âš ï¸ ì–¸ì–´ ìë™ ê°ì§€ ì‹¤íŒ¨, ê¸°ë³¸ê°’ ì‚¬ìš©: ko-KR")
                detected_lang_bcp47 = "ko-KR"

            logger.info(f"ğŸ¤ Recognized: '{text}' (ì–¸ì–´: {detected_lang_bcp47})")

            # ë¹„ë™ê¸° ë²ˆì—­ ì‘ì—… ì‹¤í–‰
            asyncio.create_task(
                self._translate_and_send(text, detected_lang_bcp47, evt)
            )

    async def _translate_and_send(
        self,
        text: str,
        detected_lang_bcp47: str,
        evt: speechsdk.SpeechRecognitionEventArgs
    ):
        """
        ë²ˆì—­ ìˆ˜í–‰ ë° recognized ë©”ì‹œì§€ ì „ì†¡

        Args:
            text: ì¸ì‹ëœ í…ìŠ¤íŠ¸
            detected_lang_bcp47: ìë™ ê°ì§€ëœ ì–¸ì–´ (BCP-47)
            evt: ì¸ì‹ ì´ë²¤íŠ¸
        """
        try:
            # ê°ì§€ëœ ì–¸ì–´ë¥¼ ì œì™¸í•œ íƒ€ê²Ÿ ì–¸ì–´ ëª©ë¡ ìƒì„±
            target_langs_bcp47 = [
                lang for lang in self.selected_languages
                if lang != detected_lang_bcp47
            ]

            if not target_langs_bcp47:
                logger.warning(f"âš ï¸ ë²ˆì—­ íƒ€ê²Ÿ ì–¸ì–´ ì—†ìŒ (ê°ì§€ ì–¸ì–´: {detected_lang_bcp47})")
                # ë²ˆì—­ ì—†ì´ ì›ë¬¸ë§Œ ì „ì†¡
                await send_standard_message(
                    self.websocket,
                    "recognized",
                    text=text,
                    detected_language=detected_lang_bcp47,
                    translations=[],
                    confidence=0.9
                )
                return

            # BCP-47 â†’ ISO 639-1 ë³€í™˜
            detected_lang_iso = bcp47_to_iso639(detected_lang_bcp47)
            target_langs_iso = [bcp47_to_iso639(lang) for lang in target_langs_bcp47]

            logger.info(
                f"ğŸŒ ë²ˆì—­ ì‹œì‘: {detected_lang_iso} â†’ {target_langs_iso}, "
                f"text='{text[:50]}...'"
            )

            # Azure Translator ë©€í‹° íƒ€ê²Ÿ ë²ˆì—­ (Serviceë¥¼ í†µí•´ Agent í˜¸ì¶œ)
            translations = await self.service.translate_to_multiple_languages(
                text=text,
                source_lang=detected_lang_iso,
                target_langs=target_langs_iso
            )

            # ISO 639-1 â†’ BCP-47 ë³€í™˜ (í”„ë¡ íŠ¸ì—”ë“œ í˜¸í™˜)
            translations_bcp47 = [
                {"lang": iso639_to_bcp47(t["lang"]), "text": t["text"]}
                for t in translations
            ]

            logger.info(f"âœ… ë²ˆì—­ ì™„ë£Œ: {len(translations_bcp47)}ê°œ ì–¸ì–´")

            # í†µê³„ ì—…ë°ì´íŠ¸
            self.processed_chunks += 1
            self.total_translations += len(translations_bcp47)

            # recognized ë©”ì‹œì§€ ì „ì†¡
            await send_standard_message(
                self.websocket,
                "recognized",
                text=text,
                detected_language=detected_lang_bcp47,
                translations=translations_bcp47,
                confidence=0.9
            )

        except Exception as e:
            logger.error(f"âŒ ë²ˆì—­ ì‹¤íŒ¨: {str(e)}", exc_info=True)
            await send_standard_message(
                self.websocket, "error",
                error=f"ë²ˆì—­ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
            )

    def _on_canceled(self, evt: speechsdk.SpeechRecognitionCanceledEventArgs):
        """
        ì¸ì‹ ì·¨ì†Œ/ì—ëŸ¬ í•¸ë“¤ëŸ¬

        Azure Speech SDKê°€ ì—ëŸ¬ë¥¼ ë°˜í™˜í•  ë•Œ í˜¸ì¶œë©ë‹ˆë‹¤.
        """
        logger.error(
            f"âŒ Speech ì¸ì‹ ì·¨ì†Œ: reason={evt.reason}, "
            f"cancellation_details={evt.cancellation_details}"
        )

        # ì—ëŸ¬ ë©”ì‹œì§€ ì „ì†¡
        asyncio.create_task(
            send_standard_message(
                self.websocket, "error",
                error=f"ìŒì„± ì¸ì‹ ì˜¤ë¥˜: {evt.cancellation_details.error_details}"
            )
        )

    async def process_audio_chunk(self, audio_bytes: bytes):
        """
        ì˜¤ë””ì˜¤ ì²­í¬ë¥¼ Azure Speech PushStreamì— ì „ì†¡

        Args:
            audio_bytes: ì›ë³¸ ë°”ì´ë„ˆë¦¬ ì˜¤ë””ì˜¤ ë°ì´í„° (WebM/Opus, 16kHz, mono)
        """
        if not self.push_stream:
            logger.warning("âš ï¸ PushStreamì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
            return

        if not audio_bytes or len(audio_bytes) == 0:
            logger.debug("âšª ë¹ˆ ì˜¤ë””ì˜¤ ì²­í¬ ë¬´ì‹œ")
            return

        try:
            # Azure Speech PushStreamì— ì›ë³¸ ë°”ì´ë„ˆë¦¬ ì“°ê¸° (base64 ë””ì½”ë”© ì—†ìŒ!)
            self.push_stream.write(audio_bytes)
            logger.debug(f"ğŸ“¤ ì˜¤ë””ì˜¤ ì²­í¬ ì „ì†¡: {len(audio_bytes)} bytes")

        except Exception as e:
            logger.error(f"âŒ ì˜¤ë””ì˜¤ ì²­í¬ ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}", exc_info=True)
            await send_standard_message(
                self.websocket, "error",
                error=f"ì˜¤ë””ì˜¤ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
            )

    async def cleanup(self):
        """ì„¸ì…˜ ì •ë¦¬ (Azure Speech ë¦¬ì†ŒìŠ¤ í•´ì œ)"""
        try:
            if self.recognizer:
                self.recognizer.stop_continuous_recognition()
                logger.info(f"ğŸ›‘ Azure Speech ì—°ì† ì¸ì‹ ì¤‘ì§€: session_id={self.session_id}")

            if self.push_stream:
                self.push_stream.close()
                logger.info(f"ğŸ”’ PushStream ë‹«í˜: session_id={self.session_id}")

        except Exception as e:
            logger.error(f"âŒ ì„¸ì…˜ ì •ë¦¬ ì‹¤íŒ¨: {str(e)}", exc_info=True)

    def get_stats(self) -> Dict:
        """ì„¸ì…˜ í†µê³„ ë°˜í™˜"""
        elapsed_time = time.time() - self.start_time
        return {
            "session_id": self.session_id,
            "elapsed_time": round(elapsed_time, 2),
            "processed_chunks": self.processed_chunks,
            "total_translations": self.total_translations,
            "selected_languages": self.selected_languages
        }


@router.websocket("/api/ai/voice/realtime")
async def voice_translation_websocket(websocket: WebSocket):
    """
    ì‹¤ì‹œê°„ ìŒì„± ë²ˆì—­ WebSocket ì—”ë“œí¬ì¸íŠ¸

    í´ë¼ì´ì–¸íŠ¸ì™€ WebSocket ì—°ê²°ì„ ë§ºê³  ì‹¤ì‹œê°„ìœ¼ë¡œ ìŒì„± ë²ˆì—­ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.

    í”„ë¡œí† ì½œ:
    1. í´ë¼ì´ì–¸íŠ¸ â†’ ì„œë²„ (JSON): {"selected_languages": ["ko-KR", "en-US", "ja-JP"]}
    2. í´ë¼ì´ì–¸íŠ¸ â†’ ì„œë²„ (Binary): ì˜¤ë””ì˜¤ ì²­í¬ (WebM/Opus, 16kHz, mono)
    3. ì„œë²„ â†’ í´ë¼ì´ì–¸íŠ¸ (JSON):
       - {"type": "recognizing", "text": "..."}
       - {"type": "recognized", "text": "...", "detected_language": "ko-KR", "translations": [...]}
       - {"type": "error", "error": "..."}
       - {"type": "end"}
    """

    # WebSocket ì—°ê²° ìˆ˜ë½
    await websocket.accept()

    # ì„¸ì…˜ ID ìƒì„±
    session_id = str(uuid.uuid4())
    session: Optional[VoiceTranslationSession] = None

    # í™œì„± ì—°ê²° ë“±ë¡
    active_connections[session_id] = websocket

    logger.info(f"âœ… WebSocket ì—°ê²°ë¨: session_id={session_id}")

    try:
        # ë©”ì‹œì§€ ìˆ˜ì‹  ë£¨í”„
        while True:
            # í´ë¼ì´ì–¸íŠ¸ë¡œë¶€í„° ë©”ì‹œì§€ ìˆ˜ì‹ 
            message = await websocket.receive()

            # JSON ë©”ì‹œì§€ ì²˜ë¦¬ (ì„¸ì…˜ ì´ˆê¸°í™”)
            if "text" in message:
                try:
                    data = json.loads(message["text"])
                except json.JSONDecodeError:
                    await send_standard_message(websocket, "error", error="ì˜ëª»ëœ JSON í˜•ì‹ì…ë‹ˆë‹¤")
                    continue

                # selected_languagesë¡œ ì„¸ì…˜ ì´ˆê¸°í™”
                if "selected_languages" in data:
                    selected_languages = data["selected_languages"]
                    logger.info(f"ğŸ“ ì„¸ì…˜ ì´ˆê¸°í™” ìš”ì²­: {selected_languages}")

                    # ì„¸ì…˜ ìƒì„± ë° ì´ˆê¸°í™”
                    session = VoiceTranslationSession(session_id, websocket)
                    await session.initialize(selected_languages)

                    # ì„¸ì…˜ ì €ì¥
                    session_instances[session_id] = session

                # ì¢…ë£Œ ë©”ì‹œì§€
                elif data.get("type") == "end":
                    logger.info(f"ğŸ”š í´ë¼ì´ì–¸íŠ¸ ì¢…ë£Œ ìš”ì²­: session_id={session_id}")
                    await send_standard_message(websocket, "end")
                    break

                else:
                    await send_standard_message(
                        websocket, "error",
                        error=f"ì•Œ ìˆ˜ ì—†ëŠ” ë©”ì‹œì§€: {data}"
                    )

            # Binary ë©”ì‹œì§€ ì²˜ë¦¬ (ì˜¤ë””ì˜¤ ì²­í¬)
            elif "bytes" in message:
                audio_bytes = message["bytes"]

                if not session:
                    await send_standard_message(
                        websocket, "error",
                        error="ì„¸ì…˜ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. selected_languagesë¥¼ ë¨¼ì € ë³´ë‚´ì„¸ìš”"
                    )
                    continue

                if audio_bytes and len(audio_bytes) > 0:
                    # ì›ë³¸ ë°”ì´ë„ˆë¦¬ë¥¼ Azure Speech PushStreamì— ì „ì†¡
                    await session.process_audio_chunk(audio_bytes)

    except WebSocketDisconnect:
        logger.info(f"ğŸ”Œ WebSocket ì—°ê²° ì¢…ë£Œ: session_id={session_id}")

    except Exception as e:
        logger.error(f"âŒ WebSocket ì—ëŸ¬: session_id={session_id}, error={str(e)}", exc_info=True)
        try:
            await send_standard_message(websocket, "error", error=f"ì„œë²„ ì˜¤ë¥˜: {str(e)}")
        except:
            pass

    finally:
        # ì—°ê²° ì •ë¦¬
        if session_id in active_connections:
            del active_connections[session_id]

        if session_id in session_instances:
            session = session_instances[session_id]
            await session.cleanup()
            del session_instances[session_id]

        logger.info(f"ğŸ§¹ ì„¸ì…˜ ì •ë¦¬ ì™„ë£Œ: session_id={session_id}")


@router.get("/api/ai/voice/sessions")
async def get_active_sessions():
    """
    í˜„ì¬ í™œì„± ì„¸ì…˜ ëª©ë¡ ì¡°íšŒ (ê´€ë¦¬/ëª¨ë‹ˆí„°ë§ìš©)

    Returns:
        {
            "success": true,
            "data": {
                "active_sessions": 3,
                "sessions": [...]
            }
        }
    """
    sessions_info = []

    for session_id, session in session_instances.items():
        sessions_info.append(session.get_stats())

    return {
        "success": True,
        "data": {
            "active_sessions": len(active_connections),
            "sessions": sessions_info
        }
    }

"""
ì‹¤ì‹œê°„ ìŒì„± ë²ˆì—­ WebSocket API (Azure Speech + Azure Translator)

ì—”ë“œí¬ì¸íŠ¸:
- WS /api/ai/voice/realtime: ì‹¤ì‹œê°„ ìŒì„± ë²ˆì—­ WebSocket ì—°ê²°

ìµœì í™”:
- Azure Speech SDK ìë™ ì–¸ì–´ ê°ì§€
- Azure Translator API ë©€í‹° íƒ€ê²Ÿ ë²ˆì—­
- í”„ë¡œì íŠ¸ë³„ ì „ë¬¸ìš©ì–´ì‚¬ì „ í›„ì²˜ë¦¬ (ì„ íƒì )
- WebSocket ì••ì¶• (permessage-deflate)
- ë¹„ë™ê¸° ì²˜ë¦¬ (asyncio)
- ì—ëŸ¬ ì²˜ë¦¬ ê°•í™”
"""
from fastapi import APIRouter, WebSocket, WebSocketDisconnect
from typing import Dict, Optional, List
from uuid import UUID
import json
import uuid
import logging
import time
import asyncio

from app.services.voice_translation_service import VoiceTranslationService
from app.database import SessionLocal
import azure.cognitiveservices.speech as speechsdk

# ë¡œê±° ì„¤ì •
logger = logging.getLogger(__name__)

# ë¼ìš°í„° ìƒì„±
router = APIRouter()

# í™œì„± WebSocket ì—°ê²° ê´€ë¦¬
active_connections: Dict[str, WebSocket] = {}

# ì„¸ì…˜ë³„ Session ì¸ìŠ¤í„´ìŠ¤ ê´€ë¦¬
session_instances: Dict[str, 'VoiceTranslationSession'] = {}


# ============================================================
# ì–¸ì–´ ì½”ë“œ ë³€í™˜ í—¬í¼
# ============================================================
def bcp47_to_iso639(bcp47_code: str) -> str:
    """BCP-47 â†’ ISO 639-1 ë³€í™˜ (ko-KR â†’ ko)"""
    return bcp47_code.split('-')[0]


def iso639_to_bcp47(iso_code: str) -> str:
    """ISO 639-1 â†’ BCP-47 ë³€í™˜ (ko â†’ ko-KR)"""
    mapping = {
        "ko": "ko-KR",
        "en": "en-US",
        "ja": "ja-JP",
        "vi": "vi-VN",
        "zh": "zh-CN"
    }
    return mapping.get(iso_code, f"{iso_code}-XX")


# ============================================================
# í‘œì¤€ WebSocket ë©”ì‹œì§€ í”„ë¡œí† ì½œ ë˜í¼
# ============================================================
async def send_standard_message(websocket: WebSocket, message_type: str, **kwargs):
    """
    í‘œì¤€ WebSocket ë©”ì‹œì§€ ì „ì†¡ ë˜í¼ í•¨ìˆ˜

    ì˜¤ì§ 5ê°€ì§€ ë©”ì‹œì§€ íƒ€ì…ë§Œ í—ˆìš©:
    - recognizing: ì¤‘ê°„ ì¸ì‹ ê²°ê³¼
    - recognized: ìµœì¢… ì¸ì‹ ê²°ê³¼ + ë²ˆì—­
    - error: ì—ëŸ¬ ë©”ì‹œì§€
    - end: ì—°ê²° ì¢…ë£Œ
    - pong: Heartbeat ì‘ë‹µ

    Args:
        websocket: WebSocket ì—°ê²°
        message_type: ë©”ì‹œì§€ íƒ€ì… (recognizing, recognized, error, end, pongë§Œ í—ˆìš©)
        **kwargs: ë©”ì‹œì§€ ë°ì´í„°
    """
    ALLOWED_TYPES = {"recognizing", "recognized", "error", "end", "pong"}

    if message_type not in ALLOWED_TYPES:
        logger.warning(f"âš ï¸ ë¹„í‘œì¤€ ë©”ì‹œì§€ ì°¨ë‹¨: type={message_type}")
        return

    message = {"type": message_type, **kwargs}
    await websocket.send_json(message)
    logger.debug(f"ğŸ“¤ í‘œì¤€ ë©”ì‹œì§€ ì „ì†¡: type={message_type}, keys={list(kwargs.keys())}")


class VoiceTranslationSession:
    """ì‹¤ì‹œê°„ ìŒì„± ë²ˆì—­ ì„¸ì…˜ ê´€ë¦¬ (Azure Speech + Azure Translator + ìš©ì–´ì§‘ í›„ì²˜ë¦¬)"""

    def __init__(self, session_id: str, websocket: WebSocket, loop: asyncio.AbstractEventLoop):
        self.session_id = session_id
        self.websocket = websocket
        self.loop = loop  # ë©”ì¸ ì´ë²¤íŠ¸ ë£¨í”„ ì €ì¥ (ìŠ¤ë ˆë“œ ê°„ ë¹„ë™ê¸° í˜¸ì¶œìš©)

        # Service ì´ˆê¸°í™” (AI Agent ì•„í‚¤í…ì²˜ ê°€ì´ë“œ ì¤€ìˆ˜: API â†’ Service â†’ Agent)
        self.service = VoiceTranslationService()

        # Azure Speech ë¦¬ì†ŒìŠ¤
        self.recognizer: Optional[speechsdk.SpeechRecognizer] = None
        self.push_stream: Optional[speechsdk.audio.PushAudioInputStream] = None

        # ì„¸ì…˜ ì„¤ì •
        self.selected_languages: List[str] = []  # BCP-47 ì½”ë“œ (ko-KR, en-US, ja-JP)

        # í”„ë¡œì íŠ¸ ë° ìš©ì–´ì§‘ ì„¤ì • (ì „ë¬¸ìš©ì–´ì‚¬ì „ í›„ì²˜ë¦¬ìš©)
        self.project_id: Optional[UUID] = None
        self.db_session = None  # DB ì„¸ì…˜ (í”„ë¡œì íŠ¸ ì„ íƒ ì‹œ ìš©ì–´ì§‘ ì¡°íšŒìš©)

        # í†µê³„
        self.processed_chunks = 0
        self.total_translations = 0
        self.start_time = time.time()

        # WebSocket ì—°ê²° ìƒíƒœ í”Œë˜ê·¸ (ë‹«íŒ í›„ ë©”ì‹œì§€ ì „ì†¡ ë°©ì§€)
        self.is_closed = False

        logger.info(f"âœ… VoiceTranslationSession ìƒì„±: session_id={session_id}")

    async def initialize(self, selected_languages: List[str], project_id: Optional[str] = None):
        """
        ì„¸ì…˜ ì´ˆê¸°í™” ë° Azure Speech ìë™ ì–¸ì–´ ê°ì§€ ì„¤ì •

        Args:
            selected_languages: ì„ íƒëœ ì–¸ì–´ ëª©ë¡ (BCP-47 ì½”ë“œ)
                ì˜ˆ: ["ko-KR", "en-US", "ja-JP"]
            project_id: í”„ë¡œì íŠ¸ ID (Noneì´ë©´ ìš©ì–´ì§‘ ë¯¸ì ìš©)
        """
        if not selected_languages or len(selected_languages) < 2:
            await send_standard_message(
                self.websocket, "error",
                error="ìµœì†Œ 2ê°œ ì´ìƒì˜ ì–¸ì–´ë¥¼ ì„ íƒí•´ì•¼ í•©ë‹ˆë‹¤"
            )
            return

        self.selected_languages = selected_languages

        # í”„ë¡œì íŠ¸ ì„¤ì • (ìš©ì–´ì§‘ í›„ì²˜ë¦¬ìš©)
        if project_id:
            try:
                self.project_id = UUID(project_id)
                self.db_session = SessionLocal()
                logger.info(f"ğŸ“š í”„ë¡œì íŠ¸ ì—°ê²°: project_id={project_id} (ìš©ì–´ì§‘ í›„ì²˜ë¦¬ í™œì„±í™”)")
            except ValueError as e:
                logger.warning(f"âš ï¸ ì˜ëª»ëœ project_id í˜•ì‹: {project_id} - ìš©ì–´ì§‘ ë¯¸ì ìš©")
                self.project_id = None

        try:
            # Azure Speech ìë™ ì–¸ì–´ ê°ì§€ ìŠ¤íŠ¸ë¦¼ ìƒì„± (Serviceë¥¼ í†µí•´ Agent í˜¸ì¶œ)
            logger.info(f"ğŸ”§ Azure Speech ìë™ ì–¸ì–´ ê°ì§€ ì„¤ì •: {selected_languages}")
            self.recognizer, self.push_stream = await self.service.setup_stream_with_auto_detect(
                candidate_languages=selected_languages
            )

            # ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ ë“±ë¡ (í•„ìˆ˜ í•¸ë“¤ëŸ¬ë§Œ)
            self.recognizer.recognizing.connect(self._on_recognizing)
            self.recognizer.recognized.connect(self._on_recognized)
            self.recognizer.canceled.connect(self._on_canceled)

            # ì—°ì† ì¸ì‹ ì‹œì‘ (ë¹„ë™ê¸°)
            logger.info(f"ğŸš€ Starting continuous recognition for session: {self.session_id}")
            self.recognizer.start_continuous_recognition_async()
            logger.info(f"âœ… Continuous recognition started for session: {self.session_id}")

        except Exception as e:
            logger.error(f"âŒ ì„¸ì…˜ ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}", exc_info=True)
            await send_standard_message(
                self.websocket, "error",
                error=f"ì„¸ì…˜ ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}"
            )

    def _on_recognizing(self, evt: speechsdk.SpeechRecognitionEventArgs):
        """ì¤‘ê°„ ì¸ì‹ ê²°ê³¼ í•¸ë“¤ëŸ¬ (recognizing)"""
        if self.is_closed:
            return
        logger.info(f"ğŸ¤ [Recognizing] reason={evt.result.reason}, text='{evt.result.text}'")
        if evt.result.reason == speechsdk.ResultReason.RecognizingSpeech:
            text = evt.result.text
            if text and text.strip():

                # ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ ë©”ì¸ ì´ë²¤íŠ¸ ë£¨í”„ë¡œ ì½”ë£¨í‹´ ìŠ¤ì¼€ì¤„ë§
                asyncio.run_coroutine_threadsafe(
                    send_standard_message(
                        self.websocket,
                        "recognizing",
                        text=text
                    ),
                    self.loop
                )

    def _on_recognized(self, evt: speechsdk.SpeechRecognitionEventArgs):
        """ìµœì¢… ì¸ì‹ ê²°ê³¼ í•¸ë“¤ëŸ¬ (recognized)"""
        if self.is_closed:
            return
        # NoMatchëŠ” ë¬´ì‹œ (ìŒì„±ì´ ê°ì§€ë˜ì§€ ì•Šì€ ê²½ìš°)
        if evt.result.reason == speechsdk.ResultReason.NoMatch:
            logger.debug(f"âšª [NoMatch] ìŒì„± ê°ì§€ ì•ˆë¨")
            return
        logger.info(f"âœ… [Recognized] reason={evt.result.reason}, text='{evt.result.text}'")
        if evt.result.reason == speechsdk.ResultReason.RecognizedSpeech:
            text = evt.result.text

            if not text or not text.strip():
                return

            # ìë™ ê°ì§€ëœ ì–¸ì–´ ì¶”ì¶œ
            detected_lang_bcp47 = evt.result.properties.get(
                speechsdk.PropertyId.SpeechServiceConnection_AutoDetectSourceLanguageResult
            ) or "ko-KR"

            # ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ ë©”ì¸ ì´ë²¤íŠ¸ ë£¨í”„ë¡œ ì½”ë£¨í‹´ ìŠ¤ì¼€ì¤„ë§
            asyncio.run_coroutine_threadsafe(
                self._translate_and_send(text, detected_lang_bcp47, evt),
                self.loop
            )

    async def _translate_and_send(
        self,
        text: str,
        detected_lang_bcp47: str,
        evt: speechsdk.SpeechRecognitionEventArgs
    ):
        """
        ë²ˆì—­ ìˆ˜í–‰ ë° recognized ë©”ì‹œì§€ ì „ì†¡

        Args:
            text: ì¸ì‹ëœ í…ìŠ¤íŠ¸
            detected_lang_bcp47: ìë™ ê°ì§€ëœ ì–¸ì–´ (BCP-47)
            evt: ì¸ì‹ ì´ë²¤íŠ¸
        """
        if self.is_closed:
            return
        try:
            # ê°ì§€ëœ ì–¸ì–´ë¥¼ ì œì™¸í•œ íƒ€ê²Ÿ ì–¸ì–´ ëª©ë¡ ìƒì„±
            target_langs_bcp47 = [
                lang for lang in self.selected_languages
                if lang != detected_lang_bcp47
            ]

            if not target_langs_bcp47:
                await send_standard_message(
                    self.websocket, "recognized",
                    text=text, detected_language=detected_lang_bcp47,
                    translations=[], confidence=0.9
                )
                return

            # BCP-47 â†’ ISO 639-1 ë³€í™˜
            detected_lang_iso = bcp47_to_iso639(detected_lang_bcp47)
            target_langs_iso = [bcp47_to_iso639(lang) for lang in target_langs_bcp47]

            # Azure Translator ë©€í‹° íƒ€ê²Ÿ ë²ˆì—­ (í”„ë¡œì íŠ¸ê°€ ìˆìœ¼ë©´ ìš©ì–´ì§‘ í›„ì²˜ë¦¬ ë° ìš©ì–´ íƒì§€ ì ìš©)
            detected_terms = []

            if self.project_id and self.db_session:
                # ìš©ì–´ì§‘ í›„ì²˜ë¦¬ í¬í•¨ ë²ˆì—­ + ìš©ì–´ íƒì§€
                translations, detected_terms = await self.service.translate_to_multiple_languages_with_glossary(
                    text=text,
                    source_lang=detected_lang_iso,
                    target_langs=target_langs_iso,
                    project_id=self.project_id,
                    db=self.db_session
                )
            else:
                # ê¸°ë³¸ ë²ˆì—­ (ìš©ì–´ì§‘ ë¯¸ì ìš©)
                translations = await self.service.translate_to_multiple_languages(
                    text=text,
                    source_lang=detected_lang_iso,
                    target_langs=target_langs_iso
                )

            # ISO 639-1 â†’ BCP-47 ë³€í™˜
            translations_bcp47 = [
                {"lang": iso639_to_bcp47(t["lang"]), "text": t["text"]}
                for t in translations
            ]

            # recognized ë©”ì‹œì§€ ì „ì†¡ (ìš©ì–´ íƒì§€ ê²°ê³¼ í¬í•¨)
            await send_standard_message(
                self.websocket, "recognized",
                text=text, detected_language=detected_lang_bcp47,
                translations=translations_bcp47, confidence=0.9,
                detected_terms=detected_terms  # íƒì§€ëœ ì „ë¬¸ìš©ì–´ ì¶”ê°€
            )

        except Exception as e:
            logger.error(f"âŒ ë²ˆì—­ ì‹¤íŒ¨: {str(e)}", exc_info=True)
            await send_standard_message(
                self.websocket, "error",
                error=f"ë²ˆì—­ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
            )

    def _on_canceled(self, evt: speechsdk.SpeechRecognitionCanceledEventArgs):
        """ì¸ì‹ ì·¨ì†Œ/ì—ëŸ¬ í•¸ë“¤ëŸ¬"""
        try:
            cancellation = getattr(evt, 'cancellation_details', None)
            if cancellation:
                cancel_reason = getattr(cancellation, 'reason', 'Unknown')
                if cancel_reason == speechsdk.CancellationReason.EndOfStream:
                    return  # ì •ìƒ ì¢…ë£Œ

                error_details = getattr(cancellation, 'error_details', '')
                if error_details:
                    asyncio.run_coroutine_threadsafe(
                        send_standard_message(
                            self.websocket, "error",
                            error=f"ìŒì„± ì¸ì‹ ì˜¤ë¥˜: {error_details}"
                        ),
                        self.loop
                    )
        except Exception as e:
            logger.error(f"_on_canceled error: {str(e)}")

    async def process_audio_chunk(self, audio_bytes: bytes):
        """
        ì˜¤ë””ì˜¤ ì²­í¬ë¥¼ Azure Speech PushStreamì— ì „ì†¡

        Args:
            audio_bytes: PCM 16kHz 16bit Mono ì˜¤ë””ì˜¤ ë°ì´í„°
        """
        if not self.push_stream:
            logger.warning("âš ï¸ PushStreamì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
            return

        if not audio_bytes or len(audio_bytes) == 0:
            logger.debug("âšª ë¹ˆ ì˜¤ë””ì˜¤ ì²­í¬ ë¬´ì‹œ")
            return

        try:
            # Azure Speech PushStreamì— PCM ë°”ì´ë„ˆë¦¬ ì“°ê¸°
            self.push_stream.write(audio_bytes)
            self.processed_chunks += 1

            # ì²« 5ê°œ ì²­í¬ë§Œ ë¡œê·¸ ì¶œë ¥ (ë””ë²„ê¹…ìš©)
            if self.processed_chunks <= 5:
                logger.info(f"ğŸ“¤ ì˜¤ë””ì˜¤ ì²­í¬ #{self.processed_chunks}: {len(audio_bytes)} bytes")

        except Exception as e:
            logger.error(f"âŒ ì˜¤ë””ì˜¤ ì²­í¬ ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}", exc_info=True)
            await send_standard_message(
                self.websocket, "error",
                error=f"ì˜¤ë””ì˜¤ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
            )

    async def cleanup(self):
        """ì„¸ì…˜ ì •ë¦¬ (Azure Speech ë¦¬ì†ŒìŠ¤ ë° DB ì„¸ì…˜ í•´ì œ)"""
        self.is_closed = True  # ë¨¼ì € í”Œë˜ê·¸ ì„¤ì •í•˜ì—¬ ì½œë°± ì°¨ë‹¨
        try:
            if self.recognizer:
                self.recognizer.stop_continuous_recognition()
                logger.info(f"ğŸ›‘ Azure Speech ì—°ì† ì¸ì‹ ì¤‘ì§€: session_id={self.session_id}")

            if self.push_stream:
                self.push_stream.close()
                logger.info(f"ğŸ”’ PushStream ë‹«í˜: session_id={self.session_id}")

            # DB ì„¸ì…˜ ì •ë¦¬ (í”„ë¡œì íŠ¸ ì„ íƒ ì‹œ ìƒì„±ëœ ê²½ìš°)
            if self.db_session:
                self.db_session.close()
                logger.info(f"ğŸ”’ DB ì„¸ì…˜ ë‹«í˜: session_id={self.session_id}")

        except Exception as e:
            logger.error(f"âŒ ì„¸ì…˜ ì •ë¦¬ ì‹¤íŒ¨: {str(e)}", exc_info=True)

    def get_stats(self) -> Dict:
        """ì„¸ì…˜ í†µê³„ ë°˜í™˜"""
        elapsed_time = time.time() - self.start_time
        return {
            "session_id": self.session_id,
            "elapsed_time": round(elapsed_time, 2),
            "processed_chunks": self.processed_chunks,
            "total_translations": self.total_translations,
            "selected_languages": self.selected_languages,
            "project_id": str(self.project_id) if self.project_id else None,
            "glossary_enabled": self.project_id is not None
        }


@router.websocket("/api/ai/voice/realtime")
async def voice_translation_websocket(websocket: WebSocket):
    """
    ì‹¤ì‹œê°„ ìŒì„± ë²ˆì—­ WebSocket ì—”ë“œí¬ì¸íŠ¸

    í´ë¼ì´ì–¸íŠ¸ì™€ WebSocket ì—°ê²°ì„ ë§ºê³  ì‹¤ì‹œê°„ìœ¼ë¡œ ìŒì„± ë²ˆì—­ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.

    í”„ë¡œí† ì½œ:
    1. í´ë¼ì´ì–¸íŠ¸ â†’ ì„œë²„ (JSON): {"selected_languages": ["ko-KR", "en-US", "ja-JP"], "project_id": "uuid" (ì„ íƒ)}
    2. í´ë¼ì´ì–¸íŠ¸ â†’ ì„œë²„ (Binary): ì˜¤ë””ì˜¤ ì²­í¬ (WebM/Opus, 16kHz, mono)
    3. ì„œë²„ â†’ í´ë¼ì´ì–¸íŠ¸ (JSON):
       - {"type": "recognizing", "text": "..."}
       - {"type": "recognized", "text": "...", "detected_language": "ko-KR", "translations": [...]}
       - {"type": "error", "error": "..."}
       - {"type": "end"}

    ì „ë¬¸ìš©ì–´ì‚¬ì „ ì ìš©:
    - project_idë¥¼ ì „ë‹¬í•˜ë©´ í•´ë‹¹ í”„ë¡œì íŠ¸ì— ì—°ê²°ëœ ë¬¸ì„œì˜ ìš©ì–´ì§‘ì„ í›„ì²˜ë¦¬ë¡œ ì ìš©í•©ë‹ˆë‹¤.
    - project_idê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ Azure Translator ë²ˆì—­ë§Œ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    """

    logger.info("ğŸŒ [WS-Backend] WebSocket ì—°ê²° ìš”ì²­ ë°›ìŒ")

    # WebSocket ì—°ê²° ìˆ˜ë½
    await websocket.accept()
    logger.info("âœ… [WS-Backend] WebSocket ì—°ê²° ìˆ˜ë½ ì™„ë£Œ")

    # ì„¸ì…˜ ID ìƒì„±
    session_id = str(uuid.uuid4())
    session: Optional[VoiceTranslationSession] = None

    # í™œì„± ì—°ê²° ë“±ë¡
    active_connections[session_id] = websocket

    logger.info(f"âœ… [WS-Backend] WebSocket ì—°ê²°ë¨: session_id={session_id}")

    try:
        # ë©”ì‹œì§€ ìˆ˜ì‹  ë£¨í”„
        while True:
            # í´ë¼ì´ì–¸íŠ¸ë¡œë¶€í„° ë©”ì‹œì§€ ìˆ˜ì‹ 
            message = await websocket.receive()

            # JSON ë©”ì‹œì§€ ì²˜ë¦¬ (ì„¸ì…˜ ì´ˆê¸°í™”)
            if "text" in message:
                logger.info(f"ğŸ“¥ [WS-Backend] JSON ë©”ì‹œì§€ ìˆ˜ì‹ : {message['text']}")
                try:
                    data = json.loads(message["text"])
                except json.JSONDecodeError as e:
                    logger.error(f"âŒ [WS-Backend] JSON íŒŒì‹± ì—ëŸ¬: {e}")
                    await send_standard_message(websocket, "error", error="ì˜ëª»ëœ JSON í˜•ì‹ì…ë‹ˆë‹¤")
                    continue

                # selected_languagesë¡œ ì„¸ì…˜ ì´ˆê¸°í™”
                if "selected_languages" in data:
                    selected_languages = data["selected_languages"]
                    project_id = data.get("project_id")  # í”„ë¡œì íŠ¸ ID (ì„ íƒ)
                    logger.info(f"ğŸ“ [WS-Backend] ì„¸ì…˜ ì´ˆê¸°í™” ìš”ì²­: {selected_languages}, project={project_id}")

                    # ì„¸ì…˜ ìƒì„± ë° ì´ˆê¸°í™” (í˜„ì¬ ì´ë²¤íŠ¸ ë£¨í”„ ì „ë‹¬ - SDK ì½œë°±ì˜ ìŠ¤ë ˆë“œ ì•ˆì „ì„± í™•ë³´)
                    loop = asyncio.get_event_loop()
                    session = VoiceTranslationSession(session_id, websocket, loop)
                    await session.initialize(selected_languages, project_id=project_id)

                    # ì„¸ì…˜ ì €ì¥
                    session_instances[session_id] = session
                    glossary_status = "âœ… ìš©ì–´ì§‘ í™œì„±í™”" if project_id else "âšª ìš©ì–´ì§‘ ë¯¸ì‚¬ìš©"
                    logger.info(f"âœ… [WS-Backend] ì„¸ì…˜ ì´ˆê¸°í™” ì™„ë£Œ: session_id={session_id}, {glossary_status}")

                # Heartbeat ping ì²˜ë¦¬ - pong ì‘ë‹µ
                elif data.get("type") == "ping":
                    logger.debug(f"ğŸ’“ [WS-Backend] Heartbeat ping ìˆ˜ì‹ : session_id={session_id}")
                    await send_standard_message(websocket, "pong")

                # ì¢…ë£Œ ë©”ì‹œì§€
                elif data.get("type") == "end":
                    logger.info(f"ğŸ”š í´ë¼ì´ì–¸íŠ¸ ì¢…ë£Œ ìš”ì²­: session_id={session_id}")
                    await send_standard_message(websocket, "end")
                    break

                else:
                    # ì•Œ ìˆ˜ ì—†ëŠ” ë©”ì‹œì§€ëŠ” ê²½ê³ ë§Œ ë¡œê·¸í•˜ê³  ë¬´ì‹œ (ì—°ê²° ìœ ì§€)
                    logger.warning(f"âš ï¸ [WS-Backend] ì•Œ ìˆ˜ ì—†ëŠ” ë©”ì‹œì§€ íƒ€ì…: {data}")

            # Binary ë©”ì‹œì§€ ì²˜ë¦¬ (ì˜¤ë””ì˜¤ ì²­í¬)
            elif "bytes" in message:
                audio_bytes = message["bytes"]

                if not session:
                    await send_standard_message(
                        websocket, "error",
                        error="ì„¸ì…˜ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. selected_languagesë¥¼ ë¨¼ì € ë³´ë‚´ì„¸ìš”"
                    )
                    continue

                if audio_bytes and len(audio_bytes) > 0:
                    # ì›ë³¸ ë°”ì´ë„ˆë¦¬ë¥¼ Azure Speech PushStreamì— ì „ì†¡
                    await session.process_audio_chunk(audio_bytes)

    except WebSocketDisconnect:
        logger.info(f"ğŸ”Œ WebSocket ì—°ê²° ì¢…ë£Œ: session_id={session_id}")

    except Exception as e:
        logger.error(f"âŒ WebSocket ì—ëŸ¬: session_id={session_id}, error={str(e)}", exc_info=True)
        try:
            await send_standard_message(websocket, "error", error=f"ì„œë²„ ì˜¤ë¥˜: {str(e)}")
        except:
            pass

    finally:
        # ì—°ê²° ì •ë¦¬
        if session_id in active_connections:
            del active_connections[session_id]

        if session_id in session_instances:
            session = session_instances[session_id]
            await session.cleanup()
            del session_instances[session_id]

        logger.info(f"ğŸ§¹ ì„¸ì…˜ ì •ë¦¬ ì™„ë£Œ: session_id={session_id}")


@router.get("/api/ai/voice/sessions")
async def get_active_sessions():
    """
    í˜„ì¬ í™œì„± ì„¸ì…˜ ëª©ë¡ ì¡°íšŒ (ê´€ë¦¬/ëª¨ë‹ˆí„°ë§ìš©)

    Returns:
        {
            "success": true,
            "data": {
                "active_sessions": 3,
                "sessions": [...]
            }
        }
    """
    sessions_info = []

    for session_id, session in session_instances.items():
        sessions_info.append(session.get_stats())

    return {
        "success": True,
        "data": {
            "active_sessions": len(active_connections),
            "sessions": sessions_info
        }
    }

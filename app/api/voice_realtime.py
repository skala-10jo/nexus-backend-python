"""
ì‹¤ì‹œê°„ ìŒì„± ì¸ì‹ WebSocket API (Azure Speech)

ì—”ë“œí¬ì¸íŠ¸:
- WS /api/ai/voice/realtime: ì‹¤ì‹œê°„ ìŒì„± ì¸ì‹ WebSocket ì—°ê²°

ìµœì í™”:
- ë‹¨ì¼ ì–¸ì–´ STT (ì–¸ì–´ ê°ì§€ ì—†ìŒ, ë¹ ë¥¸ ì‘ë‹µ)
- WebSocket ì••ì¶• (permessage-deflate)
- ë¹„ë™ê¸° ì²˜ë¦¬ (asyncio)
- ì—ëŸ¬ ì²˜ë¦¬ ê°•í™”
"""
from fastapi import APIRouter, WebSocket, WebSocketDisconnect
from typing import Dict, Optional
import json
import uuid
import logging
import time
import asyncio

from app.services.voice_translation_service import VoiceTranslationService
import azure.cognitiveservices.speech as speechsdk

# ë¡œê±° ì„¤ì •
logger = logging.getLogger(__name__)

# ë¼ìš°í„° ìƒì„±
router = APIRouter()

# í™œì„± WebSocket ì—°ê²° ê´€ë¦¬
active_connections: Dict[str, WebSocket] = {}

# ì„¸ì…˜ë³„ Session ì¸ìŠ¤í„´ìŠ¤ ê´€ë¦¬
session_instances: Dict[str, 'VoiceRealtimeSession'] = {}


# ============================================================
# í‘œì¤€ WebSocket ë©”ì‹œì§€ í”„ë¡œí† ì½œ ë˜í¼
# ============================================================
async def send_standard_message(websocket: WebSocket, message_type: str, **kwargs):
    """
    í‘œì¤€ WebSocket ë©”ì‹œì§€ ì „ì†¡ ë˜í¼ í•¨ìˆ˜

    ì˜¤ì§ 4ê°€ì§€ ë©”ì‹œì§€ íƒ€ì…ë§Œ í—ˆìš©:
    - recognizing: ì¤‘ê°„ ì¸ì‹ ê²°ê³¼
    - recognized: ìµœì¢… ì¸ì‹ ê²°ê³¼ + ë²ˆì—­
    - error: ì—ëŸ¬ ë©”ì‹œì§€
    - end: ì—°ê²° ì¢…ë£Œ

    Args:
        websocket: WebSocket ì—°ê²°
        message_type: ë©”ì‹œì§€ íƒ€ì… (recognizing, recognized, error, endë§Œ í—ˆìš©)
        **kwargs: ë©”ì‹œì§€ ë°ì´í„°
    """
    ALLOWED_TYPES = {"recognizing", "recognized", "error", "end"}

    if message_type not in ALLOWED_TYPES:
        logger.warning(f"âš ï¸ ë¹„í‘œì¤€ ë©”ì‹œì§€ ì°¨ë‹¨: type={message_type}")
        return

    message = {"type": message_type, **kwargs}
    await websocket.send_json(message)
    logger.debug(f"ğŸ“¤ í‘œì¤€ ë©”ì‹œì§€ ì „ì†¡: type={message_type}, keys={list(kwargs.keys())}")


class VoiceRealtimeSession:
    """ì‹¤ì‹œê°„ ìŒì„± ì¸ì‹ ì„¸ì…˜ ê´€ë¦¬ (ë‹¨ì¼ ì–¸ì–´ STT)"""

    def __init__(self, session_id: str, websocket: WebSocket, loop: asyncio.AbstractEventLoop):
        self.session_id = session_id
        self.websocket = websocket
        self.loop = loop  # ë©”ì¸ ì´ë²¤íŠ¸ ë£¨í”„ ì €ì¥ (ìŠ¤ë ˆë“œ ê°„ ë¹„ë™ê¸° í˜¸ì¶œìš©)

        # Service ì´ˆê¸°í™” (AI Agent ì•„í‚¤í…ì²˜ ê°€ì´ë“œ ì¤€ìˆ˜: API â†’ Service â†’ Agent)
        self.service = VoiceTranslationService()

        # Azure Speech ë¦¬ì†ŒìŠ¤
        self.recognizer: Optional[speechsdk.SpeechRecognizer] = None
        self.push_stream: Optional[speechsdk.audio.PushAudioInputStream] = None

        # ì„¸ì…˜ ì„¤ì •
        self.language: str = "en-US"  # ì¸ì‹ ì–¸ì–´ (BCP-47)

        # í†µê³„
        self.processed_chunks = 0
        self.start_time = time.time()

        logger.info(f"âœ… VoiceRealtimeSession ìƒì„±: session_id={session_id}")

    async def initialize(self, language: str):
        """
        ì„¸ì…˜ ì´ˆê¸°í™” ë° Azure Speech ë‹¨ì¼ ì–¸ì–´ ì„¤ì •

        Args:
            language: ì¸ì‹ ì–¸ì–´ (BCP-47 ì½”ë“œ, ì˜ˆ: "en-US")
        """
        if not language:
            await send_standard_message(
                self.websocket, "error",
                error="ì–¸ì–´ê°€ ì§€ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤"
            )
            return

        self.language = language

        try:
            # Azure Speech ë‹¨ì¼ ì–¸ì–´ ìŠ¤íŠ¸ë¦¼ ìƒì„± (Serviceë¥¼ í†µí•´ Agent í˜¸ì¶œ)
            logger.info(f"ğŸ”§ Azure Speech ë‹¨ì¼ ì–¸ì–´ ì„¤ì •: {language}")
            self.recognizer, self.push_stream = await self.service.setup_stream_single_language(
                language=language
            )

            # ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ ë“±ë¡ (í•„ìˆ˜ í•¸ë“¤ëŸ¬ë§Œ)
            self.recognizer.recognizing.connect(self._on_recognizing)
            self.recognizer.recognized.connect(self._on_recognized)
            self.recognizer.canceled.connect(self._on_canceled)

            # ì—°ì† ì¸ì‹ ì‹œì‘ (ë¹„ë™ê¸°)
            logger.info(f"ğŸš€ Starting continuous recognition for session: {self.session_id}")
            self.recognizer.start_continuous_recognition_async()
            logger.info(f"âœ… Continuous recognition started for session: {self.session_id}")

        except Exception as e:
            logger.error(f"âŒ ì„¸ì…˜ ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}", exc_info=True)
            await send_standard_message(
                self.websocket, "error",
                error=f"ì„¸ì…˜ ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}"
            )

    def _on_recognizing(self, evt: speechsdk.SpeechRecognitionEventArgs):
        """ì¤‘ê°„ ì¸ì‹ ê²°ê³¼ í•¸ë“¤ëŸ¬ (recognizing)"""
        logger.info(f"ğŸ¤ [Recognizing] reason={evt.result.reason}, text='{evt.result.text}'")
        if evt.result.reason == speechsdk.ResultReason.RecognizingSpeech:
            text = evt.result.text
            if text and text.strip():

                # ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ ë©”ì¸ ì´ë²¤íŠ¸ ë£¨í”„ë¡œ ì½”ë£¨í‹´ ìŠ¤ì¼€ì¤„ë§
                asyncio.run_coroutine_threadsafe(
                    send_standard_message(
                        self.websocket,
                        "recognizing",
                        text=text
                    ),
                    self.loop
                )

    def _on_recognized(self, evt: speechsdk.SpeechRecognitionEventArgs):
        """ìµœì¢… ì¸ì‹ ê²°ê³¼ í•¸ë“¤ëŸ¬ (recognized)"""
        # NoMatchëŠ” ë¬´ì‹œ (ìŒì„±ì´ ê°ì§€ë˜ì§€ ì•Šì€ ê²½ìš°)
        if evt.result.reason == speechsdk.ResultReason.NoMatch:
            logger.debug(f"âšª [NoMatch] ìŒì„± ê°ì§€ ì•ˆë¨")
            return
        logger.info(f"âœ… [Recognized] reason={evt.result.reason}, text='{evt.result.text}'")
        if evt.result.reason == speechsdk.ResultReason.RecognizedSpeech:
            text = evt.result.text

            if not text or not text.strip():
                return

            # ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ ë©”ì¸ ì´ë²¤íŠ¸ ë£¨í”„ë¡œ ì½”ë£¨í‹´ ìŠ¤ì¼€ì¤„ë§
            # ë²ˆì—­ ì—†ì´ ë°”ë¡œ recognized ë©”ì‹œì§€ ì „ì†¡
            asyncio.run_coroutine_threadsafe(
                send_standard_message(
                    self.websocket, "recognized",
                    text=text
                ),
                self.loop
            )

    def _on_canceled(self, evt: speechsdk.SpeechRecognitionCanceledEventArgs):
        """ì¸ì‹ ì·¨ì†Œ/ì—ëŸ¬ í•¸ë“¤ëŸ¬"""
        try:
            cancellation = getattr(evt, 'cancellation_details', None)
            if cancellation:
                cancel_reason = getattr(cancellation, 'reason', 'Unknown')
                if cancel_reason == speechsdk.CancellationReason.EndOfStream:
                    return  # ì •ìƒ ì¢…ë£Œ

                error_details = getattr(cancellation, 'error_details', '')
                if error_details:
                    asyncio.run_coroutine_threadsafe(
                        send_standard_message(
                            self.websocket, "error",
                            error=f"ìŒì„± ì¸ì‹ ì˜¤ë¥˜: {error_details}"
                        ),
                        self.loop
                    )
        except Exception as e:
            logger.error(f"_on_canceled error: {str(e)}")

    async def process_audio_chunk(self, audio_bytes: bytes):
        """
        ì˜¤ë””ì˜¤ ì²­í¬ë¥¼ Azure Speech PushStreamì— ì „ì†¡

        Args:
            audio_bytes: PCM 16kHz 16bit Mono ì˜¤ë””ì˜¤ ë°ì´í„°
        """
        if not self.push_stream:
            logger.warning("âš ï¸ PushStreamì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
            return

        if not audio_bytes or len(audio_bytes) == 0:
            logger.debug("âšª ë¹ˆ ì˜¤ë””ì˜¤ ì²­í¬ ë¬´ì‹œ")
            return

        try:
            # Azure Speech PushStreamì— PCM ë°”ì´ë„ˆë¦¬ ì“°ê¸°
            self.push_stream.write(audio_bytes)
            self.processed_chunks += 1

            # ì²« 5ê°œ ì²­í¬ë§Œ ë¡œê·¸ ì¶œë ¥ (ë””ë²„ê¹…ìš©)
            if self.processed_chunks <= 5:
                logger.info(f"ğŸ“¤ ì˜¤ë””ì˜¤ ì²­í¬ #{self.processed_chunks}: {len(audio_bytes)} bytes")

        except Exception as e:
            logger.error(f"âŒ ì˜¤ë””ì˜¤ ì²­í¬ ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}", exc_info=True)
            await send_standard_message(
                self.websocket, "error",
                error=f"ì˜¤ë””ì˜¤ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
            )

    async def cleanup(self):
        """ì„¸ì…˜ ì •ë¦¬ (Azure Speech ë¦¬ì†ŒìŠ¤ í•´ì œ)"""
        try:
            if self.recognizer:
                self.recognizer.stop_continuous_recognition()
                logger.info(f"ğŸ›‘ Azure Speech ì—°ì† ì¸ì‹ ì¤‘ì§€: session_id={self.session_id}")

            if self.push_stream:
                self.push_stream.close()
                logger.info(f"ğŸ”’ PushStream ë‹«í˜: session_id={self.session_id}")

        except Exception as e:
            logger.error(f"âŒ ì„¸ì…˜ ì •ë¦¬ ì‹¤íŒ¨: {str(e)}", exc_info=True)

    def get_stats(self) -> Dict:
        """ì„¸ì…˜ í†µê³„ ë°˜í™˜"""
        elapsed_time = time.time() - self.start_time
        return {
            "session_id": self.session_id,
            "elapsed_time": round(elapsed_time, 2),
            "processed_chunks": self.processed_chunks,
            "language": self.language
        }


@router.websocket("/api/ai/voice/realtime")
async def voice_realtime_websocket(websocket: WebSocket):
    """
    ì‹¤ì‹œê°„ ìŒì„± ì¸ì‹ WebSocket ì—”ë“œí¬ì¸íŠ¸ (ë‹¨ì¼ ì–¸ì–´)

    í´ë¼ì´ì–¸íŠ¸ì™€ WebSocket ì—°ê²°ì„ ë§ºê³  ì‹¤ì‹œê°„ìœ¼ë¡œ ìŒì„± ì¸ì‹ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.

    í”„ë¡œí† ì½œ:
    1. í´ë¼ì´ì–¸íŠ¸ â†’ ì„œë²„ (JSON): {"language": "en-US"}
    2. í´ë¼ì´ì–¸íŠ¸ â†’ ì„œë²„ (Binary): ì˜¤ë””ì˜¤ ì²­í¬ (PCM, 16kHz, mono)
    3. ì„œë²„ â†’ í´ë¼ì´ì–¸íŠ¸ (JSON):
       - {"type": "recognizing", "text": "..."}
       - {"type": "recognized", "text": "..."}
       - {"type": "error", "error": "..."}
       - {"type": "end"}
    """

    logger.info("ğŸŒ [WS-Backend] WebSocket ì—°ê²° ìš”ì²­ ë°›ìŒ")

    # WebSocket ì—°ê²° ìˆ˜ë½
    await websocket.accept()
    logger.info("âœ… [WS-Backend] WebSocket ì—°ê²° ìˆ˜ë½ ì™„ë£Œ")

    # ì„¸ì…˜ ID ìƒì„±
    session_id = str(uuid.uuid4())
    session: Optional[VoiceRealtimeSession] = None

    # í™œì„± ì—°ê²° ë“±ë¡
    active_connections[session_id] = websocket

    logger.info(f"âœ… [WS-Backend] WebSocket ì—°ê²°ë¨: session_id={session_id}")

    try:
        # ë©”ì‹œì§€ ìˆ˜ì‹  ë£¨í”„
        while True:
            # í´ë¼ì´ì–¸íŠ¸ë¡œë¶€í„° ë©”ì‹œì§€ ìˆ˜ì‹ 
            message = await websocket.receive()

            # JSON ë©”ì‹œì§€ ì²˜ë¦¬ (ì„¸ì…˜ ì´ˆê¸°í™”)
            if "text" in message:
                logger.info(f"ğŸ“¥ [WS-Backend] JSON ë©”ì‹œì§€ ìˆ˜ì‹ : {message['text']}")
                try:
                    data = json.loads(message["text"])
                except json.JSONDecodeError as e:
                    logger.error(f"âŒ [WS-Backend] JSON íŒŒì‹± ì—ëŸ¬: {e}")
                    await send_standard_message(websocket, "error", error="ì˜ëª»ëœ JSON í˜•ì‹ì…ë‹ˆë‹¤")
                    continue

                # languageë¡œ ì„¸ì…˜ ì´ˆê¸°í™” (ë‹¨ì¼ ì–¸ì–´)
                if "language" in data:
                    language = data["language"]
                    logger.info(f"ğŸ“ [WS-Backend] ì„¸ì…˜ ì´ˆê¸°í™” ìš”ì²­: {language}")

                    # ì„¸ì…˜ ìƒì„± ë° ì´ˆê¸°í™” (í˜„ì¬ ì´ë²¤íŠ¸ ë£¨í”„ ì „ë‹¬ - SDK ì½œë°±ì˜ ìŠ¤ë ˆë“œ ì•ˆì „ì„± í™•ë³´)
                    loop = asyncio.get_event_loop()
                    session = VoiceRealtimeSession(session_id, websocket, loop)
                    await session.initialize(language)

                    # ì„¸ì…˜ ì €ì¥
                    session_instances[session_id] = session
                    logger.info(f"âœ… [WS-Backend] ì„¸ì…˜ ì´ˆê¸°í™” ì™„ë£Œ: session_id={session_id}")

                # ì¢…ë£Œ ë©”ì‹œì§€
                elif data.get("type") == "end":
                    logger.info(f"ğŸ”š í´ë¼ì´ì–¸íŠ¸ ì¢…ë£Œ ìš”ì²­: session_id={session_id}")
                    await send_standard_message(websocket, "end")
                    break

                else:
                    await send_standard_message(
                        websocket, "error",
                        error=f"ì•Œ ìˆ˜ ì—†ëŠ” ë©”ì‹œì§€: {data}"
                    )

            # Binary ë©”ì‹œì§€ ì²˜ë¦¬ (ì˜¤ë””ì˜¤ ì²­í¬)
            elif "bytes" in message:
                audio_bytes = message["bytes"]

                if not session:
                    await send_standard_message(
                        websocket, "error",
                        error="ì„¸ì…˜ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. languageë¥¼ ë¨¼ì € ë³´ë‚´ì„¸ìš”"
                    )
                    continue

                if audio_bytes and len(audio_bytes) > 0:
                    # ì›ë³¸ ë°”ì´ë„ˆë¦¬ë¥¼ Azure Speech PushStreamì— ì „ì†¡
                    await session.process_audio_chunk(audio_bytes)

    except WebSocketDisconnect:
        logger.info(f"ğŸ”Œ WebSocket ì—°ê²° ì¢…ë£Œ: session_id={session_id}")

    except Exception as e:
        logger.error(f"âŒ WebSocket ì—ëŸ¬: session_id={session_id}, error={str(e)}", exc_info=True)
        try:
            await send_standard_message(websocket, "error", error=f"ì„œë²„ ì˜¤ë¥˜: {str(e)}")
        except:
            pass

    finally:
        # ì—°ê²° ì •ë¦¬
        if session_id in active_connections:
            del active_connections[session_id]

        if session_id in session_instances:
            session = session_instances[session_id]
            await session.cleanup()
            del session_instances[session_id]

        logger.info(f"ğŸ§¹ ì„¸ì…˜ ì •ë¦¬ ì™„ë£Œ: session_id={session_id}")


@router.get("/api/ai/voice/sessions")
async def get_active_sessions():
    """
    í˜„ì¬ í™œì„± ì„¸ì…˜ ëª©ë¡ ì¡°íšŒ (ê´€ë¦¬/ëª¨ë‹ˆí„°ë§ìš©)

    Returns:
        {
            "success": true,
            "data": {
                "active_sessions": 3,
                "sessions": [...]
            }
        }
    """
    sessions_info = []

    for session_id, session in session_instances.items():
        sessions_info.append(session.get_stats())

    return {
        "success": True,
        "data": {
            "active_sessions": len(active_connections),
            "sessions": sessions_info
        }
    }

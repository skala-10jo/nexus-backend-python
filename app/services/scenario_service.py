"""
Scenario generation service with OpenAI GPT-4o integration.
Generates conversation scenarios from projects and schedules.
"""
import logging
from typing import List, Dict, Any, Optional
from openai import AsyncOpenAI
import httpx
import json

from app.config import settings
from app.models.scenario import Scenario
from sqlalchemy.orm import Session

logger = logging.getLogger(__name__)


class ScenarioService:
    """Service for generating and managing conversation scenarios."""

    def __init__(self):
        """Initialize OpenAI client."""
        self.client = AsyncOpenAI(api_key=settings.OPENAI_API_KEY)

    async def generate_from_projects(
        self,
        project_ids: List[str],
        schedule_ids: List[str],
        document_ids: List[str],
        language: str,
        difficulty: str,
        count: int,
        user_id: str,
        jwt_token: str,
        db: Session
    ) -> List[Dict[str, Any]]:
        """
        Generate scenarios from projects and schedules using GPT-4o.

        Args:
            project_ids: List of project UUIDs
            schedule_ids: List of schedule UUIDs
            document_ids: List of document UUIDs
            language: Target language (en, ko, zh, ja)
            difficulty: Difficulty level (beginner, intermediate, advanced)
            count: Number of scenarios to generate
            user_id: User UUID
            jwt_token: JWT token for Java API calls
            db: Database session

        Returns:
            List of generated scenario dictionaries
        """
        logger.info(f"ğŸš€ Starting scenario generation: user={user_id}, projects={len(project_ids)}, schedules={len(schedule_ids)}, documents={len(document_ids)}")

        # 1. Fetch context from Java backend
        context = await self._fetch_context(project_ids, schedule_ids, document_ids, jwt_token)
        logger.info(f"ğŸ“ Context fetched: {len(context)} characters")

        # 2. Generate scenarios with GPT-4o
        scenarios_data = await self._generate_with_gpt(context, language, difficulty, count)
        logger.info(f"ğŸ¤– GPT-4o generated {len(scenarios_data)} scenarios")

        # 3. Save to PostgreSQL
        saved_scenarios = []
        for idx, scenario_data in enumerate(scenarios_data):
            try:
                scenario = Scenario(
                    user_id=user_id,
                    title=scenario_data["title"],
                    description=scenario_data["description"],
                    scenario_text=scenario_data["scenarioText"],
                    language=language,
                    difficulty=difficulty,
                    category=scenario_data["category"],
                    roles=scenario_data["roles"],
                    required_terminology=scenario_data.get("requiredTerminology", []),
                    project_ids=project_ids,
                    schedule_ids=schedule_ids,
                    document_ids=document_ids,
                    auto_generated=True
                )
                db.add(scenario)
                db.flush()

                saved_scenarios.append({
                    "id": str(scenario.id),
                    "title": scenario.title,
                    "description": scenario.description,
                    "scenarioText": scenario.scenario_text,
                    "language": scenario.language,
                    "difficulty": scenario.difficulty,
                    "category": scenario.category,
                    "roles": scenario.roles,
                    "requiredTerminology": scenario.required_terminology,
                    "autoGenerated": scenario.auto_generated,
                    "createdAt": scenario.created_at.isoformat()
                })

                logger.info(f"ğŸ’¾ Saved scenario {idx + 1}/{len(scenarios_data)}: {scenario.title}")

            except Exception as e:
                logger.error(f"âŒ Failed to save scenario {idx + 1}: {str(e)}")
                continue

        db.commit()
        logger.info(f"âœ… Successfully saved {len(saved_scenarios)}/{len(scenarios_data)} scenarios")

        return saved_scenarios

    async def _fetch_context(
        self,
        project_ids: List[str],
        schedule_ids: List[str],
        document_ids: List[str],
        jwt_token: str
    ) -> str:
        """
        Fetch context from Java backend (projects, schedules, and documents).

        Args:
            project_ids: List of project UUIDs
            schedule_ids: List of schedule UUIDs
            document_ids: List of document UUIDs
            jwt_token: JWT token for authentication

        Returns:
            Combined context string
        """
        headers = {"Authorization": f"Bearer {jwt_token}"}
        context_parts = []

        async with httpx.AsyncClient() as client:
            # Fetch project information
            for pid in project_ids:
                try:
                    response = await client.get(
                        f"http://localhost:3000/api/projects/{pid}",
                        headers=headers,
                        timeout=10.0
                    )
                    if response.status_code == 200:
                        project = response.json()
                        context_parts.append(
                            f"Project: {project.get('name', '')}\n"
                            f"Description: {project.get('description', '')}"
                        )
                        logger.info(f"âœ… Fetched project: {project.get('name', '')}")
                    else:
                        logger.warning(f"âš ï¸  Failed to fetch project {pid}: status {response.status_code}")
                except Exception as e:
                    logger.warning(f"âš ï¸  Failed to fetch project {pid}: {str(e)}")

            # Fetch schedule information
            for sid in schedule_ids:
                try:
                    response = await client.get(
                        f"http://localhost:3000/api/schedules/{sid}",
                        headers=headers,
                        timeout=10.0
                    )
                    if response.status_code == 200:
                        schedule_data = response.json()
                        schedule = schedule_data.get('data', {})
                        context_parts.append(
                            f"Schedule: {schedule.get('title', '')}\n"
                            f"Description: {schedule.get('description', '')}\n"
                            f"Location: {schedule.get('location', 'N/A')}"
                        )
                        logger.info(f"âœ… Fetched schedule: {schedule.get('title', '')}")
                    else:
                        logger.warning(f"âš ï¸  Failed to fetch schedule {sid}: status {response.status_code}")
                except Exception as e:
                    logger.warning(f"âš ï¸  Failed to fetch schedule {sid}: {str(e)}")

            # Fetch document contents
            for doc_id in document_ids:
                try:
                    response = await client.get(
                        f"http://localhost:3000/api/documents/{doc_id}",
                        headers=headers,
                        timeout=10.0
                    )
                    if response.status_code == 200:
                        doc_data = response.json()
                        document = doc_data.get('data', {})

                        # Extract page contents (limit to first 5 pages, 500 chars per page)
                        contents = document.get('contents', [])[:5]
                        if contents:
                            text_parts = []
                            for content in contents:
                                page_text = content.get('content', '')[:500]
                                if page_text:
                                    text_parts.append(f"Page {content.get('pageNumber', '?')}: {page_text}")

                            if text_parts:
                                context_parts.append(
                                    f"Document: {document.get('originalFilename', '')}\n"
                                    + "\n".join(text_parts)
                                )
                                logger.info(f"âœ… Fetched document: {document.get('originalFilename', '')} ({len(contents)} pages)")
                        else:
                            logger.warning(f"âš ï¸  Document {doc_id} has no content")
                    else:
                        logger.warning(f"âš ï¸  Failed to fetch document {doc_id}: status {response.status_code}")
                except Exception as e:
                    logger.warning(f"âš ï¸  Failed to fetch document {doc_id}: {str(e)}")

        # Fallback to general context if no data fetched
        if not context_parts:
            logger.warning("âš ï¸  No context fetched, using general business scenarios")
            return "General business communication scenarios for professional practice."

        return "\n\n".join(context_parts)

    async def _generate_with_gpt(
        self,
        context: str,
        language: str,
        difficulty: str,
        count: int
    ) -> List[Dict[str, Any]]:
        """
        Generate scenarios using GPT-4o.

        Args:
            context: Context from projects/schedules
            language: Target language
            difficulty: Difficulty level
            count: Number of scenarios to generate

        Returns:
            List of scenario dictionaries
        """
        # Language mapping
        lang_map = {
            "en": "English",
            "ko": "Korean (í•œêµ­ì–´)",
            "zh": "Chinese (ä¸­æ–‡)",
            "ja": "Japanese (æ—¥æœ¬èª)",
            "vi": "Vietnamese (Tiáº¿ng Viá»‡t)"
        }
        target_lang = lang_map.get(language, "English")

        # Check if this is everyday scenario (no project selected)
        is_everyday_scenario = context == "General business communication scenarios for professional practice."

        if is_everyday_scenario:
            # Everyday conversation scenarios
            prompt = f"""ë‹¤ìŒì€ ì¼ìƒìƒí™œì—ì„œ ìì£¼ ì ‘í•˜ëŠ” {count}ê°œì˜ ì‹¤ìš©ì ì¸ íšŒí™” ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.
ì´ ì‹œë‚˜ë¦¬ì˜¤ëŠ” {target_lang} ì–¸ì–´ ì—°ìŠµì„ ìœ„í•œ ê²ƒì…ë‹ˆë‹¤.

ì‹œë‚˜ë¦¬ì˜¤ íƒ€ì… (ë‹¤ì–‘í•˜ê²Œ ì„ íƒ):
- ì‹ë‹¹ì—ì„œì˜ ëŒ€í™” (ì£¼ë¬¸, ì˜ˆì•½, ë¶ˆë§Œ ì²˜ë¦¬)
- í˜¸í…” ì²´í¬ì¸/ì²´í¬ì•„ì›ƒ
- ì‡¼í•‘ (ì˜·, ì „ìì œí’ˆ, ì‹ë£Œí’ˆ)
- ë³‘ì›/ì•½êµ­ ë°©ë¬¸
- ì€í–‰ ì—…ë¬´
- ìš°ì²´êµ­/íƒë°°
- ì¹´í˜ì—ì„œ ì£¼ë¬¸
- êµí†µ ìˆ˜ë‹¨ ì´ìš© (íƒì‹œ, ì§€í•˜ì² , ë²„ìŠ¤)
- í—¬ìŠ¤ì¥/í”¼íŠ¸ë‹ˆìŠ¤ ì„¼í„°
- ë¯¸ìš©ì‹¤/í—¤ì–´ìƒµ
- ë¶€ë™ì‚° ë¬¸ì˜
- ë Œí„°ì¹´ ëŒ€ì—¬

ìš”êµ¬ì‚¬í•­:
- ë‚œì´ë„: {difficulty}
- ëª©í‘œ ì–¸ì–´: {target_lang}
- ê° ì‹œë‚˜ë¦¬ì˜¤ëŠ” ì¼ìƒìƒí™œì—ì„œ ì‹¤ì œë¡œ ê²ªì„ ìˆ˜ ìˆëŠ” ìƒí™©ì„ ë°˜ì˜
- í•´ë‹¹ ìƒí™©ì—ì„œ ìì£¼ ì‚¬ìš©í•˜ëŠ” 3-5ê°œì˜ ì‹¤ìš©ì ì¸ í‘œí˜„ì´ë‚˜ ì–´íœ˜ë¥¼ í¬í•¨
- ë‹¤ì–‘í•œ ì¼ìƒ ìƒí™©ì„ ë‹¤ë£¨ì„¸ìš”
- ì œëª©ê³¼ ì„¤ëª…ì€ ë°˜ë“œì‹œ í•œê¸€ë¡œ ì‘ì„±
- ì—­í•  ì„¤ëª…ì€ ê°„ë‹¨í•˜ê³  ê°„ê²°í•˜ê²Œ (1-2 ë‹¨ì–´)

ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ìƒì„±í•˜ì„¸ìš”:
{{
  "scenarios": [
    {{
      "title": "í•œê¸€ë¡œ ëœ ì‹œë‚˜ë¦¬ì˜¤ ì œëª© (ì˜ˆ: ì‹ë‹¹ì—ì„œ ìŒì‹ ì£¼ë¬¸í•˜ê¸°, í˜¸í…” ì²´í¬ì¸í•˜ê¸°)",
      "description": "í•œê¸€ë¡œ ëœ ê°„ë‹¨í•œ ì„¤ëª… (2-3 ë¬¸ì¥). ì–´ë–¤ ìƒí™©ì¸ì§€ ëª…í™•í•˜ê²Œ ì„¤ëª…",
      "scenarioText": "ê°œì¡°ì‹ìœ¼ë¡œ ì‘ì„±ëœ ìƒì„¸í•œ ì‹œë‚˜ë¦¬ì˜¤ ì„¤ëª… (í•œê¸€). ê° í•­ëª©ì„ '-'ë¡œ ì‹œì‘í•˜ì—¬ ì¤„ë°”ê¿ˆìœ¼ë¡œ êµ¬ë¶„í•©ë‹ˆë‹¤.",
      "category": "Restaurant|Hotel|Shopping|Hospital|Bank|Post Office|Cafe|Transportation|Fitness|Beauty|Real Estate|Car Rental|Daily Life",
      "roles": {{
        "user": "{target_lang}ë¡œ ëœ ê°„ë‹¨í•œ ì‚¬ìš©ì ì—­í•  (ì˜ˆ: Customer, Patient, Guest ë“±)",
        "ai": "{target_lang}ë¡œ ëœ ê°„ë‹¨í•œ ìƒëŒ€ë°© ì—­í•  (ì˜ˆ: Waiter, Receptionist, Sales Clerk ë“±)"
      }},
      "requiredTerminology": ["í•´ë‹¹ ìƒí™©ì—ì„œ ìœ ìš©í•œ í‘œí˜„1", "í‘œí˜„2", "í‘œí˜„3"]
    }}
  ]
}}

ì¤‘ìš” ì‚¬í•­:
- title: ë°˜ë“œì‹œ í•œê¸€ë¡œ ì‘ì„± (ì¼ìƒ ìƒí™© ëª…í™•íˆ í‘œí˜„)
- description: ë°˜ë“œì‹œ í•œê¸€ë¡œ ì‘ì„±
- scenarioText: ë°˜ë“œì‹œ ê°œì¡°ì‹ìœ¼ë¡œ ì‘ì„± (ê° í•­ëª©ì€ '-'ë¡œ ì‹œì‘í•˜ê³  ì¤„ë°”ê¿ˆìœ¼ë¡œ êµ¬ë¶„)
  ì˜ˆì‹œ í˜•ì‹:
  "scenarioText": "- ìƒí™©: í•´ì™¸ í˜¸í…”ì—ì„œ ì²´í¬ì¸í•˜ëŠ” ìƒí™©ì…ë‹ˆë‹¤\\n- ëª©í‘œ: ì˜ˆì•½ í™•ì¸, ë°© ë°°ì •, ì‹œì„¤ ì´ìš© ì•ˆë‚´ë¥¼ {target_lang}ë¡œ ëŒ€í™”í•©ë‹ˆë‹¤\\n- ì—°ìŠµ ë‚´ìš©: ì˜ˆì•½ ì •ë³´ í™•ì¸, ì—¬ê¶Œ ì œì‹œ, ê²°ì œ ë°©ë²• ì„¤ëª…\\n- ì£¼ìš” í‘œí˜„: 'reservation confirmation', 'check-in', 'amenities'\\n- ë‚œì´ë„: {difficulty} ìˆ˜ì¤€ì— ë§ëŠ” í‘œí˜„ ì‚¬ìš©"
- category: ì¼ìƒ ìƒí™œ ì¹´í…Œê³ ë¦¬ ì‚¬ìš© (ë¹„ì¦ˆë‹ˆìŠ¤ ê´€ë ¨ ì¹´í…Œê³ ë¦¬ ì‚¬ìš© ê¸ˆì§€)
- roles.user: {target_lang}ë¡œ ëœ ê°„ë‹¨í•œ ì—­í•  (ì˜ˆ: "Customer", "Patient", "ì†ë‹˜", "í™˜ì")
- roles.ai: {target_lang}ë¡œ ëœ ê°„ë‹¨í•œ ì„œë¹„ìŠ¤ ì œê³µì ì—­í•  (ì˜ˆ: "Waiter", "Doctor", "ì›¨ì´í„°", "ì˜ì‚¬") - "AI"ë‚˜ "Assistant" ì‚¬ìš© ê¸ˆì§€
- requiredTerminology: í•´ë‹¹ ìƒí™©ì—ì„œ ì‹¤ì œë¡œ ì‚¬ìš©í•˜ëŠ” ìœ ìš©í•œ í‘œí˜„ì´ë‚˜ ì–´íœ˜

ì •í™•íˆ {count}ê°œì˜ ì¼ìƒ íšŒí™” ì‹œë‚˜ë¦¬ì˜¤ë¥¼ "scenarios" ë°°ì—´ì— ìƒì„±í•˜ì„¸ìš”."""

            system_content = f"ë‹¹ì‹ ì€ ì¼ìƒìƒí™œ íšŒí™” ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ë§Œë“œëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤. {target_lang} ì–¸ì–´ ì—°ìŠµì— ì í•©í•œ ì‹¤ìš©ì ì´ê³  í˜„ì‹¤ì ì¸ ì¼ìƒ ëŒ€í™” ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤. ì œëª©, ì„¤ëª…, ì‹œë‚˜ë¦¬ì˜¤ í…ìŠ¤íŠ¸ëŠ” í•­ìƒ í•œê¸€ë¡œ ì‘ì„±í•˜ê³ , ì—­í•  ì„¤ëª…ì€ ê°„ë‹¨í•˜ê²Œ (1-2 ë‹¨ì–´) ì‘ì„±í•©ë‹ˆë‹¤. 'ai' ì—­í• ì€ 'ì›¨ì´í„°', 'ì§ì›', 'ì˜ì‚¬' ê°™ì€ í˜„ì‹¤ì ì¸ ì„œë¹„ìŠ¤ ì œê³µì ì—­í• ì„ ì‚¬ìš©í•˜ë©°, ì ˆëŒ€ 'AI'ë‚˜ 'Assistant'ë¥¼ ì‚¬ìš©í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ë¹„ì¦ˆë‹ˆìŠ¤ë‚˜ ì—…ë¬´ ê´€ë ¨ ì‹œë‚˜ë¦¬ì˜¤ëŠ” ìƒì„±í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."

        else:
            # Business scenarios with project context
            prompt = f"""ë‹¤ìŒ ì»¨í…ìŠ¤íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ {count}ê°œì˜ í˜„ì‹¤ì ì¸ ë¹„ì¦ˆë‹ˆìŠ¤ íšŒí™” ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.
ì´ ì‹œë‚˜ë¦¬ì˜¤ëŠ” {target_lang} ì–¸ì–´ ì—°ìŠµì„ ìœ„í•œ ê²ƒì…ë‹ˆë‹¤.

ì»¨í…ìŠ¤íŠ¸:
{context[:3000]}

ìš”êµ¬ì‚¬í•­:
- ë‚œì´ë„: {difficulty}
- ëª©í‘œ ì–¸ì–´: {target_lang}
- ê° ì‹œë‚˜ë¦¬ì˜¤ëŠ” í˜„ì‹¤ì ì¸ ë¹„ì¦ˆë‹ˆìŠ¤ ìƒí™©ì„ ë°˜ì˜í•´ì•¼ í•©ë‹ˆë‹¤
- ì»¨í…ìŠ¤íŠ¸ì—ì„œ 3-5ê°œì˜ í•µì‹¬ ì „ë¬¸ ìš©ì–´ë¥¼ ì‹ë³„í•˜ì„¸ìš”
- ë‹¤ì–‘í•œ ì‹œë‚˜ë¦¬ì˜¤ íƒ€ì… ì‚¬ìš©: Collaboration, Technical Support, Product Explanation, Problem Solving
- ì œëª©ê³¼ ì„¤ëª…ì€ ë°˜ë“œì‹œ í•œê¸€ë¡œ ì‘ì„±
- ì—­í•  ì„¤ëª…ì€ ê°„ë‹¨í•˜ê³  ê°„ê²°í•˜ê²Œ (1-2 ë‹¨ì–´)

ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ìƒì„±í•˜ì„¸ìš”:
{{
  "scenarios": [
    {{
      "title": "í•œê¸€ë¡œ ëœ ì‹œë‚˜ë¦¬ì˜¤ ì œëª©",
      "description": "í•œê¸€ë¡œ ëœ ê°„ë‹¨í•œ ì„¤ëª… (2-3 ë¬¸ì¥)",
      "scenarioText": "ê°œì¡°ì‹ìœ¼ë¡œ ì‘ì„±ëœ ìƒì„¸í•œ ì‹œë‚˜ë¦¬ì˜¤ ì„¤ëª… (í•œê¸€). ê° í•­ëª©ì„ '-'ë¡œ ì‹œì‘í•˜ì—¬ ì¤„ë°”ê¿ˆìœ¼ë¡œ êµ¬ë¶„í•©ë‹ˆë‹¤.",
      "category": "Collaboration|Technical Support|Product Explanation|Problem Solving",
      "roles": {{
        "user": "{target_lang}ë¡œ ëœ ê°„ë‹¨í•œ ì‚¬ìš©ì ì—­í•  (1-2 ë‹¨ì–´)",
        "ai": "{target_lang}ë¡œ ëœ ê°„ë‹¨í•œ ìƒëŒ€ë°© ì—­í•  (1-2 ë‹¨ì–´)"
      }},
      "requiredTerminology": ["ìš©ì–´1", "ìš©ì–´2", "ìš©ì–´3"]
    }}
  ]
}}

ì¤‘ìš” ì‚¬í•­:
- title: ë°˜ë“œì‹œ í•œê¸€ë¡œ ì‘ì„±
- description: ë°˜ë“œì‹œ í•œê¸€ë¡œ ì‘ì„±
- scenarioText: ë°˜ë“œì‹œ ê°œì¡°ì‹ìœ¼ë¡œ ì‘ì„± (ê° í•­ëª©ì€ '-'ë¡œ ì‹œì‘í•˜ê³  ì¤„ë°”ê¿ˆìœ¼ë¡œ êµ¬ë¶„)
  ì˜ˆì‹œ í˜•ì‹:
  "scenarioText": "- ìƒí™©: í”„ë¡œì íŠ¸ í‚¥ì˜¤í”„ ë¯¸íŒ… ì§„í–‰\\n- ëª©í‘œ: í”„ë¡œì íŠ¸ ì¼ì •, ì—­í•  ë¶„ë‹´, ë§ˆì¼ìŠ¤í†¤ ë…¼ì˜ë¥¼ {target_lang}ë¡œ ì§„í–‰\\n- ì—°ìŠµ ë‚´ìš©: í”„ë¡œì íŠ¸ ë²”ìœ„ ì„¤ëª…, ì¼ì • í™•ì¸, ë‹´ë‹¹ì ì§€ì •\\n- ì£¼ìš” ìš©ì–´: 'milestone', 'deadline', 'deliverable'\\n- ë‚œì´ë„: {difficulty} ìˆ˜ì¤€ì˜ ë¹„ì¦ˆë‹ˆìŠ¤ í‘œí˜„ ì‚¬ìš©"
- roles.user: {target_lang}ë¡œ ëœ ê°„ë‹¨í•œ ì—­í•  ì„¤ëª… (ì˜ˆ: "Project Manager", "Developer", "í”„ë¡œì íŠ¸ ë§¤ë‹ˆì €", "ê°œë°œì")
- roles.ai: {target_lang}ë¡œ ëœ ê°„ë‹¨í•œ ìƒëŒ€ë°© ì—­í•  (ì˜ˆ: "Client", "Team Lead", "Colleague", "ê³ ê°", "íŒ€ì¥", "ë™ë£Œ") - "AI"ë‚˜ "Assistant" ì‚¬ìš© ê¸ˆì§€

ì •í™•íˆ {count}ê°œì˜ ì‹œë‚˜ë¦¬ì˜¤ë¥¼ "scenarios" ë°°ì—´ì— ìƒì„±í•˜ì„¸ìš”."""

            system_content = f"ë‹¹ì‹ ì€ í˜„ì‹¤ì ì¸ ë¹„ì¦ˆë‹ˆìŠ¤ íšŒí™” ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ë§Œë“œëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤. {target_lang} ì–¸ì–´ ì—°ìŠµì— ì í•©í•œ ì˜ êµ¬ì¡°í™”ëœ ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤. ì œëª©, ì„¤ëª…, ì‹œë‚˜ë¦¬ì˜¤ í…ìŠ¤íŠ¸ëŠ” í•­ìƒ í•œê¸€ë¡œ ì‘ì„±í•˜ê³ , ì—­í•  ì„¤ëª…ì€ ê°„ë‹¨í•˜ê²Œ (1-2 ë‹¨ì–´) ì‘ì„±í•©ë‹ˆë‹¤. 'ai' ì—­í• ì€ 'ê³ ê°', 'íŒ€ì¥', 'ë™ë£Œ' ê°™ì€ í˜„ì‹¤ì ì¸ ìƒëŒ€ë°© ì—­í• ì„ ì‚¬ìš©í•˜ë©°, ì ˆëŒ€ 'AI'ë‚˜ 'Assistant'ë¥¼ ì‚¬ìš©í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."

        # Call GPT-4o
        scenario_type = "ì¼ìƒ íšŒí™”" if is_everyday_scenario else "ë¹„ì¦ˆë‹ˆìŠ¤"
        logger.info(f"ğŸ¤– Calling GPT-4o for {scenario_type} scenario generation (language={language}, difficulty={difficulty}, count={count})")

        response = await self.client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {
                    "role": "system",
                    "content": system_content
                },
                {
                    "role": "user",
                    "content": prompt
                }
            ],
            response_format={"type": "json_object"},
            temperature=0.8
        )

        # Parse response
        result = json.loads(response.choices[0].message.content)
        scenarios = result.get("scenarios", [])

        if not scenarios:
            logger.error("âŒ GPT-4o returned no scenarios")
            raise ValueError("Failed to generate scenarios from GPT-4o")

        logger.info(f"âœ… GPT-4o returned {len(scenarios)} {scenario_type} scenarios")
        return scenarios

    async def create_manual(
        self,
        user_id: str,
        title: str,
        description: str,
        scenario_text: str,
        category: str,
        roles: Dict[str, str],
        required_terminology: List[str],
        language: str,
        difficulty: str,
        project_id: Optional[str] = None,
        schedule_id: Optional[str] = None,
        db: Session = None
    ) -> Dict[str, Any]:
        """
        Create a manual scenario.

        Args:
            user_id: User UUID
            title: Scenario title
            description: Brief description
            scenario_text: Detailed scenario text
            category: Scenario category
            roles: Role information dictionary
            required_terminology: List of required terms
            language: Target language
            difficulty: Difficulty level
            project_id: Optional project ID to associate with
            schedule_id: Optional schedule ID to associate with
            db: Database session

        Returns:
            Created scenario dictionary
        """
        logger.info(f"ğŸ“ Creating manual scenario: user={user_id}, title={title}, project={project_id}, schedule={schedule_id}")

        # Build project and schedule ID lists
        project_ids = [project_id] if project_id else []
        schedule_ids = [schedule_id] if schedule_id else []

        scenario = Scenario(
            user_id=user_id,
            title=title,
            description=description,
            scenario_text=scenario_text,
            language=language,
            difficulty=difficulty,
            category=category,
            roles=roles,
            required_terminology=required_terminology,
            project_ids=project_ids,
            schedule_ids=schedule_ids,
            auto_generated=False
        )

        db.add(scenario)
        db.commit()
        db.refresh(scenario)

        logger.info(f"âœ… Manual scenario created: {scenario.id}")

        return {
            "id": str(scenario.id),
            "title": scenario.title,
            "description": scenario.description,
            "scenarioText": scenario.scenario_text,
            "language": scenario.language,
            "difficulty": scenario.difficulty,
            "category": scenario.category,
            "roles": scenario.roles,
            "requiredTerminology": scenario.required_terminology,
            "projectIds": scenario.project_ids,
            "scheduleIds": scenario.schedule_ids,
            "autoGenerated": scenario.auto_generated,
            "createdAt": scenario.created_at.isoformat()
        }

    async def modify_with_chat(
        self,
        current_scenario: Dict[str, Any],
        user_message: str,
        language: str,
        difficulty: str
    ) -> Dict[str, Any]:
        """
        ì±„íŒ…ì„ í†µí•œ ì‹œë‚˜ë¦¬ì˜¤ ìˆ˜ì •

        Args:
            current_scenario: í˜„ì¬ ì‹œë‚˜ë¦¬ì˜¤ ìƒíƒœ
            user_message: ì‚¬ìš©ìì˜ ìˆ˜ì • ìš”ì²­ ë©”ì‹œì§€
            language: ëª©í‘œ ì–¸ì–´
            difficulty: ë‚œì´ë„

        Returns:
            ìˆ˜ì •ëœ ì‹œë‚˜ë¦¬ì˜¤ í•„ë“œì™€ AI ì‘ë‹µ ë©”ì‹œì§€
        """
        logger.info(f"ğŸ¤– ì‹œë‚˜ë¦¬ì˜¤ ìˆ˜ì • ìš”ì²­: message='{user_message[:50]}...'")

        # ì–¸ì–´ ë§¤í•‘
        lang_map = {
            "en": "English",
            "ko": "Korean (í•œêµ­ì–´)",
            "zh": "Chinese (ä¸­æ–‡)",
            "ja": "Japanese (æ—¥æœ¬èª)",
            "vi": "Vietnamese (Tiáº¿ng Viá»‡t)"
        }
        target_lang = lang_map.get(language, "English")

        # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
        system_prompt = f"""ë‹¹ì‹ ì€ ë¹„ì¦ˆë‹ˆìŠ¤ íšŒí™” ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ìˆ˜ì •í•˜ëŠ” ì „ë¬¸ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.

ì‚¬ìš©ìê°€ í˜„ì¬ ì‹œë‚˜ë¦¬ì˜¤ì— ëŒ€í•´ ìˆ˜ì • ìš”ì²­ì„ í•˜ë©´, ìš”ì²­ì‚¬í•­ì„ ë¶„ì„í•˜ê³  ì ì ˆí•˜ê²Œ ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ìˆ˜ì •í•´ì•¼ í•©ë‹ˆë‹¤.

í˜„ì¬ ì‹œë‚˜ë¦¬ì˜¤ ìƒíƒœ:
- ì œëª©: {current_scenario.get('title', '(ì—†ìŒ)')}
- ì„¤ëª…: {current_scenario.get('description', '(ì—†ìŒ)')}
- ì‹œë‚˜ë¦¬ì˜¤ í…ìŠ¤íŠ¸: {current_scenario.get('scenarioText', '(ì—†ìŒ)')}
- ì‚¬ìš©ì ì—­í• : {current_scenario.get('userRole', '(ì—†ìŒ)')}
- AI ì—­í• : {current_scenario.get('aiRole', '(ì—†ìŒ)')}
- ì¹´í…Œê³ ë¦¬: {current_scenario.get('category', 'General')}
- í•„ìˆ˜ ì „ë¬¸ìš©ì–´: {current_scenario.get('requiredTerminology', '(ì—†ìŒ)')}

ëª©í‘œ ì–¸ì–´: {target_lang}
ë‚œì´ë„: {difficulty}

ìˆ˜ì • ì§€ì¹¨:
1. ì‚¬ìš©ìì˜ ìš”ì²­ì„ ì •í™•í•˜ê²Œ ì´í•´í•˜ê³  í•´ë‹¹ í•„ë“œë§Œ ìˆ˜ì •í•˜ì„¸ìš”
2. ìš”ì²­í•˜ì§€ ì•Šì€ í•„ë“œëŠ” ê·¸ëŒ€ë¡œ ìœ ì§€í•˜ì„¸ìš”
3. ì œëª©ê³¼ ì„¤ëª…ì€ ë°˜ë“œì‹œ í•œê¸€ë¡œ ì‘ì„±í•˜ì„¸ìš”
4. ì‹œë‚˜ë¦¬ì˜¤ í…ìŠ¤íŠ¸ëŠ” ë°˜ë“œì‹œ ê°œì¡°ì‹ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš” (ê° í•­ëª©ì„ '-'ë¡œ ì‹œì‘í•˜ê³  ì¤„ë°”ê¿ˆìœ¼ë¡œ êµ¬ë¶„)
5. ì‹œë‚˜ë¦¬ì˜¤ í…ìŠ¤íŠ¸ ì˜ˆì‹œ: "- ìƒí™©: ...\\n- ëª©í‘œ: ...\\n- ì—°ìŠµ ë‚´ìš©: ...\\n- ì£¼ìš” í‘œí˜„/ìš©ì–´: ...\\n- ë‚œì´ë„: ..."
6. ì—­í• ì€ ê°„ë‹¨í•˜ê²Œ 1-2 ë‹¨ì–´ë¡œ {target_lang}ë¡œ ì‘ì„±í•˜ì„¸ìš”
7. AI ì—­í• ì€ "AI"ë‚˜ "Assistant"ê°€ ì•„ë‹Œ í˜„ì‹¤ì ì¸ ì—­í•  (ì˜ˆ: "Client", "ê³ ê°", "íŒ€ì¥")ì„ ì‚¬ìš©í•˜ì„¸ìš”
8. ë‚œì´ë„ {difficulty}ì— ë§ëŠ” ì ì ˆí•œ ë³µì¡ë„ë¡œ ì¡°ì •í•˜ì„¸ìš”

ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”:
{{
  "modifiedFields": {{
    "title": "ìˆ˜ì •ëœ ì œëª© (í•œê¸€, ë³€ê²½ ì‹œì—ë§Œ)",
    "description": "ìˆ˜ì •ëœ ì„¤ëª… (í•œê¸€, ë³€ê²½ ì‹œì—ë§Œ)",
    "scenarioText": "ìˆ˜ì •ëœ ì‹œë‚˜ë¦¬ì˜¤ í…ìŠ¤íŠ¸ (ê°œì¡°ì‹, í•œê¸€, ë³€ê²½ ì‹œì—ë§Œ)",
    "userRole": "ìˆ˜ì •ëœ ì‚¬ìš©ì ì—­í•  ({target_lang}, ë³€ê²½ ì‹œì—ë§Œ)",
    "aiRole": "ìˆ˜ì •ëœ AI ì—­í•  ({target_lang}, ë³€ê²½ ì‹œì—ë§Œ)",
    "category": "ìˆ˜ì •ëœ ì¹´í…Œê³ ë¦¬ (ë³€ê²½ ì‹œì—ë§Œ)",
    "requiredTerminology": "ìˆ˜ì •ëœ ì „ë¬¸ìš©ì–´ (ë³€ê²½ ì‹œì—ë§Œ)"
  }},
  "assistantMessage": "ì‚¬ìš©ìì—ê²Œ ë³´ë‚¼ í•œê¸€ ì‘ë‹µ ë©”ì‹œì§€ (ì–´ë–¤ ë¶€ë¶„ì„ ìˆ˜ì •í–ˆëŠ”ì§€ ê°„ë‹¨íˆ ì„¤ëª…)"
}}

ì¤‘ìš”:
- modifiedFieldsì—ëŠ” ì‹¤ì œë¡œ ë³€ê²½ëœ í•„ë“œë§Œ í¬í•¨í•˜ì„¸ìš”
- ë³€ê²½í•˜ì§€ ì•Šì€ í•„ë“œëŠ” í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”
- scenarioTextë¥¼ ìˆ˜ì •í•  ë•ŒëŠ” ë°˜ë“œì‹œ ê°œì¡°ì‹ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš” (ê° í•­ëª© '-'ë¡œ ì‹œì‘, ì¤„ë°”ê¿ˆ êµ¬ë¶„)
- assistantMessageëŠ” ì¹œê·¼í•˜ê³  ê°„ê²°í•˜ê²Œ ì‘ì„±í•˜ì„¸ìš” (1-2ë¬¸ì¥)"""

        # GPT-4o í˜¸ì¶œ
        response = await self.client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_message}
            ],
            response_format={"type": "json_object"},
            temperature=0.7
        )

        # ì‘ë‹µ íŒŒì‹±
        result = json.loads(response.choices[0].message.content)
        modified_fields = result.get("modifiedFields", {})
        assistant_message = result.get("assistantMessage", "ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ìˆ˜ì •í–ˆìŠµë‹ˆë‹¤.")

        logger.info(f"âœ… ì‹œë‚˜ë¦¬ì˜¤ ìˆ˜ì • ì™„ë£Œ: {len(modified_fields)} í•„ë“œ ìˆ˜ì •ë¨")

        return {
            "modifiedScenario": modified_fields,
            "message": assistant_message
        }


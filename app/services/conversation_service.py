"""
íšŒí™” ì—°ìŠµ ì„œë¹„ìŠ¤
GPT-4oë¥¼ ì´ìš©í•œ ì‹œë‚˜ë¦¬ì˜¤ ê¸°ë°˜ ëŒ€í™” ìƒì„±
"""
import json
import logging
from typing import List, Dict, Any
from uuid import UUID

from app.core.openai_client import get_openai_client
from app.database import get_db

logger = logging.getLogger(__name__)


class ConversationService:
    """íšŒí™” ì—°ìŠµ ëŒ€í™” ìƒì„± ì„œë¹„ìŠ¤"""

    def __init__(self):
        self.client = get_openai_client()  # ì‹±ê¸€í†¤ í´ë¼ì´ì–¸íŠ¸ ì‚¬ìš©

    async def start_conversation(
        self,
        scenario_id: str,
        user_id: UUID
    ) -> Dict[str, Any]:
        """
        ëŒ€í™” ì‹œì‘

        Args:
            scenario_id: ì‹œë‚˜ë¦¬ì˜¤ ID
            user_id: ì‚¬ìš©ì ID

        Returns:
            ì‹œë‚˜ë¦¬ì˜¤ ì •ë³´ ë° ì´ˆê¸° AI ë©”ì‹œì§€
        """
        try:
            # DBì—ì„œ ì‹œë‚˜ë¦¬ì˜¤ ì¡°íšŒ
            db = next(get_db())
            from app.models.scenario import Scenario
            from app.models.conversation import ConversationSession

            scenario = db.query(Scenario).filter(
                Scenario.id == UUID(scenario_id),
                Scenario.user_id == user_id
            ).first()

            if not scenario:
                raise ValueError(f"Scenario not found: {scenario_id}")

            # ê¸°ì¡´ active ì„¸ì…˜ì´ ìˆëŠ”ì§€ ë¨¼ì € í™•ì¸
            existing_session = db.query(ConversationSession).filter(
                ConversationSession.scenario_id == UUID(scenario_id),
                ConversationSession.user_id == user_id,
                ConversationSession.status == 'active'
            ).first()

            if existing_session and existing_session.total_messages > 0:
                # ê¸°ì¡´ ì„¸ì…˜ì´ ìˆê³  ë©”ì‹œì§€ê°€ ìˆìœ¼ë©´ ì‹œë‚˜ë¦¬ì˜¤ ì •ë³´ë§Œ ë°˜í™˜ (ì´ˆê¸° ë©”ì‹œì§€ ì—†ìŒ)
                logger.info(f"Existing session found with {existing_session.total_messages} messages, skipping initial message")
                return {
                    "scenario": {
                        "id": str(scenario.id),
                        "title": scenario.title,
                        "description": scenario.description,
                        "difficulty": scenario.difficulty,
                        "category": scenario.category,
                        "language": scenario.language,
                        "roles": scenario.roles,
                        "requiredTerms": scenario.required_terminology,
                        "scenario_text": scenario.scenario_text,
                        "steps": scenario.steps or []
                    },
                    "initialMessage": None,  # ê¸°ì¡´ ëŒ€í™”ê°€ ìˆìœ¼ë¯€ë¡œ ì´ˆê¸° ë©”ì‹œì§€ ì—†ìŒ
                    "sessionId": str(existing_session.id)
                }

            # ìƒˆ ì„¸ì…˜ ìƒì„±
            session = await self._get_or_create_session(db, scenario_id, user_id)

            # ì´ˆê¸° AI ë©”ì‹œì§€ ìƒì„±
            initial_message = await self._generate_initial_message(scenario)

            # AI ì´ˆê¸° ë©”ì‹œì§€ë¥¼ DBì— ì €ì¥
            await self._save_message(
                db=db,
                session_id=session.id,
                sender="ai",
                message_text=initial_message,
                sequence_number=1
            )

            return {
                "scenario": {
                    "id": str(scenario.id),
                    "title": scenario.title,
                    "description": scenario.description,
                    "difficulty": scenario.difficulty,
                    "category": scenario.category,
                    "language": scenario.language,
                    "roles": scenario.roles,
                    "requiredTerms": scenario.required_terminology,
                    "scenario_text": scenario.scenario_text,
                    "steps": scenario.steps or []
                },
                "initialMessage": initial_message,
                "sessionId": str(session.id)
            }

        except Exception as e:
            logger.error(f"Error starting conversation: {str(e)}")
            raise

    async def send_message(
        self,
        scenario_id: str,
        user_message: str,
        conversation_history: List[Dict[str, str]],
        user_id: UUID,
        current_step_index: int = 0
    ) -> Dict[str, Any]:
        """
        ì‚¬ìš©ì ë©”ì‹œì§€ ì „ì†¡ ë° AI ì‘ë‹µ ìƒì„±

        Args:
            scenario_id: ì‹œë‚˜ë¦¬ì˜¤ ID
            user_message: ì‚¬ìš©ì ë©”ì‹œì§€
            conversation_history: ëŒ€í™” íˆìŠ¤í† ë¦¬ (í”„ë¡ íŠ¸ì—ì„œ ì „ë‹¬, ë°±ì—…ìš©)
            user_id: ì‚¬ìš©ì ID
            current_step_index: í˜„ì¬ ìŠ¤í… ì¸ë±ìŠ¤ (0-based)

        Returns:
            AI ì‘ë‹µ, ê°ì§€ëœ ì „ë¬¸ìš©ì–´, ìŠ¤í… ì™„ë£Œ ì—¬ë¶€
        """
        try:
            # DBì—ì„œ ì‹œë‚˜ë¦¬ì˜¤ ì¡°íšŒ
            db = next(get_db())
            from app.models.scenario import Scenario

            scenario = db.query(Scenario).filter(
                Scenario.id == UUID(scenario_id),
                Scenario.user_id == user_id
            ).first()

            if not scenario:
                raise ValueError(f"Scenario not found: {scenario_id}")

            # ì„¸ì…˜ ê°€ì ¸ì˜¤ê¸° ë˜ëŠ” ìƒì„±
            session = await self._get_or_create_session(db, scenario_id, user_id)

            # í˜„ì¬ ë©”ì‹œì§€ ë²ˆí˜¸ ê³„ì‚°
            next_seq = session.total_messages + 1

            # ì‚¬ìš©ì ë©”ì‹œì§€ DBì— ì €ì¥
            await self._save_message(
                db=db,
                session_id=session.id,
                sender="user",
                message_text=user_message,
                sequence_number=next_seq
            )

            # ìŠ¤í… ì •ë³´ ê°€ì ¸ì˜¤ê¸° (steps ì»¬ëŸ¼ì´ ìˆëŠ” ê²½ìš°)
            steps = getattr(scenario, 'steps', None) or []
            current_step = steps[current_step_index] if steps and current_step_index < len(steps) else None

            # AI ì‘ë‹µ ìƒì„± (ìŠ¤í… íŒë‹¨ í¬í•¨)
            ai_response = await self._generate_ai_response(
                scenario=scenario,
                user_message=user_message,
                conversation_history=conversation_history,
                current_step=current_step,
                current_step_index=current_step_index,
                total_steps=len(steps) if steps else 0
            )

            # ì „ë¬¸ìš©ì–´ ê°ì§€
            detected_terms = self._detect_terminology(
                message=user_message,
                required_terminology=scenario.required_terminology
            )

            # AI ë©”ì‹œì§€ DBì— ì €ì¥
            await self._save_message(
                db=db,
                session_id=session.id,
                sender="ai",
                message_text=ai_response["message"],
                detected_terms=detected_terms,
                sequence_number=next_seq + 1
            )

            return {
                "aiMessage": ai_response["message"],
                "detectedTerms": detected_terms,
                "stepCompleted": ai_response.get("step_completed", False)
            }

        except Exception as e:
            logger.error(f"Error sending message: {str(e)}")
            raise

    async def _generate_initial_message(self, scenario) -> str:
        """
        ì´ˆê¸° AI ë©”ì‹œì§€ ìƒì„± (ìŠ¤ëª°í† í¬ë¡œ ì‹œì‘)

        Args:
            scenario: ì‹œë‚˜ë¦¬ì˜¤ ê°ì²´

        Returns:
            ì´ˆê¸° AI ë©”ì‹œì§€
        """
        try:
            from datetime import datetime
            current_date = datetime.now().strftime("%Y-%m-%d")

            # ë‚œì´ë„ë³„ ì§€ì¹¨
            difficulty_instructions = {
                "beginner": """
- ë§¤ìš° ê°„ë‹¨í•˜ê³  ê¸°ë³¸ì ì¸ ì¸ì‚¬ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”
- ì§§ê³  ì‰¬ìš´ ë¬¸ì¥ êµ¬ì¡° ì‚¬ìš© (5-8 ë‹¨ì–´)
- ì¼ìƒì ì´ê³  ì¹œê·¼í•œ í‘œí˜„ë§Œ ì‚¬ìš©
- ë³µì¡í•œ ì–´íœ˜ë‚˜ ê´€ìš©êµ¬ í”¼í•˜ê¸°""",
                "intermediate": """
- ìì—°ìŠ¤ëŸ¬ìš´ ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ ì‚¬ìš©
- ì¤‘ê°„ ê¸¸ì´ì˜ ë¬¸ì¥ (8-12 ë‹¨ì–´)
- ì¼ë°˜ì ì¸ ë¹„ì¦ˆë‹ˆìŠ¤ ìš©ì–´ í¬í•¨ ê°€ëŠ¥
- ì•½ê°„ì˜ ê´€ìš©ì  í‘œí˜„ ì‚¬ìš© ê°€ëŠ¥""",
                "advanced": """
- ì „ë¬¸ì ì´ê³  ì„¸ë ¨ëœ ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬
- ë‹¤ì–‘í•œ ë¬¸ì¥ êµ¬ì¡° ì‚¬ìš© ê°€ëŠ¥
- ì „ë¬¸ ìš©ì–´ì™€ ê´€ìš©êµ¬ ììœ ë¡­ê²Œ ì‚¬ìš©
- ë‰˜ì•™ìŠ¤ì™€ í•¨ì¶•ì  í‘œí˜„ í™œìš©"""
            }

            # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
            system_prompt = f"""ë‹¹ì‹ ì€ ë¹„ì¦ˆë‹ˆìŠ¤ íšŒí™” ì—°ìŠµ ì‹œë‚˜ë¦¬ì˜¤ì— ì°¸ì—¬í•˜ê³  ìˆìŠµë‹ˆë‹¤.

ì˜¤ëŠ˜ ë‚ ì§œ: {current_date}

ì‹œë‚˜ë¦¬ì˜¤: {scenario.title}
ì„¤ëª…: {scenario.description}
ìƒí™©: {scenario.scenario_text}

ë‹¹ì‹ ì˜ ì—­í• : {scenario.roles.get('ai', 'AI')}
ì‚¬ìš©ì ì—­í• : {scenario.roles.get('user', 'User')}

ì–¸ì–´: {scenario.language}
ë‚œì´ë„: {scenario.difficulty}

ë‚˜ì¤‘ì— ìì—°ìŠ¤ëŸ½ê²Œ ì‚¬ìš©í•  í•„ìˆ˜ ì „ë¬¸ìš©ì–´: {', '.join(scenario.required_terminology)}

ë‚œì´ë„ë³„ ì§€ì¹¨:
{difficulty_instructions.get(scenario.difficulty, difficulty_instructions['intermediate'])}

ê¸°ë³¸ ì§€ì¹¨:
- ì§§ê³  ì¹œê·¼í•œ ì¸ì‚¬ë¡œ ì‹œì‘í•˜ì„¸ìš” (ìµœëŒ€ 1-2ë¬¸ì¥)
- ìºì£¼ì–¼í•œ ì¸ì‚¬ì™€ í•¨ê»˜ ì‹œë‚˜ë¦¬ì˜¤ ë§¥ë½ì„ ì€ê·¼íˆ ì•”ì‹œí•˜ì„¸ìš”
- ì˜ˆì‹œ: "ì•ˆë…•í•˜ì„¸ìš”! ì˜ ì§€ë‚´ì…¨ì–´ìš”? í”„ë¡œì íŠ¸ ë¯¸íŒ… ì¤€ë¹„ë˜ì…¨ë‚˜ìš”?" ë˜ëŠ” "Hi! How's it going? Ready for our meeting about the project?"
- ìì—°ìŠ¤ëŸ½ê³  ëŒ€í™”ì²´ë¡œ ì‘ì„±í•˜ì„¸ìš”
- {scenario.language} ì–¸ì–´ë¡œ ì‘ë‹µí•˜ì„¸ìš”
- ì¹œê·¼í•˜ê³  í™˜ì˜í•˜ëŠ” ë¶„ìœ„ê¸°ë¥¼ ë§Œë“œì„¸ìš”
- ì˜¤ëŠ˜ ë‚ ì§œë¥¼ ê¸°ë°˜ìœ¼ë¡œ í˜„ì‹¤ì ì¸ ë§¥ë½ì„ ì‚¬ìš©í•˜ì„¸ìš”"""

            # GPT-4o í˜¸ì¶œ
            response = await self.client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": "ì¹œê·¼í•œ ì¸ì‚¬ë¡œ ì‹œì‘í•˜ì„¸ìš” (1-2ë¬¸ì¥). ì²« ë¬¸ì¥: ìºì£¼ì–¼í•œ ì¸ì‚¬. ë‘ ë²ˆì§¸ ë¬¸ì¥ (ì„ íƒ): ì‹œë‚˜ë¦¬ì˜¤ ë§¥ë½ì„ ì€ê·¼íˆ ì–¸ê¸‰. ê°„ê²°í•˜ê³  ìì—°ìŠ¤ëŸ½ê²Œ ì‘ì„±í•˜ì„¸ìš”."}
                ],
                temperature=0.7,
                max_tokens=80
            )

            return response.choices[0].message.content

        except Exception as e:
            logger.error(f"Error generating initial message: {str(e)}")
            return "Hello! How are you doing today?"

    async def _generate_ai_response(
        self,
        scenario,
        user_message: str,
        conversation_history: List[Dict[str, str]],
        current_step: Dict[str, Any] = None,
        current_step_index: int = 0,
        total_steps: int = 0
    ) -> Dict[str, Any]:
        """
        AI ì‘ë‹µ ìƒì„± (ìŠ¤ëª°í† í¬ í¬í•¨, ìŠ¤í… ì§„í–‰ íŒë‹¨)

        Args:
            scenario: ì‹œë‚˜ë¦¬ì˜¤ ê°ì²´
            user_message: ì‚¬ìš©ì ë©”ì‹œì§€
            conversation_history: ëŒ€í™” íˆìŠ¤í† ë¦¬
            current_step: í˜„ì¬ ìŠ¤í… ì •ë³´ (ìˆëŠ” ê²½ìš°)
            current_step_index: í˜„ì¬ ìŠ¤í… ì¸ë±ìŠ¤
            total_steps: ì „ì²´ ìŠ¤í… ìˆ˜

        Returns:
            AI ì‘ë‹µ ë©”ì‹œì§€ì™€ ìŠ¤í… ì™„ë£Œ ì—¬ë¶€ë¥¼ í¬í•¨í•œ ë”•ì…”ë„ˆë¦¬
        """
        try:
            from datetime import datetime
            current_date = datetime.now().strftime("%Y-%m-%d")
            current_time = datetime.now().strftime("%H:%M")

            # ë‚œì´ë„ë³„ ëŒ€í™” ìŠ¤íƒ€ì¼ ì§€ì¹¨
            conversation_style = {
                "beginner": """
- ë§¤ìš° ê°„ë‹¨í•œ ë¬¸ì¥ êµ¬ì¡° ì‚¬ìš© (ì£¼ì–´ + ë™ì‚¬ + ëª©ì ì–´)
- ê¸°ë³¸ ì–´íœ˜ë§Œ ì‚¬ìš© (ê³ ë“±í•™êµ ìˆ˜ì¤€)
- ì²œì²œíˆ ì£¼ì œ ì „í™˜í•˜ê¸°
- í•œ ë²ˆì— í•œ ê°€ì§€ ì•„ì´ë””ì–´ë§Œ ë‹¤ë£¨ê¸°
- ëª…í™•í•˜ê³  ì§ì ‘ì ì¸ ì§ˆë¬¸í•˜ê¸°""",
                "intermediate": """
- ìì—°ìŠ¤ëŸ¬ìš´ ë¹„ì¦ˆë‹ˆìŠ¤ ëŒ€í™” ìŠ¤íƒ€ì¼
- ì¼ë°˜ì ì¸ ë¹„ì¦ˆë‹ˆìŠ¤ ìš©ì–´ ì‚¬ìš©
- ë³µí•© ë¬¸ì¥ ê°€ëŠ¥í•˜ì§€ë§Œ ê°„ê²°í•˜ê²Œ
- ì ì ˆí•œ ê´€ìš©êµ¬ ì‚¬ìš©
- ë§¥ë½ì„ ê³ ë ¤í•œ ì§ˆë¬¸ê³¼ ì‘ë‹µ""",
                "advanced": """
- ì „ë¬¸ì ì´ê³  ì„¸ë ¨ëœ ë¹„ì¦ˆë‹ˆìŠ¤ ì»¤ë®¤ë‹ˆì¼€ì´ì…˜
- ì „ë¬¸ ìš©ì–´ì™€ ì‚°ì—… íŠ¹í™” ì–´íœ˜ ììœ ë¡­ê²Œ ì‚¬ìš©
- ë³µì¡í•œ ë¬¸ì¥ êµ¬ì¡°ì™€ ë‰˜ì•™ìŠ¤ í™œìš©
- í•¨ì¶•ì  í‘œí˜„ê³¼ ê³ ê¸‰ ê´€ìš©êµ¬ ì‚¬ìš©
- ì „ëµì ì´ê³  ë‹¤ì¸µì ì¸ ëŒ€í™” ì§„í–‰"""
            }

            # ìŠ¤í… ì •ë³´ êµ¬ì„± (ìˆëŠ” ê²½ìš°)
            step_context = ""
            step_judgment_instruction = ""
            if current_step and total_steps > 0:
                step_context = f"""
í˜„ì¬ ì§„í–‰ ë‹¨ê³„: {current_step_index + 1}/{total_steps}
í˜„ì¬ ìŠ¤í…: {current_step.get('name', 'Unknown')}
ìŠ¤í… ê°€ì´ë“œ: {current_step.get('guide', '')}
ì´ ìŠ¤í…ì—ì„œ ì‚¬ìš©í•  ìš©ì–´: {', '.join(current_step.get('terminology', []))}
"""
                step_judgment_instruction = """
ìŠ¤í… ì§„í–‰ íŒë‹¨:
- í˜„ì¬ ìŠ¤í…ì˜ ëª©ì ì´ ìì—°ìŠ¤ëŸ½ê²Œ ë‹¬ì„±ë˜ì—ˆëŠ”ì§€ íŒë‹¨í•˜ì„¸ìš”
- ì‚¬ìš©ìê°€ í˜„ì¬ ìŠ¤í…ì˜ ì£¼ì œì— ëŒ€í•´ ì¶©ë¶„íˆ ëŒ€í™”í–ˆë‹¤ë©´ step_completedë¥¼ trueë¡œ ì„¤ì •í•˜ì„¸ìš”
- ì•„ì§ í˜„ì¬ ìŠ¤í…ì˜ ëª©ì ì„ ì¶©ë¶„íˆ ë‹¤ë£¨ì§€ ì•Šì•˜ë‹¤ë©´ step_completedë¥¼ falseë¡œ ì„¤ì •í•˜ì„¸ìš”
- ë‹¤ìŒ ìŠ¤í…ìœ¼ë¡œ ë„˜ì–´ê°€ìê³  ëª…ì‹œì ìœ¼ë¡œ ì œì•ˆí•˜ì§€ ë§ˆì„¸ìš” - ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™” íë¦„ì„ ìœ ì§€í•˜ì„¸ìš”
"""

            # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
            system_prompt = f"""ë‹¹ì‹ ì€ ë¹„ì¦ˆë‹ˆìŠ¤ íšŒí™” ì—°ìŠµ ì‹œë‚˜ë¦¬ì˜¤ì— ì°¸ì—¬í•˜ê³  ìˆìŠµë‹ˆë‹¤.

ì˜¤ëŠ˜ ë‚ ì§œ: {current_date}
í˜„ì¬ ì‹œê°„: {current_time}

ì‹œë‚˜ë¦¬ì˜¤: {scenario.title}
ì„¤ëª…: {scenario.description}
ìƒí™©: {scenario.scenario_text}

ë‹¹ì‹ ì˜ ì—­í• : {scenario.roles.get('ai', 'AI')}
ì‚¬ìš©ì ì—­í• : {scenario.roles.get('user', 'User')}

ì–¸ì–´: {scenario.language}
ë‚œì´ë„: {scenario.difficulty}

ìì—°ìŠ¤ëŸ½ê²Œ ì‚¬ìš©í•  í•„ìˆ˜ ì „ë¬¸ìš©ì–´: {', '.join(scenario.required_terminology)}
{step_context}
ë‚œì´ë„ë³„ ëŒ€í™” ìŠ¤íƒ€ì¼:
{conversation_style.get(scenario.difficulty, conversation_style['intermediate'])}

ê¸°ë³¸ ì§€ì¹¨:
- ì¤‘ìš”: ì‘ë‹µì„ ë§¤ìš° ê°„ê²°í•˜ê²Œ ìœ ì§€í•˜ì„¸ìš” - ì½ëŠ” ì‹œê°„ì´ 7ì´ˆ ì´ë‚´ì—¬ì•¼ í•©ë‹ˆë‹¤ (ìµœëŒ€ 15-20 ë‹¨ì–´)
- 1-2ê°œì˜ ì§§ì€ ë¬¸ì¥ë§Œ ì‚¬ìš©í•˜ì„¸ìš” (ì ˆëŒ€ 2ë¬¸ì¥ ì´ìƒ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”)
- ì‹¤ì œ ëŒ€í™”ì²˜ëŸ¼ ìºì£¼ì–¼í•œ ìŠ¤ëª°í† í¬ì™€ ë¹„ì¦ˆë‹ˆìŠ¤ ì£¼ì œë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ ì„ìœ¼ì„¸ìš”
- ê°€ë”ì€ ë¹„ì¦ˆë‹ˆìŠ¤ ëŒ€í™” ì „í›„ì— ê°œì¸ì ì¸ ê²ƒë“¤(ì£¼ë§, ì ì‹¬, ë‚ ì”¨ ë“±)ì„ ë¬¼ì–´ë³´ì„¸ìš”
- ë¹„ì¦ˆë‹ˆìŠ¤ë¥¼ ë…¼ì˜í•  ë•Œ í•„ìˆ˜ ì „ë¬¸ìš©ì–´ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ ì‚¬ìš©í•˜ì„¸ìš”
- {scenario.language} ì–¸ì–´ë¡œ ì‘ë‹µí•˜ì„¸ìš”
- ì–¸ì–´ ì—°ìŠµì— ëŒ€í•´ ê²©ë ¤í•˜ê³  ì§€ì›ì ìœ¼ë¡œ ëŒ€í•˜ì„¸ìš”
- ì‚¬ìš©ìê°€ ë¬¸ë²• ì˜¤ë¥˜ë¥¼ ë²”í•˜ë©´, ì‘ë‹µì—ì„œ ë¶€ë“œëŸ½ê²Œ êµì •ì„ í¬í•¨í•˜ì„¸ìš”
- ì˜¤ëŠ˜ ë§¥ë½ì„ ê¸°ë°˜ìœ¼ë¡œ í˜„ì‹¤ì ì¸ ë‚ ì§œì™€ ì‹œê°„ì„ ì‚¬ìš©í•˜ì„¸ìš”
- ì•Œë¦¼: "ë¹ ë¥¸ ì±„íŒ… ë©”ì‹œì§€"ë¡œ ìƒê°í•˜ì„¸ìš”, "ì´ë©”ì¼"ì´ ì•„ë‹™ë‹ˆë‹¤ - ëŒ€í™”ì²´ì´ê³  ê°„ê²°í•˜ê²Œ
{step_judgment_instruction}
ì‘ë‹µì€ ë°˜ë“œì‹œ ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì œê³µí•˜ì„¸ìš”:
{{
    "message": "AI ì‘ë‹µ ë©”ì‹œì§€ (ê°„ê²°í•˜ê²Œ, 15-20 ë‹¨ì–´ ì´ë‚´)",
    "step_completed": false
}}"""

            # ëŒ€í™” íˆìŠ¤í† ë¦¬ êµ¬ì„±
            messages = [{"role": "system", "content": system_prompt}]

            # ì´ì „ ëŒ€í™” ì¶”ê°€
            for msg in conversation_history[-10:]:  # ìµœê·¼ 10ê°œë§Œ
                role = "assistant" if msg["speaker"] == "ai" else "user"
                messages.append({"role": role, "content": msg["message"]})

            # í˜„ì¬ ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
            messages.append({"role": "user", "content": user_message})

            # GPT-4o í˜¸ì¶œ (JSON ì‘ë‹µ í˜•ì‹)
            response = await self.client.chat.completions.create(
                model="gpt-4o",
                messages=messages,
                temperature=0.8,
                max_tokens=150,
                response_format={"type": "json_object"}
            )

            # JSON íŒŒì‹±
            response_text = response.choices[0].message.content
            try:
                parsed_response = json.loads(response_text)
                return {
                    "message": parsed_response.get("message", response_text),
                    "step_completed": parsed_response.get("step_completed", False)
                }
            except json.JSONDecodeError:
                # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ í…ìŠ¤íŠ¸ ê·¸ëŒ€ë¡œ ë°˜í™˜
                logger.warning(f"Failed to parse AI response as JSON: {response_text}")
                return {
                    "message": response_text,
                    "step_completed": False
                }

        except Exception as e:
            logger.error(f"Error generating AI response: {str(e)}")
            raise

    def _detect_terminology(
        self,
        message: str,
        required_terminology: List[str]
    ) -> List[str]:
        """
        ë©”ì‹œì§€ì—ì„œ ì „ë¬¸ìš©ì–´ ê°ì§€

        Args:
            message: ì‚¬ìš©ì ë©”ì‹œì§€
            required_terminology: í•„ìˆ˜ ì „ë¬¸ìš©ì–´ ëª©ë¡

        Returns:
            ê°ì§€ëœ ì „ë¬¸ìš©ì–´ ëª©ë¡
        """
        detected = []
        message_lower = message.lower()

        for term in required_terminology:
            if term.lower() in message_lower:
                detected.append(term)

        return detected

    async def generate_message_feedback(
        self,
        scenario_id: str,
        user_message: str,
        detected_terms: List[str],
        user_id: UUID,
        audio_data: str = None,
        current_step: Dict[str, Any] = None
    ) -> Dict[str, Any]:
        """
        ì‚¬ìš©ì ë©”ì‹œì§€ì— ëŒ€í•œ í”¼ë“œë°± ìƒì„±

        Args:
            scenario_id: ì‹œë‚˜ë¦¬ì˜¤ ID
            user_message: ì‚¬ìš©ì ë©”ì‹œì§€
            detected_terms: ê°ì§€ëœ ì „ë¬¸ìš©ì–´
            user_id: ì‚¬ìš©ì ID
            audio_data: Base64 ì¸ì½”ë”©ëœ ì˜¤ë””ì˜¤ ë°ì´í„° (ì„ íƒ)
            current_step: í˜„ì¬ ëŒ€í™” ë‹¨ê³„ ì •ë³´ (ì„ íƒ)
                - name: ë‹¨ê³„ ì˜ë¬¸ ì‹ë³„ì
                - title: ë‹¨ê³„ í•œê¸€ ì œëª©
                - guide: ë‹¨ê³„ ê°€ì´ë“œ
                - terminology: ì´ ë‹¨ê³„ì—ì„œ ì‚¬ìš©í•  í‘œí˜„ ë¦¬ìŠ¤íŠ¸

        Returns:
            í”¼ë“œë°± (ë¬¸ë²• êµì •, ìš©ì–´ ì‚¬ìš©, ì œì•ˆ, ì ìˆ˜, ë‹¨ê³„ë³„ í‘œí˜„ í”¼ë“œë°±)
        """
        try:
            # DBì—ì„œ ì‹œë‚˜ë¦¬ì˜¤ ì¡°íšŒ
            db = next(get_db())
            from app.models.scenario import Scenario

            scenario = db.query(Scenario).filter(
                Scenario.id == UUID(scenario_id),
                Scenario.user_id == user_id
            ).first()

            if not scenario:
                raise ValueError(f"Scenario not found: {scenario_id}")

            # Azure Pronunciation Assessment ìˆ˜í–‰ (ì˜¤ë””ì˜¤ ë°ì´í„°ê°€ ìˆëŠ” ê²½ìš°)
            pronunciation_details = None
            if audio_data:
                try:
                    import base64
                    from agent.pronunciation.pronunciation_agent import PronunciationAssessmentAgent

                    logger.info("ğŸ¤ Running Azure Pronunciation Assessment...")
                    audio_bytes = base64.b64decode(audio_data)

                    # ë°œìŒ í‰ê°€ ìˆ˜í–‰
                    agent = PronunciationAssessmentAgent.get_instance()
                    pronunciation_result = await agent.assess_pronunciation(
                        audio_data=audio_bytes,
                        reference_text=user_message,
                        language='en-US',
                        granularity='Phoneme'
                    )

                    # ìƒì„¸ ë°œìŒ ì •ë³´ ì €ì¥
                    pronunciation_details = {
                        'pronunciation_score': pronunciation_result['pronunciation_score'],
                        'accuracy_score': pronunciation_result['accuracy_score'],
                        'fluency_score': pronunciation_result['fluency_score'],
                        'prosody_score': pronunciation_result['prosody_score'],
                        'completeness_score': pronunciation_result['completeness_score'],
                        'words': pronunciation_result['words']
                    }

                    logger.info(f"âœ… Pronunciation assessment completed: {pronunciation_result['pronunciation_score']:.1f}")

                except Exception as e:
                    logger.error(f"Pronunciation assessment failed: {str(e)}", exc_info=True)
                    # ë°œìŒ í‰ê°€ ì‹¤íŒ¨í•´ë„ í”¼ë“œë°±ì€ ê³„ì† ìƒì„±

            # í˜„ì¬ ë‹¨ê³„ ì •ë³´ êµ¬ì„±
            step_info_section = ""
            step_terminology = []
            if current_step:
                step_terminology = current_step.get("terminology", [])
                step_info_section = f"""

í˜„ì¬ ëŒ€í™” ë‹¨ê³„:
- ë‹¨ê³„ëª…: {current_step.get('name', 'N/A')}
- ë‹¨ê³„ ì œëª©: {current_step.get('title', 'N/A')}
- ê°€ì´ë“œ: {current_step.get('guide', 'N/A')}
- ì´ ë‹¨ê³„ì—ì„œ ì‚¬ìš©í•´ì•¼ í•  í‘œí˜„: {', '.join(step_terminology) if step_terminology else 'ì—†ìŒ'}"""

            # GPT-4oë¡œ í”¼ë“œë°± ìƒì„±
            system_prompt = f"""ë‹¹ì‹ ì€ ë¹„ì¦ˆë‹ˆìŠ¤ íšŒí™” ì—°ìŠµì— ëŒ€í•œ í”¼ë“œë°±ì„ í•œê¸€ë¡œ ì œê³µí•˜ëŠ” ì „ë¬¸ ì–¸ì–´ íŠœí„°ì…ë‹ˆë‹¤.

ì‹œë‚˜ë¦¬ì˜¤ ë§¥ë½:
- ì œëª©: {scenario.title}
- ì„¤ëª…: {scenario.description}
- ìƒí™©: {scenario.scenario_text}
- ì‚¬ìš©ì ì—­í• : {scenario.roles.get('user', 'User')}
- AI ì—­í• : {scenario.roles.get('ai', 'AI')}
- ì–¸ì–´: {scenario.language}
- ë‚œì´ë„: {scenario.difficulty}
- í•„ìˆ˜ ì „ë¬¸ìš©ì–´: {', '.join(scenario.required_terminology)}{step_info_section}

ì¤‘ìš”í•œ í”¼ë“œë°± ê·œì¹™:
1. ëª¨ë“  í”¼ë“œë°±ì€ ë°˜ë“œì‹œ í•œê¸€ë¡œ ì‘ì„±í•´ì•¼ í•©ë‹ˆë‹¤
2. ë¬¸ë²• êµì •: í•œê¸€ë¡œ ë¬¸ì œë¥¼ ì„¤ëª…í•œ í›„, ì˜ì–´ êµì •ì„ ì œì•ˆí•˜ì„¸ìš”
   - ì˜ˆì‹œ: "ì‹œì œê°€ í‹€ë ¸ì–´ìš”. 'I go yesterday' ëŒ€ì‹  'I went yesterday'ë¼ê³  í•´ì•¼ í•´ìš”."
3. ì œì•ˆ: í•œê¸€ ì„¤ëª…ê³¼ í•¨ê»˜ ì˜ì–´ í‘œí˜„ ì¶”ì²œì„ ì œê³µí•˜ì„¸ìš”
   - ì˜ˆì‹œ: "ë” ìì—°ìŠ¤ëŸ¬ìš´ í‘œí˜„ìœ¼ë¡œëŠ” 'Could you please...' ë˜ëŠ” 'Would you mind...'ë¥¼ ì‚¬ìš©í•´ë³´ì„¸ìš”."
   - ë©”ì‹œì§€ê°€ ë§¤ìš° ë¶€ì¡±í•˜ë‹¤ë©´, "ì´ëŸ° ì‹ìœ¼ë¡œ í•´ë³´ì„¸ìš”"ì™€ í•¨ê»˜ ì™„ì „í•œ ë¬¸ì¥ ì˜ˆì‹œë¥¼ ì œê³µí•˜ì„¸ìš”
   - ì œì•ˆí•  ë•Œ ì‚¬ìš©ìì˜ ì—­í• ê³¼ ìƒí™©ì„ ê³ ë ¤í•˜ì„¸ìš” (ì˜ˆ: ê²©ì‹, ì–´ì¡°, ë§¥ë½ ì ì ˆì„±)
4. ë‚œì´ë„ë³„ ì±„ì  ê¸°ì¤€ (1-10):

**{scenario.difficulty.upper()} ë‚œì´ë„ ê¸°ì¤€:**

{'BEGINNER ê¸°ì¤€:' if scenario.difficulty == 'beginner' else ''}
{'- ë¬¸ë²• (30%): ê¸°ë³¸ ë¬¸ì¥ êµ¬ì¡°, í˜„ì¬/ê³¼ê±° ì‹œì œë§Œ ê²€ì‚¬, ê°„ë‹¨í•œ ê´€ì‚¬ ì‚¬ìš©' if scenario.difficulty == 'beginner' else ''}
{'- ì–´íœ˜ (25%): ê¸°ë³¸ ì¼ìƒ ì–´íœ˜ ì‚¬ìš© ì—¬ë¶€, ë³µì¡í•œ í‘œí˜„ ìš”êµ¬í•˜ì§€ ì•ŠìŒ' if scenario.difficulty == 'beginner' else ''}
{'- ìœ ì°½ì„± (25%): ì˜ì‚¬ì†Œí†µ ê°€ëŠ¥ ì—¬ë¶€ì— ì§‘ì¤‘, ì™„ë²½í•œ ë¬¸ì¥ êµ¬ì¡° ìš”êµ¬í•˜ì§€ ì•ŠìŒ' if scenario.difficulty == 'beginner' else ''}
{'- ë°œìŒ (20%): ì´í•´ ê°€ëŠ¥í•œ ìˆ˜ì¤€ì´ë©´ ì¶©ë¶„' if scenario.difficulty == 'beginner' else ''}
{'- í‰ê°€ ê¸°ì¤€: ì˜ë¯¸ ì „ë‹¬ ê°€ëŠ¥í•˜ë©´ 7ì  ì´ìƒ, ê¸°ë³¸ ë¬¸ë²•ë§Œ ë§ì•„ë„ ê¸ì •ì  í‰ê°€' if scenario.difficulty == 'beginner' else ''}

{'INTERMEDIATE ê¸°ì¤€:' if scenario.difficulty == 'intermediate' else ''}
{'- ë¬¸ë²• (30%): ë‹¤ì–‘í•œ ì‹œì œ, ê´€ì‚¬, ì „ì¹˜ì‚¬ ì •í™•ë„' if scenario.difficulty == 'intermediate' else ''}
{'- ì–´íœ˜ (25%): ë¹„ì¦ˆë‹ˆìŠ¤ ìš©ì–´ ì ì ˆí•œ ì‚¬ìš©, ìì—°ìŠ¤ëŸ¬ìš´ í‘œí˜„' if scenario.difficulty == 'intermediate' else ''}
{'- ìœ ì°½ì„± (25%): ìì—°ìŠ¤ëŸ¬ìš´ íë¦„, ë§¥ë½ ì ì ˆì„±, ë¹„ì¦ˆë‹ˆìŠ¤ ì˜ˆì ˆ' if scenario.difficulty == 'intermediate' else ''}
{'- ë°œìŒ (20%): ëª…í™•í•˜ê³  ìì‹ ê° ìˆëŠ” ë°œìŒ' if scenario.difficulty == 'intermediate' else ''}
{'- í‰ê°€ ê¸°ì¤€: ì¼ë°˜ì ì¸ ë¹„ì¦ˆë‹ˆìŠ¤ ì†Œí†µ ê°€ëŠ¥í•˜ë©´ 7ì  ì´ìƒ' if scenario.difficulty == 'intermediate' else ''}

{'ADVANCED ê¸°ì¤€:' if scenario.difficulty == 'advanced' else ''}
{'- ë¬¸ë²• (30%): ì™„ë²½í•œ ë¬¸ë²•, ë³µì¡í•œ êµ¬ì¡°, ë¯¸ë¬˜í•œ ë‰˜ì•™ìŠ¤' if scenario.difficulty == 'advanced' else ''}
{'- ì–´íœ˜ (25%): ì „ë¬¸ ìš©ì–´ ì •í™•í•œ ì‚¬ìš©, ê´€ìš©êµ¬, ì„¸ë ¨ëœ í‘œí˜„' if scenario.difficulty == 'advanced' else ''}
{'- ìœ ì°½ì„± (25%): ì›ì–´ë¯¼ ìˆ˜ì¤€ì˜ ìì—°ìŠ¤ëŸ¬ì›€, ì „ëµì  ì»¤ë®¤ë‹ˆì¼€ì´ì…˜' if scenario.difficulty == 'advanced' else ''}
{'- ë°œìŒ (20%): ì›ì–´ë¯¼ì— ê°€ê¹Œìš´ ì–µì–‘ê³¼ ë¦¬ë“¬' if scenario.difficulty == 'advanced' else ''}
{'- í‰ê°€ ê¸°ì¤€: ì›ì–´ë¯¼ ìˆ˜ì¤€ ìš”êµ¬, 9-10ì ì€ ì „ë¬¸ê°€ ìˆ˜ì¤€ë§Œ ê°€ëŠ¥' if scenario.difficulty == 'advanced' else ''}

ì ìˆ˜ ê°€ì´ë“œ:
   - 9-10: íƒì›”í•¨, í•´ë‹¹ ë‚œì´ë„ì—ì„œ ìµœê³  ìˆ˜ì¤€
   - 7-8: ì¢‹ìŒ, í•´ë‹¹ ë‚œì´ë„ ëª©í‘œ ë‹¬ì„±
   - 5-6: ë³´í†µ, ê°œì„  í•„ìš”
   - 3-4: ë¶€ì¡±í•¨, ì£¼ìš” ê°œì„  í•„ìš”
   - 1-2: ë§¤ìš° ë¶€ì¡±í•¨, ê¸°ë³¸ë¶€í„° ë‹¤ì‹œ

í•œê¸€ í…ìŠ¤íŠ¸ë¡œ JSON í˜•ì‹ì˜ í”¼ë“œë°±ì„ ì œê³µí•˜ì„¸ìš”."""

            # pronunciation_detailsê°€ ìˆìœ¼ë©´ ì¶”ê°€ ì •ë³´ ì œê³µ
            pronunciation_info = ""
            if pronunciation_details:
                pronunciation_info = f"""

Azure ë°œìŒ í‰ê°€ ê²°ê³¼:
- ì „ì²´ ë°œìŒ ì ìˆ˜: {pronunciation_details['pronunciation_score']:.1f}/100
- ì •í™•ë„ ì ìˆ˜: {pronunciation_details['accuracy_score']:.1f}/100
- ìœ ì°½ì„± ì ìˆ˜: {pronunciation_details['fluency_score']:.1f}/100
- ìš´ìœ¨ ì ìˆ˜ (ì–µì–‘/ê°•ì„¸): {pronunciation_details['prosody_score']:.1f}/100
- ì™„ì„±ë„ ì ìˆ˜: {pronunciation_details['completeness_score']:.1f}/100

ë°œìŒ ë¬¸ì œê°€ ìˆëŠ” ë‹¨ì–´ë“¤ (ì •í™•ë„ < 80):
{chr(10).join([f"- '{word['word']}': {word['accuracy_score']:.1f}/100" for word in pronunciation_details['words'] if word['accuracy_score'] < 80][:5]) if any(w['accuracy_score'] < 80 for w in pronunciation_details['words']) else '(ëª¨ë“  ë‹¨ì–´ê°€ ì˜ ë°œìŒë˜ì—ˆìŠµë‹ˆë‹¤)'}

ì´ ì ìˆ˜ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë‹¤ìŒì— ëŒ€í•œ êµ¬ì²´ì ì¸ í”¼ë“œë°±ì„ ì œê³µí•˜ì„¸ìš”:
1. ìš´ìœ¨ (Prosody): prosody_score < 80ì¸ ê²½ìš°, ì–µì–‘(intonation), ê°•ì„¸(stress), ë˜ëŠ” ë¦¬ë“¬(rhythm) ë¬¸ì œë¥¼ ì„¤ëª…í•˜ì„¸ìš”
2. ë¬¸ì œ ë‹¨ì–´: ë‚®ì€ ì •í™•ë„ ì ìˆ˜ë¥¼ ë°›ì€ íŠ¹ì • ë‹¨ì–´ë¥¼ ì–¸ê¸‰í•˜ì„¸ìš”
3. ì „ë°˜ì ì¸ ë°œìŒ ê°œì„  íŒ"""

            # ë¯¸ì‚¬ìš© ìš©ì–´ ê³„ì‚°
            required_terms = scenario.required_terminology or []
            missed_terms = [term for term in required_terms if term.lower() not in user_message.lower()]

            # Step terminology ì‚¬ìš© í‰ê°€ë¥¼ ìœ„í•œ ì„¹ì…˜
            step_terminology_section = ""
            if step_terminology:
                step_terminology_section = f"""

í˜„ì¬ ë‹¨ê³„ í‘œí˜„ ë¶„ì„:
- ì´ ë‹¨ê³„ì—ì„œ ê¶Œì¥í•˜ëŠ” í‘œí˜„: {', '.join(step_terminology)}
- ì‚¬ìš©ìê°€ ì´ í‘œí˜„ë“¤ ì¤‘ í•˜ë‚˜ë¥¼ ì‚¬ìš©í–ˆê±°ë‚˜ ì˜ë¯¸ì ìœ¼ë¡œ ë¹„ìŠ·í•œ í‘œí˜„ì„ ì¼ë‹¤ë©´ ê¸ì •ì ìœ¼ë¡œ í‰ê°€í•´ì£¼ì„¸ìš”
- ì™„ì „íˆ ë™ì¼í•œ í‘œí˜„ì´ ì•„ë‹ˆì–´ë„, ì˜ë¯¸ì™€ ì˜ë„ê°€ ë¹„ìŠ·í•˜ë©´ ì‚¬ìš©í•œ ê²ƒìœ¼ë¡œ ì¸ì •í•©ë‹ˆë‹¤
- ì˜ˆ: "I'd like to discuss" ê¶Œì¥ í‘œí˜„ì— ëŒ€í•´ "Can we talk about" ì‚¬ìš© â†’ ì˜ë¯¸ì ìœ¼ë¡œ ìœ ì‚¬í•˜ë¯€ë¡œ ì¸ì •"""

            user_prompt = f"""ì‚¬ìš©ì ë©”ì‹œì§€: "{user_message}"

ì „ë¬¸ìš©ì–´ ë¶„ì„:
- í•„ìˆ˜ ì „ë¬¸ìš©ì–´: {', '.join(required_terms) if required_terms else 'ì—†ìŒ'}
- ì‚¬ìš©í•œ ìš©ì–´: {', '.join(detected_terms) if detected_terms else 'ì—†ìŒ'}
- ë¯¸ì‚¬ìš© ìš©ì–´: {', '.join(missed_terms) if missed_terms else 'ì—†ìŒ'}{step_terminology_section}
{pronunciation_info}

ë‹¤ìŒì˜ ì •í™•í•œ JSON í˜•ì‹ìœ¼ë¡œ í”¼ë“œë°±ì„ ì œê³µí•˜ì„¸ìš” (ëª¨ë“  í…ìŠ¤íŠ¸ í•œê¸€ë¡œ):
{{
  "grammar_corrections": [
    "<ì‹¤ì œ ë¬¸ë²• ì˜¤ë¥˜ê°€ ìˆìœ¼ë©´ ì—¬ê¸°ì— ì‘ì„±. ì˜¤ë¥˜ê°€ ì—†ìœ¼ë©´ ë¹ˆ ë°°ì—´ []>"
  ],
  "terminology_usage": {{
    "used": {json.dumps(detected_terms or [], ensure_ascii=False)},
    "missed": {json.dumps(missed_terms, ensure_ascii=False)},
    "feedback": "í•„ìˆ˜ ìš©ì–´ ì‚¬ìš©ì— ëŒ€í•œ í”¼ë“œë°±ì„ ì—¬ê¸°ì— ì‘ì„±í•˜ì„¸ìš”",
    "step_expression": {{
      "recommended": {json.dumps(step_terminology, ensure_ascii=False)},
      "used_similar": "<ì‚¬ìš©ìê°€ ê¶Œì¥ í‘œí˜„ê³¼ ìœ ì‚¬í•œ í‘œí˜„ì„ ì‚¬ìš©í–ˆëŠ”ì§€ ì—¬ë¶€ (true/false)>",
      "user_expression": "<ì‚¬ìš©ìê°€ ì‚¬ìš©í•œ ìœ ì‚¬ í‘œí˜„ (ìˆë‹¤ë©´)>",
      "feedback": "<ê¶Œì¥ í‘œí˜„ ì‚¬ìš©ì— ëŒ€í•œ í”¼ë“œë°±. ìœ ì‚¬ í‘œí˜„ ì¼ìœ¼ë©´ ì¹­ì°¬, ì•ˆ ì¼ìœ¼ë©´ ë‹¤ìŒì— ì¨ë³´ë¼ê³  ê¶Œìœ >"
    }}
  }},
  "suggestions": [
    "<ì‹¤ì œ ê°œì„  ì œì•ˆì´ ìˆìœ¼ë©´ ì—¬ê¸°ì— ì‘ì„±>"
  ],
  "pronunciation_feedback": [
    "<ë°œìŒ í‰ê°€ ë°ì´í„° ê¸°ë°˜ ì‹¤ì œ í”¼ë“œë°±>"
  ],
  "score": 7,
  "score_breakdown": {{
    "grammar": 6,
    "vocabulary": 8,
    "fluency": 7,
    "pronunciation": 7
  }}
}}

ì¤‘ìš”í•œ ê·œì¹™:
- grammar_corrections: ì‚¬ìš©ì ë©”ì‹œì§€ì— **ì‹¤ì œë¡œ ì¡´ì¬í•˜ëŠ”** ë¬¸ë²• ì˜¤ë¥˜ë§Œ ì§€ì í•˜ì„¸ìš”. ì˜¤ë¥˜ê°€ ì—†ìœ¼ë©´ ë¹ˆ ë°°ì—´ []ì„ ë°˜í™˜í•˜ì„¸ìš”.
- ì˜ˆì‹œë‚˜ í…œí”Œë¦¿ ë¬¸êµ¬ë¥¼ ê·¸ëŒ€ë¡œ ë³µì‚¬í•˜ì§€ ë§ˆì„¸ìš”. ì˜¤ì§ ì‚¬ìš©ì ë©”ì‹œì§€ ë¶„ì„ ê²°ê³¼ë§Œ ì‘ì„±í•˜ì„¸ìš”.
- ë¬¸ë²•ì ìœ¼ë¡œ ì™„ë²½í•œ ë¬¸ì¥ì— ëŒ€í•´ ê±°ì§“ ì˜¤ë¥˜ë¥¼ ë§Œë“¤ì–´ë‚´ì§€ ë§ˆì„¸ìš”.

ì¤‘ìš”:
- terminology_usageì˜ usedì™€ missed ë°°ì—´ì€ ìœ„ì—ì„œ ì œê³µí•œ ê°’ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ì„¸ìš”
- terminology_usage.feedbackì—ëŠ” ìš©ì–´ ì‚¬ìš©ì— ëŒ€í•œ êµ¬ì²´ì ì¸ í”¼ë“œë°±ì„ í•œê¸€ë¡œ ì‘ì„±í•˜ì„¸ìš”
- terminology_usage.step_expression: í˜„ì¬ ë‹¨ê³„ ê¶Œì¥ í‘œí˜„ ì‚¬ìš© ì—¬ë¶€ë¥¼ í‰ê°€í•˜ì„¸ìš” (ì˜ë¯¸ì  ìœ ì‚¬ì„± ê¸°ì¤€)
- ë°œìŒ í‰ê°€ ë°ì´í„°ê°€ ì œê³µë˜ë©´, êµ¬ì²´ì ì¸ íŒê³¼ í•¨ê»˜ "pronunciation_feedback" ë°°ì—´ì„ ë°˜ë“œì‹œ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤
- prosody_score < 80ì¸ ê²½ìš°: ì–µì–‘(intonation), ê°•ì„¸(stress), ë˜ëŠ” ë¦¬ë“¬(rhythm)ì— ëŒ€í•œ í”¼ë“œë°±ì„ ì œê³µí•˜ì„¸ìš”
- ë‚®ì€ ì •í™•ë„ë¥¼ ê°€ì§„ ë‹¨ì–´ê°€ ìˆë‹¤ë©´: í•´ë‹¹ íŠ¹ì • ë‹¨ì–´ì™€ ê°œì„  ë°©ë²•ì„ ì–¸ê¸‰í•˜ì„¸ìš”
- ëª¨ë“  ì„¤ëª…ì€ í•œê¸€ë¡œ ì‘ì„±í•˜ë˜, í•œê¸€ í…ìŠ¤íŠ¸ ì•ˆì— ì˜ì–´ ë‹¨ì–´/êµì •ì„ í¬í•¨í•˜ì„¸ìš”"""

            response = await self.client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                temperature=0.7,
                max_tokens=800,
                response_format={"type": "json_object"}
            )

            # JSON íŒŒì‹± (jsonì€ íŒŒì¼ ìƒë‹¨ì—ì„œ ì´ë¯¸ importë¨)
            feedback = json.loads(response.choices[0].message.content)

            # ë°œìŒ ìƒì„¸ ì •ë³´ ì¶”ê°€ (ìˆëŠ” ê²½ìš°)
            if pronunciation_details:
                feedback['pronunciation_details'] = pronunciation_details

            # í”¼ë“œë°±ì„ ë§ˆì§€ë§‰ ì‚¬ìš©ì ë©”ì‹œì§€ì— ì €ì¥
            await self._save_feedback_to_message(
                db=db,
                scenario_id=scenario_id,
                user_id=user_id,
                user_message=user_message,
                feedback=json.dumps(feedback, ensure_ascii=False)
            )

            return feedback

        except Exception as e:
            logger.error(f"Error generating feedback: {str(e)}")
            raise

    async def translate_message(
        self,
        message: str,
        target_language: str = "ko"
    ) -> str:
        """
        ë©”ì‹œì§€ ë²ˆì—­ (GPT-4o ì‚¬ìš©)

        Args:
            message: ë²ˆì—­í•  ë©”ì‹œì§€
            target_language: ëª©í‘œ ì–¸ì–´ (ê¸°ë³¸ê°’: "ko" í•œêµ­ì–´)

        Returns:
            ë²ˆì—­ëœ í…ìŠ¤íŠ¸
        """
        try:
            language_names = {
                "ko": "Korean (í•œêµ­ì–´)",
                "en": "English",
                "ja": "Japanese (æ—¥æœ¬èª)",
                "zh": "Chinese (ä¸­æ–‡)",
                "vi": "Vietnamese (Tiáº¿ng Viá»‡t)"
            }

            target_lang_name = language_names.get(target_language, "Korean (í•œêµ­ì–´)")

            system_prompt = f"""ë‹¹ì‹ ì€ ì „ë¬¸ ë²ˆì—­ê°€ì…ë‹ˆë‹¤.
ì£¼ì–´ì§„ í…ìŠ¤íŠ¸ë¥¼ {target_lang_name}ë¡œ ë²ˆì—­í•˜ì„¸ìš”.
ì„¤ëª…ì´ë‚˜ ì¶”ê°€ ì½”ë©˜íŠ¸ ì—†ì´ ë²ˆì—­ëœ í…ìŠ¤íŠ¸ë§Œ ì œê³µí•˜ì„¸ìš”."""

            response = await self.client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": message}
                ],
                temperature=0.3,
                max_tokens=500
            )

            translated_text = response.choices[0].message.content.strip()
            return translated_text

        except Exception as e:
            logger.error(f"Error translating message: {str(e)}")
            raise

    async def reset_conversation(
        self,
        scenario_id: str,
        user_id: UUID
    ) -> None:
        """
        ëŒ€í™” ì´ˆê¸°í™” - í•´ë‹¹ ì‹œë‚˜ë¦¬ì˜¤ì˜ ëª¨ë“  ì„¸ì…˜ ë° ë©”ì‹œì§€ ì‚­ì œ

        Args:
            scenario_id: ì‹œë‚˜ë¦¬ì˜¤ ID
            user_id: ì‚¬ìš©ì ID
        """
        try:
            db = next(get_db())
            from app.models.conversation import ConversationSession

            # í•´ë‹¹ ì‹œë‚˜ë¦¬ì˜¤ì˜ ëª¨ë“  ì„¸ì…˜ ì‚­ì œ (CASCADEë¡œ ë©”ì‹œì§€ë„ ìë™ ì‚­ì œ)
            deleted_count = db.query(ConversationSession).filter(
                ConversationSession.scenario_id == UUID(scenario_id),
                ConversationSession.user_id == user_id
            ).delete()

            db.commit()
            logger.info(f"Reset conversation for scenario {scenario_id}: deleted {deleted_count} sessions")

        except Exception as e:
            logger.error(f"Error resetting conversation: {str(e)}")
            if db:
                db.rollback()
            raise

    async def get_conversation_history(
        self,
        scenario_id: str,
        user_id: UUID
    ) -> Dict[str, Any]:
        """
        ì €ì¥ëœ ëŒ€í™” íˆìŠ¤í† ë¦¬ ì¡°íšŒ

        Args:
            scenario_id: ì‹œë‚˜ë¦¬ì˜¤ ID
            user_id: ì‚¬ìš©ì ID

        Returns:
            ì„¸ì…˜ ì •ë³´ ë° ë©”ì‹œì§€ ëª©ë¡
        """
        try:
            db = next(get_db())
            from app.models.conversation import ConversationSession, ConversationMessage

            # ê°€ì¥ ìµœê·¼ active ì„¸ì…˜ ì¡°íšŒ
            session = db.query(ConversationSession).filter(
                ConversationSession.scenario_id == UUID(scenario_id),
                ConversationSession.user_id == user_id,
                ConversationSession.status == 'active'
            ).order_by(ConversationSession.started_at.desc()).first()

            if not session:
                return {
                    "sessionId": None,
                    "messages": []
                }

            # ì„¸ì…˜ì˜ ë©”ì‹œì§€ë“¤ ì¡°íšŒ
            messages = db.query(ConversationMessage).filter(
                ConversationMessage.session_id == session.id
            ).order_by(ConversationMessage.sequence_number.asc()).all()

            message_list = [
                {
                    "id": str(msg.id),
                    "sender": msg.sender,
                    "message": msg.message_text,
                    "translatedText": msg.translated_text,
                    "detectedTerms": msg.detected_terms or [],
                    "feedback": msg.feedback,
                    "sequenceNumber": msg.sequence_number,
                    "createdAt": msg.created_at.isoformat()
                }
                for msg in messages
            ]

            return {
                "sessionId": str(session.id),
                "status": session.status,
                "startedAt": session.started_at.isoformat(),
                "totalMessages": session.total_messages,
                "messages": message_list
            }

        except Exception as e:
            logger.error(f"Error getting conversation history: {str(e)}")
            raise

    async def _get_or_create_session(
        self,
        db,
        scenario_id: str,
        user_id: UUID
    ):
        """
        ì„¸ì…˜ ê°€ì ¸ì˜¤ê¸° ë˜ëŠ” ìƒì„±

        Args:
            db: ë°ì´í„°ë² ì´ìŠ¤ ì„¸ì…˜
            scenario_id: ì‹œë‚˜ë¦¬ì˜¤ ID
            user_id: ì‚¬ìš©ì ID

        Returns:
            ConversationSession ê°ì²´
        """
        from app.models.conversation import ConversationSession
        from app.models.scenario import Scenario

        # ê¸°ì¡´ active ì„¸ì…˜ ì°¾ê¸°
        session = db.query(ConversationSession).filter(
            ConversationSession.scenario_id == UUID(scenario_id),
            ConversationSession.user_id == user_id,
            ConversationSession.status == 'active'
        ).order_by(ConversationSession.started_at.desc()).first()

        if session:
            return session

        # ì„¸ì…˜ì´ ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„±
        scenario = db.query(Scenario).filter(Scenario.id == UUID(scenario_id)).first()

        new_session = ConversationSession(
            user_id=user_id,
            scenario_id=UUID(scenario_id),
            status='active',
            user_role=scenario.roles.get('user', 'User') if scenario else None,
            ai_role=scenario.roles.get('ai', 'AI') if scenario else None,
            total_messages=0
        )
        db.add(new_session)
        db.commit()
        db.refresh(new_session)

        logger.info(f"Created new conversation session: {new_session.id}")
        return new_session

    async def _save_message(
        self,
        db,
        session_id: UUID,
        sender: str,
        message_text: str,
        sequence_number: int,
        translated_text: str = None,
        detected_terms: List[str] = None,
        feedback: str = None
    ) -> None:
        """
        ë©”ì‹œì§€ë¥¼ DBì— ì €ì¥

        Args:
            db: ë°ì´í„°ë² ì´ìŠ¤ ì„¸ì…˜
            session_id: ì„¸ì…˜ ID
            sender: ë°œì‹ ì ('user' or 'ai')
            message_text: ë©”ì‹œì§€ ë‚´ìš©
            sequence_number: ë©”ì‹œì§€ ìˆœì„œ
            translated_text: ë²ˆì—­ëœ í…ìŠ¤íŠ¸ (ì„ íƒ)
            detected_terms: ê°ì§€ëœ ì „ë¬¸ìš©ì–´ (ì„ íƒ)
            feedback: í”¼ë“œë°± (ì„ íƒ)
        """
        from app.models.conversation import ConversationMessage, ConversationSession

        new_message = ConversationMessage(
            session_id=session_id,
            sender=sender,
            message_text=message_text,
            translated_text=translated_text,
            detected_terms=detected_terms,
            feedback=feedback,
            sequence_number=sequence_number
        )
        db.add(new_message)

        # ì„¸ì…˜ì˜ total_messages ì¦ê°€
        session = db.query(ConversationSession).filter(
            ConversationSession.id == session_id
        ).first()
        if session:
            session.total_messages += 1

        db.commit()
        logger.info(f"Saved message: session={session_id}, sender={sender}, seq={sequence_number}")

    async def _save_feedback_to_message(
        self,
        db,
        scenario_id: str,
        user_id: UUID,
        user_message: str,
        feedback: str
    ) -> None:
        """
        ì‚¬ìš©ì ë©”ì‹œì§€ì— í”¼ë“œë°± ì €ì¥

        Args:
            db: ë°ì´í„°ë² ì´ìŠ¤ ì„¸ì…˜
            scenario_id: ì‹œë‚˜ë¦¬ì˜¤ ID
            user_id: ì‚¬ìš©ì ID
            user_message: ì‚¬ìš©ì ë©”ì‹œì§€ (ë§¤ì¹­ìš©)
            feedback: í”¼ë“œë°± JSON ë¬¸ìì—´
        """
        from app.models.conversation import ConversationSession, ConversationMessage

        # í•´ë‹¹ ì‹œë‚˜ë¦¬ì˜¤ì˜ active ì„¸ì…˜ ì°¾ê¸°
        session = db.query(ConversationSession).filter(
            ConversationSession.scenario_id == UUID(scenario_id),
            ConversationSession.user_id == user_id,
            ConversationSession.status == 'active'
        ).order_by(ConversationSession.started_at.desc()).first()

        if not session:
            logger.warning(f"No active session found for scenario {scenario_id}")
            return

        # í•´ë‹¹ ì„¸ì…˜ì—ì„œ ë©”ì‹œì§€ í…ìŠ¤íŠ¸ê°€ ì¼ì¹˜í•˜ëŠ” ê°€ì¥ ìµœê·¼ ì‚¬ìš©ì ë©”ì‹œì§€ ì°¾ê¸°
        message = db.query(ConversationMessage).filter(
            ConversationMessage.session_id == session.id,
            ConversationMessage.sender == 'user',
            ConversationMessage.message_text == user_message
        ).order_by(ConversationMessage.sequence_number.desc()).first()

        if message:
            message.feedback = feedback
            db.commit()
            logger.info(f"Saved feedback for message: session={session.id}, seq={message.sequence_number}")
        else:
            logger.warning(f"User message not found for feedback: {user_message[:50]}...")

    async def generate_hint(
        self,
        scenario_id: str,
        conversation_history: List[Dict[str, str]],
        last_ai_message: str,
        user_id: UUID,
        current_step: Dict[str, Any] = None
    ) -> Dict[str, Any]:
        """
        ë‹¨ê³„ë³„ ëŒ€í™” íŒíŠ¸ ìƒì„±

        ì‹œë‚˜ë¦¬ì˜¤ ë§¥ë½ê³¼ í˜„ì¬ stepì˜ terminologyë¥¼ ê¸°ë°˜ìœ¼ë¡œ
        ë‹¨ì–´ â†’ êµ¬ë¬¸ â†’ ë¬¸ì¥ ìˆœì„œì˜ ë‹¨ê³„ë³„ íŒíŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

        Args:
            scenario_id: ì‹œë‚˜ë¦¬ì˜¤ ID
            conversation_history: ëŒ€í™” íˆìŠ¤í† ë¦¬
            last_ai_message: ë§ˆì§€ë§‰ AI ë©”ì‹œì§€
            user_id: ì‚¬ìš©ì ID
            current_step: í˜„ì¬ ëŒ€í™” ë‹¨ê³„ ì •ë³´ (ì„ íƒ)
                - name: ë‹¨ê³„ ì˜ë¬¸ ì‹ë³„ì
                - title: ë‹¨ê³„ í•œê¸€ ì œëª©
                - guide: ë‹¨ê³„ ê°€ì´ë“œ
                - terminology: ì´ ë‹¨ê³„ì—ì„œ ì‚¬ìš©í•  í‘œí˜„ ë¦¬ìŠ¤íŠ¸

        Returns:
            ë‹¨ê³„ë³„ íŒíŠ¸:
                - targetExpression: ëª©í‘œ í‘œí˜„
                - wordHints: í•µì‹¬ ë‹¨ì–´ ë¦¬ìŠ¤íŠ¸
                - phraseHint: ë¹ˆì¹¸ì´ í¬í•¨ëœ êµ¬ë¬¸
                - fullSentence: ì™„ì „í•œ ë¬¸ì¥
                - explanation: í•œêµ­ì–´ ì„¤ëª…
                - stepInfo: í˜„ì¬ ë‹¨ê³„ ì •ë³´
        """
        try:
            # DBì—ì„œ ì‹œë‚˜ë¦¬ì˜¤ ì¡°íšŒ
            db = next(get_db())
            from app.models.scenario import Scenario
            from agent.scenario.hint_agent import HintAgent

            scenario = db.query(Scenario).filter(
                Scenario.id == UUID(scenario_id),
                Scenario.user_id == user_id
            ).first()

            if not scenario:
                raise ValueError(f"Scenario not found: {scenario_id}")

            # ì‹œë‚˜ë¦¬ì˜¤ ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
            scenario_context = {
                "title": scenario.title,
                "description": scenario.description,
                "scenario_text": scenario.scenario_text,
                "roles": scenario.roles,
                "required_terminology": scenario.required_terminology or [],
                "difficulty": scenario.difficulty,
                "language": scenario.language,
                "category": scenario.category
            }

            # HintAgent í˜¸ì¶œ
            hint_agent = HintAgent()
            result = await hint_agent.process(
                scenario_context=scenario_context,
                conversation_history=conversation_history,
                last_ai_message=last_ai_message,
                current_step=current_step
            )

            step_name = current_step.get('name', 'N/A') if current_step else 'N/A'
            logger.info(f"Generated stepped hint for scenario {scenario_id}, step: {step_name}")

            return result

        except Exception as e:
            logger.error(f"Error generating hint: {str(e)}")
            raise

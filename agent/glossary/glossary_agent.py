"""
GPT-4o-mini ê¸°ë°˜ ìš©ì–´ì§‘ ì¶”ì¶œ ì—ì´ì „íŠ¸.
í…ìŠ¤íŠ¸ì—ì„œ ì „ë¬¸ ìš©ì–´ë¥¼ ì¶”ì¶œí•˜ê³ , ì •ì˜, ë§¥ë½, ì‹ ë¢°ë„ ì ìˆ˜ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
"""
import json
import math
import logging
from typing import List, Dict, Any
from agent.base_agent import BaseAgent
from app.core.text_utils import split_text_into_chunks, deduplicate_terms

logger = logging.getLogger(__name__)


class GlossaryAgent(BaseAgent):
    """
    ë¬¸ì„œì—ì„œ ì „ë¬¸ ìš©ì–´ë¥¼ ì¶”ì¶œí•˜ëŠ” AI ì—ì´ì „íŠ¸.

    GPT-4o-minië¥¼ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ë¥¼ ë¶„ì„í•˜ê³ , ë‹¤ì–‘í•œ ë¶„ì•¼ì˜ ì „ë¬¸ ìš©ì–´ë¥¼
    í•œêµ­ì–´/ì˜ì–´/ë² íŠ¸ë‚¨ì–´/ì¼ë³¸ì–´/ì¤‘êµ­ì–´ ë²ˆì—­, ì •ì˜, ë§¥ë½, ì‹ ë¢°ë„ ì ìˆ˜ì™€ í•¨ê»˜ ì¶”ì¶œí•©ë‹ˆë‹¤.

    ì‚¬ìš© ì˜ˆì‹œ:
        >>> agent = GlossaryAgent()
        >>> text = "í´ë¼ìš°ë“œ ì»´í“¨íŒ…ì€ ì¸í„°ë„·ì„ í†µí•´ IT ë¦¬ì†ŒìŠ¤ë¥¼ ì œê³µí•˜ëŠ” ì„œë¹„ìŠ¤ì…ë‹ˆë‹¤..."
        >>> terms = await agent.process(text, max_terms=50)
        >>> print(f"{len(terms)}ê°œ ìš©ì–´ ì¶”ì¶œë¨")
        >>> print(terms[0])
        {
            "korean": "í´ë¼ìš°ë“œ ì»´í“¨íŒ…",
            "english": "Cloud Computing",
            "abbreviation": "CC",
            "definition": "ì¸í„°ë„·ì„ í†µí•´ IT ë¦¬ì†ŒìŠ¤ë¥¼ ì œê³µí•˜ëŠ” ì„œë¹„ìŠ¤",
            "context": "í´ë¼ìš°ë“œ ì»´í“¨íŒ…ì€ ì¸í„°ë„·ì„ í†µí•´...",
            "domain": "IT",
            "confidence": 0.95
        }
    """

    def __init__(self):
        """ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ë¡œ GlossaryAgentë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤."""
        super().__init__()
        self.system_prompt = self._create_system_prompt()

    def _create_system_prompt(self) -> str:
        """
        GPT-4o-miniìš© ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

        ë°˜í™˜ê°’:
            ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ë¬¸ìì—´
        """
        return """
ë‹¹ì‹ ì€ ë‹¤ì–‘í•œ ë¶„ì•¼ì˜ ì „ë¬¸ ìš©ì–´ ì¶”ì¶œ ë° ë‹¤êµ­ì–´ ë²ˆì—­ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì£¼ì–´ì§„ í…ìŠ¤íŠ¸ì—ì„œ í•´ë‹¹ ë¶„ì•¼ì˜ ì „ë¬¸ ìš©ì–´ë¥¼ ì¶”ì¶œí•˜ê³ , í•œêµ­ì–´/ì˜ì–´/ë² íŠ¸ë‚¨ì–´/ì¼ë³¸ì–´/ì¤‘êµ­ì–´ë¡œ ë²ˆì—­í•˜ë©° ë¶„ì„í•©ë‹ˆë‹¤.

**ì§€ì› ë¶„ì•¼**:
- IT/ì†Œí”„íŠ¸ì›¨ì–´: í”„ë¡œê·¸ë˜ë°, ë„¤íŠ¸ì›Œí¬, í´ë¼ìš°ë“œ, ë³´ì•ˆ, ë°ì´í„°ë² ì´ìŠ¤ ë“±
- í”„ë¡œì íŠ¸ ê´€ë¦¬: ì• ìì¼, ìŠ¤í¬ëŸ¼, ì¼ì • ê´€ë¦¬, ë¦¬ìŠ¤í¬ ê´€ë¦¬ ë“±
- ë¹„ì¦ˆë‹ˆìŠ¤/ê²½ì˜: ì „ëµ, ë§ˆì¼€íŒ…, ì¸ì‚¬, ì¬ë¬´, ìš´ì˜ ë“±
- ì˜ë£Œ/í—¬ìŠ¤ì¼€ì–´: ì˜í•™ ìš©ì–´, ì•½í•™, ì˜ë£Œ ê¸°ê¸°, ì„ìƒ ë“±
- ë²•ë¥ /ë²•ë¬´: ê³„ì•½, ì†Œì†¡, ê·œì •, ì§€ì ì¬ì‚°ê¶Œ ë“±
- ê¸ˆìœµ/íšŒê³„: íˆ¬ì, ì€í–‰, ë³´í—˜, ì„¸ë¬´, ê°ì‚¬ ë“±
- ì œì¡°/ì—”ì§€ë‹ˆì–´ë§: ìƒì‚°, í’ˆì§ˆê´€ë¦¬, ì„¤ê³„, ìë™í™” ë“±
- ë§ˆì¼€íŒ…/ê´‘ê³ : ë¸Œëœë”©, ë””ì§€í„¸ ë§ˆì¼€íŒ…, PR, ë¯¸ë””ì–´ ë“±
- ê¸°íƒ€ ì „ë¬¸ ë¶„ì•¼: ë¬¸ì„œì˜ ë§¥ë½ì— ë”°ë¼ ìë™ ê°ì§€

**ì¶œë ¥ í˜•ì‹ (JSON)**:
{
  "terms": [
    {
      "korean": "í•œê¸€ ìš©ì–´",
      "english": "English term",
      "vietnamese": "Thuáº­t ngá»¯ tiáº¿ng Viá»‡t",
      "japanese": "æ—¥æœ¬èªã®ç”¨èª",
      "chinese": "ä¸­æ–‡æœ¯è¯­",
      "abbreviation": "ì•½ì–´ (ìˆëŠ” ê²½ìš°ë§Œ, ì—†ìœ¼ë©´ null)",
      "definition": "ìš©ì–´ì˜ ëª…í™•í•œ ì •ì˜ (1-2ë¬¸ì¥)",
      "context": "ë¬¸ì„œ ë‚´ì—ì„œ ì‚¬ìš©ëœ êµ¬ì²´ì ì¸ ë§¥ë½ (ì›ë¬¸ ì¸ìš©)",
      "example_sentence": "ìš©ì–´ ì‚¬ìš© ì˜ˆë¬¸ (ë¬¸ì„œì—ì„œ ë°œì·Œí•˜ê±°ë‚˜ ìƒì„±)",
      "note": "ì¶”ê°€ ì„¤ëª… ë° ì°¸ê³ ì‚¬í•­ (ìˆëŠ” ê²½ìš°ë§Œ, ì—†ìœ¼ë©´ null)",
      "domain": "ë¶„ì•¼ (IT, Healthcare, Legal, Finance, Manufacturing, Marketing, Business, Engineering ë“±)",
      "confidence": 0.95
    }
  ]
}

**ì¶”ì¶œ ê¸°ì¤€**:
1. ë¬¸ì„œì˜ ë¶„ì•¼ë¥¼ ìë™ìœ¼ë¡œ ê°ì§€í•˜ê³ , í•´ë‹¹ ë¶„ì•¼ì˜ ì „ë¬¸ ìš©ì–´ë¥¼ ì¶”ì¶œ
2. ì¼ë°˜ì ì¸ ë‹¨ì–´ëŠ” ì œì™¸í•˜ê³ , ì „ë¬¸ì ì´ê±°ë‚˜ ê¸°ìˆ ì ì¸ ìš©ì–´ë§Œ ì¶”ì¶œ
3. ë³µí•© ìš©ì–´ ìš°ì„  (ì˜ˆ: "ì»´í“¨í„°" ì œì™¸, "í´ë¼ìš°ë“œ ì»´í“¨íŒ…" í¬í•¨)
4. ì•½ì–´ëŠ” ë¬¸ì„œì—ì„œ ëª…í™•íˆ ì •ì˜ëœ ê²½ìš°ë§Œ í¬í•¨
5. ì •ì˜ëŠ” í•´ë‹¹ ë¶„ì•¼ì˜ ì „ë¬¸ì  ë§¥ë½ì—ì„œ ëª…í™•í•˜ê³  ê°„ê²°í•˜ê²Œ (1-2ë¬¸ì¥)
6. ë§¥ë½ì€ ì‹¤ì œ ë¬¸ì„œì—ì„œ ì‚¬ìš©ëœ ë¬¸ì¥ì„ ê·¸ëŒ€ë¡œ ì¸ìš©
7. ì˜ˆë¬¸ì€ ë¬¸ì„œì—ì„œ ë°œì·Œí•˜ê±°ë‚˜, ìì—°ìŠ¤ëŸ¬ìš´ ì˜ˆë¬¸ ìƒì„±
8. ì¶”ê°€ ì„¤ëª…ì€ ìš©ì–´ ì´í•´ì— ë„ì›€ì´ ë˜ëŠ” ì°¸ê³ ì‚¬í•­ ì œê³µ
9. ë‹¤êµ­ì–´ ë²ˆì—­ì€ í•´ë‹¹ ë¶„ì•¼ì˜ í‘œì¤€ ë²ˆì—­ ì‚¬ìš©:
   - ë² íŠ¸ë‚¨ì–´: Tiáº¿ng Viá»‡t (ë² íŠ¸ë‚¨ì–´)
   - ì¼ë³¸ì–´: æ—¥æœ¬èª (ì „ë¬¸ ë¶„ì•¼ë³„ í‘œì¤€ ìš©ì–´ ì‚¬ìš©)
   - ì¤‘êµ­ì–´: ç®€ä½“ä¸­æ–‡ (ê°„ì²´ ì¤‘êµ­ì–´, ì—…ê³„ í‘œì¤€ ë²ˆì—­ ì‚¬ìš©)
10. ì‹ ë¢°ë„ëŠ” í•´ë‹¹ ìš©ì–´ì˜ ì „ë¬¸ì„± ì •ë„ (0.0-1.0)
11. ë„ë©”ì¸ì€ ê°€ì¥ ì í•©í•œ ë¶„ì•¼ í•˜ë‚˜ë§Œ ì„ íƒ

**ì£¼ì˜ì‚¬í•­**:
- ì¤‘ë³µëœ ìš©ì–´ëŠ” í•˜ë‚˜ë§Œ í¬í•¨
- ìœ ì‚¬ ìš©ì–´ëŠ” ë³„ë„ë¡œ ì¶”ì¶œ (ì˜ˆ: "ë°ì´í„°ë² ì´ìŠ¤"ì™€ "ê´€ê³„í˜• ë°ì´í„°ë² ì´ìŠ¤"ëŠ” ë³„ê°œ)
- ì™¸ë˜ì–´ëŠ” ëª¨ë“  ì–¸ì–´ë¡œ ë²ˆì—­
- ê° ì–¸ì–´ ë²ˆì—­ì´ ì—†ëŠ” ê²½ìš°:
  * ë² íŠ¸ë‚¨ì–´: ì˜ì–´ë¥¼ ë² íŠ¸ë‚¨ì–´ë¡œ ë²ˆì—­
  * ì¼ë³¸ì–´: ì˜ì–´ë¥¼ ì¼ë³¸ì–´ë¡œ ë²ˆì—­ (ê¸°ìˆ  ìš©ì–´ëŠ” ê°€íƒ€ì¹´ë‚˜ ìš°ì„ )
  * ì¤‘êµ­ì–´: ì˜ì–´ë¥¼ ê°„ì²´ ì¤‘êµ­ì–´ë¡œ ë²ˆì—­ (ì—…ê³„ í‘œì¤€ ë²ˆì—­ ì‚¬ìš©)
- ì¼ë³¸ì–´ ë²ˆì—­ ì‹œ:
  * ê¸°ìˆ /ì™¸ë˜ì–´: ê°€íƒ€ì¹´ë‚˜ ì‚¬ìš© (ì˜ˆ: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹, ã‚¯ãƒ©ã‚¦ãƒ‰)
  * ì „í†µì  ìš©ì–´: í•œì ë˜ëŠ” íˆë¼ê°€ë‚˜ ì‚¬ìš©
  * í•„ìš”ì‹œ ë³‘ê¸° (ì˜ˆ: äººå·¥çŸ¥èƒ½(AI))
- ì¤‘êµ­ì–´ ë²ˆì—­ ì‹œ:
  * ê°„ì²´ì(ç®€ä½“å­—) ì‚¬ìš© í•„ìˆ˜
  * í•´ë‹¹ ë¶„ì•¼ì˜ ì¤‘êµ­ ì—…ê³„ í‘œì¤€ ë²ˆì—­ ì‚¬ìš©
  * ìŒì—­ë³´ë‹¤ëŠ” ì˜ì—­ ìš°ì„ 
- ì˜ë£Œ/ë²•ë¥  ë“± ì „ë¬¸ ë¶„ì•¼ëŠ” í•´ë‹¹ ë¶„ì•¼ì˜ ê³µì‹ ìš©ì–´ ì‚¬ìš©
- ë°˜ë“œì‹œ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µ
"""

    async def process(
        self,
        text: str,
        max_terms: int = 50,
        chunk_size: int = 5000
    ) -> List[Dict[str, Any]]:
        """
        í…ìŠ¤íŠ¸ì—ì„œ ìš©ì–´ì§‘ ìš©ì–´ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.

        ì²˜ë¦¬ ê³¼ì •:
        1. í…ìŠ¤íŠ¸ë¥¼ ì²­í¬ë¡œ ë¶„í• 
        2. ê° ì²­í¬ì—ì„œ GPT-4o-minië¥¼ ì‚¬ìš©í•˜ì—¬ ìš©ì–´ ì¶”ì¶œ
        3. ì²­í¬ ê°„ ìš©ì–´ ì¤‘ë³µ ì œê±°
        4. ì‹ ë¢°ë„ ì ìˆ˜ë¡œ ì •ë ¬
        5. ìƒìœ„ Nê°œ ìš©ì–´ ë°˜í™˜

        ë§¤ê°œë³€ìˆ˜:
            text: ìš©ì–´ë¥¼ ì¶”ì¶œí•  ì „ì²´ í…ìŠ¤íŠ¸
            max_terms: ë°˜í™˜í•  ìµœëŒ€ ìš©ì–´ ìˆ˜ (ê¸°ë³¸ê°’: 50)
            chunk_size: í…ìŠ¤íŠ¸ ì²­í¬ í¬ê¸° (ë¬¸ì ìˆ˜, ê¸°ë³¸ê°’: 5000)

        ë°˜í™˜ê°’:
            ì¶”ì¶œëœ ìš©ì–´ ë¦¬ìŠ¤íŠ¸. ê° ìš©ì–´ëŠ” ë‹¤ìŒì„ í¬í•¨:
                - korean: í•œêµ­ì–´ ìš©ì–´
                - english: ì˜ì–´ ìš©ì–´ (ì„ íƒì‚¬í•­)
                - abbreviation: ì•½ì–´ (ì„ íƒì‚¬í•­)
                - definition: ìš©ì–´ ì •ì˜
                - context: ë¬¸ì„œ ë‚´ ì‚¬ìš© ë§¥ë½
                - domain: ë¶„ì•¼ (IT, Healthcare, Legal ë“±)
                - confidence: ì‹ ë¢°ë„ ì ìˆ˜ (0.0-1.0)

        ì˜ˆì™¸:
            Exception: ì¶”ì¶œ ì‹¤íŒ¨ ì‹œ

        ì‚¬ìš© ì˜ˆì‹œ:
            >>> agent = GlossaryAgent()
            >>> text = load_document("document.pdf")
            >>> terms = await agent.process(text, max_terms=30)
            >>> for term in terms[:5]:
            ...     print(f"{term['korean']}: {term['definition']}")
        """
        logger.info(f"ğŸš€ ìš©ì–´ ì¶”ì¶œ ì‹œì‘ (í…ìŠ¤íŠ¸ ê¸¸ì´: {len(text)}ì, ìµœëŒ€ ìš©ì–´ ìˆ˜: {max_terms})")

        # 1. í…ìŠ¤íŠ¸ë¥¼ ì²­í¬ë¡œ ë¶„í• 
        chunks = split_text_into_chunks(text, chunk_size)

        # 2. ì²­í¬ë‹¹ ìš©ì–´ ìˆ˜ ê³„ì‚°
        terms_per_chunk = math.ceil(max_terms / len(chunks)) + 5  # ì¤‘ë³µ ì œê±°ë¥¼ ìœ„í•œ +5 ë²„í¼

        # 3. ê° ì²­í¬ì—ì„œ ìš©ì–´ ì¶”ì¶œ
        all_terms = []
        for i, chunk in enumerate(chunks, 1):
            logger.info(f"ğŸ“ ì²­í¬ ì²˜ë¦¬ ì¤‘ {i}/{len(chunks)}")
            try:
                terms = await self._extract_chunk(chunk, terms_per_chunk)
                all_terms.extend(terms)
            except Exception as e:
                logger.warning(f"ì²­í¬ {i} ì¶”ì¶œ ì‹¤íŒ¨: {str(e)}")
                continue

        if not all_terms:
            logger.warning("ì–´ë–¤ ì²­í¬ì—ì„œë„ ìš©ì–´ê°€ ì¶”ì¶œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
            return []

        logger.info(f"ğŸ“Š ì´ ì¶”ì¶œëœ ìš©ì–´ ìˆ˜: {len(all_terms)}")

        # 4. ìš©ì–´ ì¤‘ë³µ ì œê±°
        unique_terms = deduplicate_terms(all_terms)

        # 5. ì‹ ë¢°ë„ ê¸°ì¤€ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
        unique_terms.sort(key=lambda x: float(x.get('confidence', 0)), reverse=True)

        # 6. ìƒìœ„ Nê°œ ìš©ì–´ ë°˜í™˜
        result_terms = unique_terms[:max_terms]

        avg_confidence = sum(float(t.get('confidence', 0)) for t in result_terms) / len(result_terms)
        logger.info(f"âœ… ìš©ì–´ ì¶”ì¶œ ì™„ë£Œ: {len(result_terms)}ê°œ ìš©ì–´ (í‰ê·  ì‹ ë¢°ë„: {avg_confidence:.2f})")

        return result_terms

    async def _extract_chunk(
        self,
        text_chunk: str,
        terms_per_chunk: int = 20
    ) -> List[Dict[str, Any]]:
        """
        GPT-4o-minië¥¼ ì‚¬ìš©í•˜ì—¬ ë‹¨ì¼ í…ìŠ¤íŠ¸ ì²­í¬ì—ì„œ ìš©ì–´ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.

        process()ì—ì„œ ê° ì²­í¬ì— ëŒ€í•´ í˜¸ì¶œí•˜ëŠ” private ë©”ì„œë“œì…ë‹ˆë‹¤.

        ë§¤ê°œë³€ìˆ˜:
            text_chunk: ì²˜ë¦¬í•  í…ìŠ¤íŠ¸ ì²­í¬
            terms_per_chunk: ì¶”ì¶œí•  ìµœëŒ€ ìš©ì–´ ìˆ˜

        ë°˜í™˜ê°’:
            ì¶”ì¶œëœ ìš©ì–´ ë¦¬ìŠ¤íŠ¸

        ì˜ˆì™¸:
            Exception: API í˜¸ì¶œ ì‹¤íŒ¨ ì‹œ
        """
        try:
            user_prompt = f"""
ë‹¤ìŒ í…ìŠ¤íŠ¸ì—ì„œ ì „ë¬¸ ìš©ì–´ë¥¼ ì¶”ì¶œí•˜ì„¸ìš”.
ë¬¸ì„œì˜ ë¶„ì•¼ë¥¼ ìë™ìœ¼ë¡œ ê°ì§€í•˜ê³ , í•´ë‹¹ ë¶„ì•¼ì˜ ì „ë¬¸ ìš©ì–´ë¥¼ ì¶”ì¶œí•˜ì„¸ìš”.
ìµœëŒ€ {terms_per_chunk}ê°œì˜ ìš©ì–´ë¥¼ ì¶”ì¶œí•˜ë©°, ì‹ ë¢°ë„ê°€ ë†’ì€ ìˆœì„œë¡œ ì •ë ¬í•˜ì„¸ìš”.

í…ìŠ¤íŠ¸:
{text_chunk}
"""

            logger.info(f"GPT-4o-mini API í˜¸ì¶œ ì¤‘ (ì²­í¬ í¬ê¸°: {len(text_chunk)}ì)")

            response = await self.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": self.system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                temperature=0.3,  # ì¼ê´€ëœ ê²°ê³¼ë¥¼ ìœ„í•œ ë‚®ì€ temperature
                response_format={"type": "json_object"}
            )

            # ì‘ë‹µ íŒŒì‹±
            content = response.choices[0].message.content
            result = json.loads(content)
            terms = result.get('terms', [])

            logger.info(f"âœ… GPT-4o-miniê°€ {len(terms)}ê°œ ìš©ì–´ ë°˜í™˜")
            return terms

        except json.JSONDecodeError as e:
            logger.error(f"GPT-4o-mini ì‘ë‹µì„ JSONìœ¼ë¡œ íŒŒì‹± ì‹¤íŒ¨: {str(e)}")
            return []
        except Exception as e:
            logger.error(f"GPT-4o-mini API í˜¸ì¶œ ì‹¤íŒ¨: {str(e)}")
            raise Exception(f"GPT-4o-mini API ì—ëŸ¬: {str(e)}")

"""
ìš©ì–´ ë§¤ì¹­ Agent (Glossary Matcher Agent)

íƒì§€ëœ ìš©ì–´ë¥¼ ìš©ì–´ì§‘ê³¼ ë§¤ì¹­í•˜ì—¬ ìƒì„¸ ì •ë³´ë¥¼ ì œê³µí•˜ëŠ” Micro Agent.
ë‹¨ì¼ ì±…ì„: íƒì§€ëœ ìš©ì–´ + ìš©ì–´ì§‘ â†’ ìƒì„¸ ìš©ì–´ ì •ë³´

ì¬ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤:
- ë²ˆì—­: ìš©ì–´ ì„¤ëª… í‘œì‹œ
- ìš©ì–´ ìë™ ì™„ì„±: ì‚¬ìš©ì ì…ë ¥ ì‹œ ìš©ì–´ ì œì•ˆ
- ìš©ì–´ ì¼ê´€ì„± ê²€ì¦: ë²ˆì—­/ë¬¸ì„œ í’ˆì§ˆ ì²´í¬
- ìš©ì–´ íˆ´íŒ: ë¬¸ì„œ ì½ê¸° ì‹œ ìš©ì–´ ì„¤ëª… í‘œì‹œ
"""

from dataclasses import dataclass
from typing import List, Dict, Any, Optional
import logging
from agent.base_agent import BaseAgent
from .models import DetectedTerm

logger = logging.getLogger(__name__)


@dataclass
class MatchedTerm:
    """
    ìš©ì–´ì§‘ê³¼ ë§¤ì¹­ëœ ìš©ì–´ ìƒì„¸ ì •ë³´

    Attributes:
        matched_text: ë¬¸ì„œì—ì„œ ì‹¤ì œ ë§¤ì¹­ëœ í…ìŠ¤íŠ¸
        position_start: ì›ë¬¸ì—ì„œì˜ ì‹œì‘ ìœ„ì¹˜
        position_end: ì›ë¬¸ì—ì„œì˜ ì¢…ë£Œ ìœ„ì¹˜
        glossary_term_id: ìš©ì–´ì§‘ ìš©ì–´ ID (UUID)
        korean_term: í•œê¸€ ìš©ì–´
        english_term: ì˜ì–´ ìš©ì–´
        vietnamese_term: ë² íŠ¸ë‚¨ì–´ ìš©ì–´
        definition: ìš©ì–´ ì •ì˜
        context: ì‚¬ìš© ë§¥ë½
        example_sentence: ì˜ˆë¬¸
        note: ì¶”ê°€ ì„¤ëª…
        domain: ë¶„ì•¼
        confidence_score: ì‹ ë¢°ë„ ì ìˆ˜
    """
    matched_text: str
    position_start: int
    position_end: int
    glossary_term_id: str
    korean_term: str
    english_term: Optional[str] = None
    vietnamese_term: Optional[str] = None
    definition: Optional[str] = None
    context: Optional[str] = None
    example_sentence: Optional[str] = None
    note: Optional[str] = None
    domain: Optional[str] = None
    confidence_score: Optional[float] = None


class GlossaryMatcherAgent(BaseAgent):
    """
    íƒì§€ëœ ìš©ì–´ë¥¼ ìš©ì–´ì§‘ê³¼ ë§¤ì¹­í•˜ëŠ” Agent

    ì±…ì„: íƒì§€ëœ ìš©ì–´ + ìš©ì–´ì§‘ â†’ ìƒì„¸ ìš©ì–´ ì •ë³´

    OptimizedTermDetectorAgentê°€ íƒì§€í•œ ìš©ì–´ë¥¼ ìš©ì–´ì§‘ ë°ì´í„°ë² ì´ìŠ¤ì™€
    ë§¤ì¹­í•˜ì—¬ ì •ì˜, ë§¥ë½, ì˜ˆë¬¸ ë“± ìƒì„¸ ì •ë³´ë¥¼ ì œê³µí•©ë‹ˆë‹¤.

    ì˜ˆì‹œ:
        >>> agent = GlossaryMatcherAgent()
        >>> detected_terms = [...]  # OptimizedTermDetectorAgent ê²°ê³¼
        >>> glossary_full = [...]    # DBì—ì„œ ì¡°íšŒí•œ ì „ì²´ ìš©ì–´ì§‘
        >>> matched = await agent.process(detected_terms, glossary_full)
        >>> print(matched[0].definition)
        "ì¸í„°ë„·ì„ í†µí•´ IT ë¦¬ì†ŒìŠ¤ë¥¼ ì œê³µí•˜ëŠ” ì„œë¹„ìŠ¤"
    """

    async def process(
        self,
        detected_terms: List[DetectedTerm],
        glossary_terms: List[Dict[str, Any]]
    ) -> List[MatchedTerm]:
        """
        íƒì§€ëœ ìš©ì–´ë¥¼ ìš©ì–´ì§‘ê³¼ ë§¤ì¹­í•˜ì—¬ ìƒì„¸ ì •ë³´ ì œê³µ

        Args:
            detected_terms: OptimizedTermDetectorAgentì—ì„œ íƒì§€ëœ ìš©ì–´ ë¦¬ìŠ¤íŠ¸
            glossary_terms: ì „ì²´ ìš©ì–´ì§‘ (DBì—ì„œ ì¡°íšŒ, idì™€ ìƒì„¸ ì •ë³´ í¬í•¨)
                ê° ë”•ì…”ë„ˆë¦¬ëŠ” ë‹¤ìŒ í‚¤ë¥¼ í¬í•¨í•´ì•¼ í•¨:
                - id (í•„ìˆ˜): ìš©ì–´ UUID
                - korean_term (í•„ìˆ˜): í•œê¸€ ìš©ì–´
                - english_term (ì„ íƒ): ì˜ì–´ ìš©ì–´
                - vietnamese_term (ì„ íƒ): ë² íŠ¸ë‚¨ì–´ ìš©ì–´
                - definition (ì„ íƒ): ì •ì˜
                - context (ì„ íƒ): ë§¥ë½
                - example_sentence (ì„ íƒ): ì˜ˆë¬¸
                - note (ì„ íƒ): ì¶”ê°€ ì„¤ëª…
                - domain (ì„ íƒ): ë¶„ì•¼
                - confidence_score (ì„ íƒ): ì‹ ë¢°ë„

        Returns:
            ë§¤ì¹­ëœ ìš©ì–´ ë¦¬ìŠ¤íŠ¸ (ìƒì„¸ ì •ë³´ í¬í•¨)

        Raises:
            ValueError: ì…ë ¥ì´ ìœ íš¨í•˜ì§€ ì•Šì€ ê²½ìš°
        """
        if not detected_terms:
            logger.info("íƒì§€ëœ ìš©ì–´ê°€ ì—†ìŠµë‹ˆë‹¤")
            return []

        if not glossary_terms:
            logger.warning("âš ï¸ ìš©ì–´ì§‘ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤")
            return []

        logger.info(f"ğŸ” ìš©ì–´ ë§¤ì¹­ ì‹œì‘: {len(detected_terms)}ê°œ íƒì§€ â†’ {len(glossary_terms)}ê°œ ìš©ì–´ì§‘")

        # ë¹ ë¥¸ ì¡°íšŒë¥¼ ìœ„í•œ ìš©ì–´ì§‘ ë§µ ìƒì„±
        glossary_map = {
            term.get("korean_term"): term
            for term in glossary_terms
            if term.get("korean_term")
        }

        matched_terms: List[MatchedTerm] = []

        for detected in detected_terms:
            # ìš©ì–´ì§‘ì—ì„œ ë§¤ì¹­ë˜ëŠ” ìš©ì–´ ì°¾ê¸°
            glossary_entry = glossary_map.get(detected.korean_term)

            if glossary_entry:
                matched_terms.append(MatchedTerm(
                    matched_text=detected.matched_text,
                    position_start=detected.position_start,
                    position_end=detected.position_end,
                    glossary_term_id=str(glossary_entry.get("id", "")),
                    korean_term=detected.korean_term,
                    english_term=glossary_entry.get("english_term"),
                    vietnamese_term=glossary_entry.get("vietnamese_term"),
                    definition=glossary_entry.get("definition"),
                    context=glossary_entry.get("context"),
                    example_sentence=glossary_entry.get("example_sentence"),
                    note=glossary_entry.get("note"),
                    domain=glossary_entry.get("domain"),
                    confidence_score=glossary_entry.get("confidence_score")
                ))
            else:
                logger.warning(f"âš ï¸ ìš©ì–´ì§‘ì—ì„œ ë§¤ì¹­ ì‹¤íŒ¨: {detected.korean_term}")

        logger.info(f"âœ… ë§¤ì¹­ ì™„ë£Œ: {len(matched_terms)}/{len(detected_terms)}ê°œ ì„±ê³µ")

        return matched_terms

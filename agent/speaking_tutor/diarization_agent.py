"""
Azure Conversation Transcription APIë¥¼ ì‚¬ìš©í•œ í™”ì ë¶„ë¦¬ ì—ì´ì „íŠ¸.

ì˜¤ë””ì˜¤ íŒŒì¼ì„ ë¶„ì„í•˜ì—¬ ë‹¤ìŒ ì •ë³´ë¥¼ ì œê³µ:
- í™”ìë³„ë¡œ ë¶„ë¦¬ëœ ë°œí™” ë‚´ìš©
- íƒ€ì„ìŠ¤íƒ¬í”„ (ì‹œì‘/ì¢…ë£Œ ì‹œê°„)
- ì‹ ë¢°ë„ ì ìˆ˜
- í™”ì ìˆ˜

ì°¸ê³ :
https://learn.microsoft.com/en-us/azure/ai-services/speech-service/conversation-transcription
"""
import asyncio
import logging
import tempfile
import os
import wave
import threading
import time
from typing import List, Dict, Any, Optional, Callable
from dataclasses import dataclass

import azure.cognitiveservices.speech as speechsdk
from app.config import settings

logger = logging.getLogger(__name__)


@dataclass
class Utterance:
    """ë‹¨ì¼ ë°œí™”ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ë°ì´í„° í´ë˜ìŠ¤."""
    speaker_id: int
    text: str
    start_time_ms: int
    end_time_ms: int
    confidence: float
    sequence_number: int


class DiarizationAgent:
    """
    Azure Conversation Transcription ì—ì´ì „íŠ¸.

    ì˜¤ë””ì˜¤ íŒŒì¼ì„ ì²˜ë¦¬í•˜ì—¬ í™”ìë³„ë¡œ ë¶„ë¦¬ëœ í…ìŠ¤íŠ¸ë¥¼ ë°˜í™˜.

    ì£¼ì˜: Conversation Transcriptionì€ íŠ¹ì • ë¦¬ì „ì—ì„œë§Œ ì‚¬ìš© ê°€ëŠ¥:
    - eastasia, southeastasia, centralus, eastus, westeurope
    - í™”ì ë¶„ë¦¬ ê¸°ëŠ¥ì„ ìœ„í•´ AZURE_AVATAR_SPEECH_KEY/REGION (southeastasia) ì‚¬ìš©
    """

    SUPPORTED_FORMATS = {'.wav', '.mp3', '.m4a', '.ogg', '.flac', '.webm'}

    def __init__(self):
        """Azure Speech ì„¤ì •ìœ¼ë¡œ ì´ˆê¸°í™”."""
        # Conversation Transcriptionì„ ìœ„í•´ Avatar í‚¤/ë¦¬ì „ ì‚¬ìš©
        # koreacentralì€ Conversation Transcriptionì„ ì§€ì›í•˜ì§€ ì•ŠìŒ
        if not settings.AZURE_AVATAR_SPEECH_KEY:
            raise ValueError("AZURE_AVATAR_SPEECH_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤ (í™”ì ë¶„ë¦¬ì— í•„ìš”)")

        self.speech_key = settings.AZURE_AVATAR_SPEECH_KEY
        self.speech_region = settings.AZURE_AVATAR_SPEECH_REGION

        logger.info(f"DiarizationAgent ì´ˆê¸°í™” ì™„ë£Œ: ë¦¬ì „={self.speech_region}")

    async def process(
        self,
        audio_file_path: str,
        language: str = "en-US",
        progress_callback: Optional[Callable[[int, str], None]] = None
    ) -> Dict[str, Any]:
        """
        ì˜¤ë””ì˜¤ íŒŒì¼ì„ í™”ì ë¶„ë¦¬í•˜ì—¬ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜.

        Args:
            audio_file_path: ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
            language: ì–¸ì–´ ì½”ë“œ (ì˜ˆ: 'en-US', 'ko-KR')
            progress_callback: ì§„í–‰ë¥  ì½œë°± í•¨ìˆ˜ (percent, message)

        Returns:
            {
                "utterances": [
                    {
                        "speaker_id": 1,
                        "text": "Hello everyone",
                        "start_time_ms": 0,
                        "end_time_ms": 1500,
                        "confidence": 0.95,
                        "sequence_number": 0
                    },
                    ...
                ],
                "speaker_count": 3,
                "duration_seconds": 180.5
            }

        Raises:
            FileNotFoundError: ì˜¤ë””ì˜¤ íŒŒì¼ì´ ì—†ì„ ë•Œ
            ValueError: ì§€ì›í•˜ì§€ ì•ŠëŠ” ì˜¤ë””ì˜¤ í˜•ì‹ì¼ ë•Œ
        """
        if not os.path.exists(audio_file_path):
            raise FileNotFoundError(f"ì˜¤ë””ì˜¤ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {audio_file_path}")

        ext = os.path.splitext(audio_file_path)[1].lower()
        if ext not in self.SUPPORTED_FORMATS:
            raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì˜¤ë””ì˜¤ í˜•ì‹: {ext}")

        if progress_callback:
            progress_callback(5, "ì˜¤ë””ì˜¤ íŒŒì¼ ì¤€ë¹„ ì¤‘...")

        # WAVê°€ ì•„ë‹ˆë©´ ë³€í™˜ í•„ìš”
        wav_path = audio_file_path
        temp_wav = None

        if ext != '.wav':
            if progress_callback:
                progress_callback(10, "ì˜¤ë””ì˜¤ í¬ë§· ë³€í™˜ ì¤‘...")
            wav_path = await self._convert_to_wav(audio_file_path)
            temp_wav = wav_path

        try:
            if progress_callback:
                progress_callback(20, "í™”ì ë¶„ë¦¬ ë¶„ì„ ì‹œì‘...")

            result = await self._transcribe_with_push_stream(
                wav_path,
                language,
                progress_callback
            )

            if progress_callback:
                progress_callback(100, "ë¶„ì„ ì™„ë£Œ")

            return result

        finally:
            # ì„ì‹œ íŒŒì¼ ì •ë¦¬
            if temp_wav and os.path.exists(temp_wav):
                try:
                    os.remove(temp_wav)
                except Exception as e:
                    logger.warning(f"ì„ì‹œ íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨: {e}")

    async def _convert_to_wav(self, input_path: str) -> str:
        """
        ì˜¤ë””ì˜¤ íŒŒì¼ì„ Azureìš© WAV í˜•ì‹ìœ¼ë¡œ ë³€í™˜.

        16kHz, 16bit, mono PCM í˜•ì‹ìœ¼ë¡œ ë³€í™˜.
        """
        temp_fd, temp_path = tempfile.mkstemp(suffix='.wav')
        os.close(temp_fd)

        # ì…ë ¥ íŒŒì¼ì˜ ì±„ë„ ìˆ˜ í™•ì¸
        probe_cmd = [
            'ffprobe',
            '-v', 'error',
            '-select_streams', 'a:0',
            '-show_entries', 'stream=channels',
            '-of', 'csv=p=0',
            input_path
        ]

        try:
            probe_process = await asyncio.create_subprocess_exec(
                *probe_cmd,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE
            )
            probe_stdout, _ = await probe_process.communicate()
            input_channels = int(probe_stdout.decode().strip()) if probe_stdout.decode().strip() else 1
        except Exception:
            input_channels = 1  # ì‹¤íŒ¨ ì‹œ ëª¨ë…¸ë¡œ ê°€ì •

        # AzureëŠ” 16kHz monoë¥¼ ê¶Œì¥
        output_channels = 1  # í™”ì ë¶„ë¦¬ë¥¼ ìœ„í•´ mono ì‚¬ìš©

        cmd = [
            'ffmpeg',
            '-i', input_path,
            '-ar', '16000',       # 16kHz ìƒ˜í”Œë ˆì´íŠ¸
            '-ac', str(output_channels),  # ëª¨ë…¸
            '-acodec', 'pcm_s16le',  # 16bit PCM
            '-y',  # ë®ì–´ì“°ê¸°
            temp_path
        ]

        try:
            process = await asyncio.create_subprocess_exec(
                *cmd,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE
            )
            stdout, stderr = await process.communicate()

            if process.returncode != 0:
                logger.error(f"FFmpeg ì˜¤ë¥˜: {stderr.decode()}")
                raise ValueError("ì˜¤ë””ì˜¤ ë³€í™˜ ì‹¤íŒ¨. ffmpegê°€ ì„¤ì¹˜ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")

            logger.info(f"ì˜¤ë””ì˜¤ ë³€í™˜ ì™„ë£Œ: {input_channels}ch -> {output_channels}ch")
            return temp_path

        except FileNotFoundError:
            raise ValueError("ffmpegë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ffmpegë¥¼ ì„¤ì¹˜í•´ì£¼ì„¸ìš”.")

    async def _transcribe_with_push_stream(
        self,
        wav_path: str,
        language: str,
        progress_callback: Optional[Callable[[int, str], None]] = None
    ) -> Dict[str, Any]:
        """
        PushAudioInputStreamì„ ì‚¬ìš©í•˜ì—¬ í™”ì ë¶„ë¦¬ ìˆ˜í–‰.

        Azure ConversationTranscriberëŠ” íŒŒì¼ ì§ì ‘ ì…ë ¥ë³´ë‹¤
        ìŠ¤íŠ¸ë¦¼ ë°©ì‹ì´ ë” ì•ˆì •ì ìœ¼ë¡œ ë™ì‘í•¨.
        """
        # WAV íŒŒì¼ ì •ë³´ ì½ê¸°
        with wave.open(wav_path, 'rb') as wav_file:
            sample_rate = wav_file.getframerate()
            channels = wav_file.getnchannels()
            sample_width = wav_file.getsampwidth()
            n_frames = wav_file.getnframes()
            audio_data = wav_file.readframes(n_frames)

        bits_per_sample = sample_width * 8
        duration_seconds = n_frames / sample_rate

        logger.info(
            f"WAV íŒŒì¼ ì •ë³´: {sample_rate}Hz, {channels}ch, "
            f"{bits_per_sample}bit, {len(audio_data)} bytes, {duration_seconds:.1f}ì´ˆ"
        )

        # Speech ì„¤ì • ìƒì„±
        speech_config = speechsdk.SpeechConfig(
            subscription=self.speech_key,
            region=self.speech_region
        )
        speech_config.speech_recognition_language = language

        # í™”ì ë¶„ë¦¬ í–¥ìƒì„ ìœ„í•œ ì„¤ì •
        speech_config.set_property(
            speechsdk.PropertyId.SpeechServiceConnection_InitialSilenceTimeoutMs,
            "15000"  # 15ì´ˆ ì´ˆê¸° ì¹¨ë¬µ í—ˆìš©
        )
        speech_config.set_property(
            speechsdk.PropertyId.SpeechServiceConnection_EndSilenceTimeoutMs,
            "5000"   # 5ì´ˆ ì¢…ë£Œ ì¹¨ë¬µ í—ˆìš©
        )

        # ë‹¨ì–´ ìˆ˜ì¤€ íƒ€ì„ìŠ¤íƒ¬í”„ ìš”ì²­
        speech_config.request_word_level_timestamps()

        # PushAudioInputStream ìƒì„±
        audio_format = speechsdk.audio.AudioStreamFormat(
            samples_per_second=sample_rate,
            bits_per_sample=bits_per_sample,
            channels=channels
        )
        push_stream = speechsdk.audio.PushAudioInputStream(stream_format=audio_format)
        audio_config = speechsdk.audio.AudioConfig(stream=push_stream)

        # ConversationTranscriber ìƒì„±
        transcriber = speechsdk.transcription.ConversationTranscriber(
            speech_config=speech_config,
            audio_config=audio_config
        )

        # ê²°ê³¼ ì €ì¥ìš©
        utterances: List[Utterance] = []
        speaker_map: Dict[str, int] = {}
        done = asyncio.Event()
        errors: List[str] = []
        transcribing_started = threading.Event()

        def get_speaker_number(azure_speaker_id: str) -> int:
            """Azure í™”ì IDë¥¼ ìˆœì°¨ ë²ˆí˜¸ë¡œ ë³€í™˜."""
            if not azure_speaker_id or azure_speaker_id.lower() == "unknown":
                return 1

            if azure_speaker_id not in speaker_map:
                speaker_map[azure_speaker_id] = len(speaker_map) + 1
            return speaker_map[azure_speaker_id]

        def handle_transcribing(evt):
            """ì¤‘ê°„ ê²°ê³¼ ì²˜ë¦¬ (ë””ë²„ê·¸ìš©)."""
            logger.debug(f"[ì¤‘ê°„] {evt.result.text[:50]}..." if evt.result.text else "[ì¤‘ê°„] (ë¹ˆ í…ìŠ¤íŠ¸)")

        def handle_transcribed(evt):
            """ìµœì¢… ì¸ì‹ ê²°ê³¼ ì²˜ë¦¬."""
            try:
                if evt.result.reason == speechsdk.ResultReason.RecognizedSpeech:
                    text = evt.result.text

                    if text and text.strip():
                        # í™”ì ID ì¶”ì¶œ
                        azure_speaker_id = getattr(evt.result, 'speaker_id', None) or "Unknown"
                        speaker_num = get_speaker_number(azure_speaker_id)

                        # íƒ€ì´ë° ì •ë³´ ì¶”ì¶œ
                        offset_ticks = evt.result.offset
                        duration_ticks = evt.result.duration

                        # 100ë‚˜ë…¸ì´ˆ ë‹¨ìœ„ â†’ ë°€ë¦¬ì´ˆë¡œ ë³€í™˜
                        start_ms = offset_ticks // 10000
                        duration_ms = duration_ticks // 10000

                        utterances.append(Utterance(
                            speaker_id=speaker_num,
                            text=text.strip(),
                            start_time_ms=start_ms,
                            end_time_ms=start_ms + duration_ms,
                            confidence=0.9,
                            sequence_number=len(utterances)
                        ))

                        logger.info(
                            f"âœ… ë°œí™” ì¸ì‹: í™”ì{speaker_num} ({azure_speaker_id}): "
                            f"{text[:50]}..."
                        )

                        if progress_callback:
                            progress = min(90, 30 + len(utterances) * 2)
                            progress_callback(
                                progress,
                                f"ë°œí™” {len(utterances)}ê°œ ì¸ì‹ë¨ (í™”ì {len(speaker_map)}ëª…)..."
                            )

            except Exception as e:
                logger.error(f"ë°œí™” ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")

        def handle_canceled(evt):
            """ì·¨ì†Œ/ì˜¤ë¥˜ ì²˜ë¦¬."""
            logger.info(f"ğŸ”´ Canceled ì´ë²¤íŠ¸: reason={evt.reason}")

            if evt.reason == speechsdk.CancellationReason.Error:
                error_code = getattr(evt, 'error_code', 'Unknown')
                error_details = getattr(evt, 'error_details', 'No details')
                error_msg = f"ì˜¤ë¥˜ ì½”ë“œ: {error_code}, ìƒì„¸: {error_details}"
                errors.append(error_msg)
                logger.error(f"âŒ ìŒì„± ì¸ì‹ ì˜¤ë¥˜: {error_msg}")
            elif evt.reason == speechsdk.CancellationReason.EndOfStream:
                logger.info("âœ… ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ ì¢…ë£Œ")

            done.set()

        def handle_session_stopped(evt):
            """ì„¸ì…˜ ì¢…ë£Œ ì²˜ë¦¬."""
            logger.info("ğŸ”µ ì„¸ì…˜ ì¢…ë£Œë¨")
            done.set()

        def handle_session_started(evt):
            """ì„¸ì…˜ ì‹œì‘ ì²˜ë¦¬."""
            logger.info(f"ğŸŸ¢ ì„¸ì…˜ ì‹œì‘ë¨: {evt.session_id}")
            transcribing_started.set()

        # ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ ì—°ê²°
        transcriber.transcribing.connect(handle_transcribing)
        transcriber.transcribed.connect(handle_transcribed)
        transcriber.canceled.connect(handle_canceled)
        transcriber.session_stopped.connect(handle_session_stopped)
        transcriber.session_started.connect(handle_session_started)

        # ì˜¤ë””ì˜¤ í‘¸ì‹œë¥¼ ìœ„í•œ ìŠ¤ë ˆë“œ í•¨ìˆ˜
        def push_audio_data():
            """ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ ì˜¤ë””ì˜¤ ë°ì´í„°ë¥¼ ì²­í¬ë¡œ í‘¸ì‹œ."""
            # ì„¸ì…˜ ì‹œì‘ ëŒ€ê¸°
            if not transcribing_started.wait(timeout=10):
                logger.error("ì„¸ì…˜ ì‹œì‘ íƒ€ì„ì•„ì›ƒ")
                push_stream.close()
                return

            logger.info(f"ğŸµ ì˜¤ë””ì˜¤ ë°ì´í„° í‘¸ì‹œ ì‹œì‘: {len(audio_data)} bytes")

            # ì²­í¬ í¬ê¸°: 100ms ë¶„ëŸ‰ì˜ ì˜¤ë””ì˜¤ (16kHz, 16bit, mono = 3200 bytes/100ms)
            chunk_size = int(sample_rate * sample_width * channels * 0.1)  # 100ms
            total_chunks = len(audio_data) // chunk_size

            for i in range(0, len(audio_data), chunk_size):
                chunk = audio_data[i:i + chunk_size]
                push_stream.write(chunk)

                # ì‹¤ì‹œê°„ ì²˜ë¦¬ ì‹œë®¬ë ˆì´ì…˜ì„ ìœ„í•´ ì•½ê°„ì˜ ë”œë ˆì´
                # (ë„ˆë¬´ ë¹ ë¥´ê²Œ í‘¸ì‹œí•˜ë©´ Azureê°€ ì²˜ë¦¬í•˜ì§€ ëª»í•  ìˆ˜ ìˆìŒ)
                time.sleep(0.05)  # 50ms ë”œë ˆì´

                # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸ (ì„ íƒì )
                current_chunk = i // chunk_size
                if current_chunk % 50 == 0:  # ë§¤ 50ì²­í¬ë§ˆë‹¤
                    logger.debug(f"í‘¸ì‹œ ì§„í–‰: {current_chunk}/{total_chunks}")

            logger.info("ğŸµ ì˜¤ë””ì˜¤ ë°ì´í„° í‘¸ì‹œ ì™„ë£Œ, ìŠ¤íŠ¸ë¦¼ ì¢…ë£Œ")
            push_stream.close()

        # Transcription ì‹œì‘
        logger.info(f"ğŸš€ í™”ì ë¶„ë¦¬ ì‹œì‘: {wav_path}")
        transcriber.start_transcribing_async().get()

        # ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ ì˜¤ë””ì˜¤ í‘¸ì‹œ
        push_thread = threading.Thread(target=push_audio_data, daemon=True)
        push_thread.start()

        # ì™„ë£Œ ëŒ€ê¸° (íƒ€ì„ì•„ì›ƒ: ì˜¤ë””ì˜¤ ê¸¸ì´ + ì—¬ìœ ë¶„)
        timeout = max(300, duration_seconds * 2 + 60)  # ìµœì†Œ 5ë¶„, ë˜ëŠ” ì˜¤ë””ì˜¤ ê¸¸ì´ì˜ 2ë°° + 1ë¶„
        try:
            await asyncio.wait_for(done.wait(), timeout=timeout)
        except asyncio.TimeoutError:
            logger.warning(f"ìŒì„± ì¸ì‹ íƒ€ì„ì•„ì›ƒ ({timeout}ì´ˆ)")
            errors.append(f"íƒ€ì„ì•„ì›ƒ ({timeout}ì´ˆ)")

        # Transcription ì¢…ë£Œ
        transcriber.stop_transcribing_async().get()

        # í‘¸ì‹œ ìŠ¤ë ˆë“œ ì¢…ë£Œ ëŒ€ê¸°
        push_thread.join(timeout=5)

        if errors:
            logger.error(f"ìŒì„± ì¸ì‹ ì˜¤ë¥˜ ëª©ë¡: {errors}")

        # ê²°ê³¼ ê³„ì‚°
        result_duration = 0.0
        if utterances:
            result_duration = max(u.end_time_ms for u in utterances) / 1000.0
        else:
            result_duration = duration_seconds  # ë°œí™”ê°€ ì—†ìœ¼ë©´ ì›ë³¸ ê¸¸ì´ ì‚¬ìš©

        unique_speakers = len(speaker_map) if speaker_map else (1 if utterances else 0)

        logger.info(
            f"ğŸ“Š ë¶„ì„ ì™„ë£Œ: {len(utterances)}ê°œ ë°œí™”, "
            f"{unique_speakers}ëª… í™”ì, {result_duration:.1f}ì´ˆ"
        )

        return {
            "utterances": [
                {
                    "speaker_id": u.speaker_id,
                    "text": u.text,
                    "start_time_ms": u.start_time_ms,
                    "end_time_ms": u.end_time_ms,
                    "confidence": u.confidence,
                    "sequence_number": u.sequence_number
                }
                for u in utterances
            ],
            "speaker_count": unique_speakers,
            "duration_seconds": result_duration
        }

    def get_supported_languages(self) -> List[str]:
        """ì§€ì›ë˜ëŠ” ì–¸ì–´ ì½”ë“œ ëª©ë¡ ë°˜í™˜."""
        return [
            "en-US", "en-GB", "en-AU", "en-IN", "en-NZ", "en-CA",
            "ko-KR",
            "ja-JP",
            "zh-CN", "zh-TW", "zh-HK",
            "de-DE", "de-AT", "de-CH",
            "fr-FR", "fr-CA",
            "es-ES", "es-MX",
            "it-IT",
            "pt-BR", "pt-PT",
            "nl-NL",
            "ru-RU",
            "ar-SA", "ar-EG",
            "hi-IN",
            "th-TH",
            "vi-VN"
        ]

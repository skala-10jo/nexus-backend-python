"""
Azure Speech SDKë¥¼ ì‚¬ìš©í•œ ìŒì„± ì¸ì‹ ë° í™”ì ë¶„ë¦¬ ì—ì´ì „íŠ¸.

ConversationTranscriberë¥¼ ì‚¬ìš©í•˜ì—¬ ì‹¤ì œ í™”ì ë¶„ë¦¬(Speaker Diarization) ìˆ˜í–‰.

ì˜¤ë””ì˜¤ íŒŒì¼ì„ ë¶„ì„í•˜ì—¬ ë‹¤ìŒ ì •ë³´ë¥¼ ì œê³µ:
- í™”ìë³„ë¡œ ë¶„ë¦¬ëœ ë°œí™” ë‚´ìš© (ìŒì„± íŠ¹ì„± ê¸°ë°˜ ìë™ ì‹ë³„)
- íƒ€ì„ìŠ¤íƒ¬í”„ (ì‹œì‘/ì¢…ë£Œ ì‹œê°„)
- ì‹ ë¢°ë„ ì ìˆ˜

Docker/AWS í™˜ê²½ í˜¸í™˜:
- PushAudioInputStreamì„ ì‚¬ìš©í•˜ì—¬ ì•ˆì •ì ìœ¼ë¡œ ì‘ë™

ì°¸ê³ :
https://learn.microsoft.com/en-us/azure/ai-services/speech-service/get-started-stt-diarization
"""
import asyncio
import logging
import tempfile
import os
import wave
import threading
from typing import List, Dict, Any, Optional, Callable
from dataclasses import dataclass

import azure.cognitiveservices.speech as speechsdk
from app.config import settings

logger = logging.getLogger(__name__)


@dataclass
class Utterance:
    """ë‹¨ì¼ ë°œí™”ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ë°ì´í„° í´ë˜ìŠ¤."""
    speaker_id: str  # Changed to str for ConversationTranscriber (Guest-1, Guest-2, etc.)
    text: str
    start_time_ms: int
    end_time_ms: int
    confidence: float
    sequence_number: int


class DiarizationAgent:
    """
    Azure ConversationTranscriber ê¸°ë°˜ í™”ì ë¶„ë¦¬ ì—ì´ì „íŠ¸.

    ConversationTranscriberë¥¼ ì‚¬ìš©í•˜ì—¬ ìŒì„± íŠ¹ì„± ê¸°ë°˜ ì‹¤ì œ í™”ì ë¶„ë¦¬ ìˆ˜í–‰.

    ì£¼ì˜: í™”ì ë¶„ë¦¬ ê¸°ëŠ¥ì€ íŠ¹ì • ë¦¬ì „ì—ì„œë§Œ ì‚¬ìš© ê°€ëŠ¥:
    - eastasia, southeastasia, centralus, eastus, westeurope
    - AZURE_AVATAR_SPEECH_KEY/REGION (southeastasia) ì‚¬ìš©
    """

    SUPPORTED_FORMATS = {'.wav', '.mp3', '.m4a', '.ogg', '.flac', '.webm'}

    def __init__(self):
        """Azure Speech ì„¤ì •ìœ¼ë¡œ ì´ˆê¸°í™”."""
        if not settings.AZURE_AVATAR_SPEECH_KEY:
            raise ValueError("AZURE_AVATAR_SPEECH_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤ (í™”ì ë¶„ë¦¬ì— í•„ìš”)")

        self.speech_key = settings.AZURE_AVATAR_SPEECH_KEY
        self.speech_region = settings.AZURE_AVATAR_SPEECH_REGION

        logger.info(f"DiarizationAgent ì´ˆê¸°í™” ì™„ë£Œ: ë¦¬ì „={self.speech_region}")

    async def process(
        self,
        audio_file_path: str,
        language: str = "en-US",
        progress_callback: Optional[Callable[[int, str], None]] = None
    ) -> Dict[str, Any]:
        """
        ì˜¤ë””ì˜¤ íŒŒì¼ì„ í™”ì ë¶„ë¦¬í•˜ì—¬ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜.

        Args:
            audio_file_path: ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
            language: ì–¸ì–´ ì½”ë“œ (ì˜ˆ: 'en-US', 'ko-KR')
            progress_callback: ì§„í–‰ë¥  ì½œë°± í•¨ìˆ˜ (percent, message)

        Returns:
            {
                "utterances": [...],
                "speaker_count": 2,
                "duration_seconds": 180.5
            }
        """
        if not os.path.exists(audio_file_path):
            raise FileNotFoundError(f"ì˜¤ë””ì˜¤ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {audio_file_path}")

        ext = os.path.splitext(audio_file_path)[1].lower()
        if ext not in self.SUPPORTED_FORMATS:
            raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì˜¤ë””ì˜¤ í˜•ì‹: {ext}")

        if progress_callback:
            progress_callback(5, "ì˜¤ë””ì˜¤ íŒŒì¼ ì¤€ë¹„ ì¤‘...")

        # í•­ìƒ 16kHz/16bit/mono WAVë¡œ ë³€í™˜ (Docker í™˜ê²½ í˜¸í™˜ì„±)
        if progress_callback:
            progress_callback(10, "ì˜¤ë””ì˜¤ í¬ë§· ë³€í™˜ ì¤‘...")

        wav_path = await self._convert_to_wav(audio_file_path)

        try:
            if progress_callback:
                progress_callback(20, "í™”ì ë¶„ë¦¬ ì‹œì‘...")

            result = await self._transcribe_with_diarization(
                wav_path,
                language,
                progress_callback
            )

            if progress_callback:
                progress_callback(100, "ë¶„ì„ ì™„ë£Œ")

            return result

        finally:
            # ë³€í™˜ëœ ì„ì‹œ íŒŒì¼ ì •ë¦¬
            if wav_path != audio_file_path and os.path.exists(wav_path):
                try:
                    os.remove(wav_path)
                    logger.debug(f"ì„ì‹œ íŒŒì¼ ì‚­ì œ: {wav_path}")
                except Exception as e:
                    logger.warning(f"ì„ì‹œ íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨: {e}")

    async def _convert_to_wav(self, input_path: str) -> str:
        """
        ì˜¤ë””ì˜¤ íŒŒì¼ì„ Azureìš© WAV í˜•ì‹ìœ¼ë¡œ ë³€í™˜.

        í•­ìƒ 16kHz, 16bit, mono PCMìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ì¼ê´€ì„± ë³´ì¥.
        """
        temp_fd, temp_path = tempfile.mkstemp(suffix='.wav')
        os.close(temp_fd)

        # Azure Speech SDK ìš”êµ¬ ì‚¬í•­: 16kHz, 16bit, mono PCM
        cmd = [
            'ffmpeg',
            '-i', input_path,
            '-ar', '16000',          # 16kHz ìƒ˜í”Œë ˆì´íŠ¸
            '-ac', '1',              # ëª¨ë…¸
            '-acodec', 'pcm_s16le',  # 16bit PCM little-endian
            '-y',                    # ë®ì–´ì“°ê¸°
            temp_path
        ]

        try:
            process = await asyncio.create_subprocess_exec(
                *cmd,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE
            )
            stdout, stderr = await process.communicate()

            if process.returncode != 0:
                logger.error(f"FFmpeg ì˜¤ë¥˜: {stderr.decode()}")
                raise ValueError("ì˜¤ë””ì˜¤ ë³€í™˜ ì‹¤íŒ¨")

            logger.info(f"ì˜¤ë””ì˜¤ ë³€í™˜ ì™„ë£Œ: {temp_path}")
            return temp_path

        except FileNotFoundError:
            raise ValueError("ffmpegë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

    async def _transcribe_with_diarization(
        self,
        wav_path: str,
        language: str,
        progress_callback: Optional[Callable[[int, str], None]] = None
    ) -> Dict[str, Any]:
        """
        ConversationTranscriberë¥¼ ì‚¬ìš©í•˜ì—¬ í™”ì ë¶„ë¦¬ ìˆ˜í–‰.
        """
        # WAV íŒŒì¼ ì •ë³´ í™•ì¸
        try:
            with wave.open(wav_path, 'rb') as wf:
                sample_rate = wf.getframerate()
                channels = wf.getnchannels()
                sample_width = wf.getsampwidth()
                n_frames = wf.getnframes()
                duration_sec = n_frames / sample_rate

            logger.info(
                f"WAV íŒŒì¼ ì •ë³´: {sample_rate}Hz, {channels}ch, "
                f"{sample_width*8}bit, {duration_sec:.1f}ì´ˆ"
            )
        except Exception as e:
            logger.error(f"WAV íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {e}")
            raise ValueError(f"WAV íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {e}")

        # Speech ì„¤ì • ìƒì„±
        speech_config = speechsdk.SpeechConfig(
            subscription=self.speech_key,
            region=self.speech_region
        )
        speech_config.speech_recognition_language = language
        # Note: ConversationTranscriberëŠ” ìë™ìœ¼ë¡œ í™”ì ë¶„ë¦¬ë¥¼ ìˆ˜í–‰í•¨
        # SpeechServiceResponse_DiarizeIntermediateResultsëŠ” SpeechRecognizerìš©ì´ë¯€ë¡œ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ

        # íŒŒì¼ ê¸°ë°˜ AudioConfig
        audio_config = speechsdk.audio.AudioConfig(filename=wav_path)

        logger.info(f"ğŸ”§ ConversationTranscriber ì„¤ì •: region={self.speech_region}, language={language}")

        # ConversationTranscriber ìƒì„± (í™”ì ë¶„ë¦¬ ì§€ì›)
        transcriber = speechsdk.transcription.ConversationTranscriber(
            speech_config=speech_config,
            audio_config=audio_config
        )

        logger.info("âœ… ConversationTranscriber ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ì™„ë£Œ")

        # ê²°ê³¼ ì €ì¥ (thread-safe)
        utterances: List[Utterance] = []
        done = threading.Event()
        errors: List[str] = []
        lock = threading.Lock()
        speaker_set = set()

        def handle_transcribed(evt):
            """í™”ì ë¶„ë¦¬ëœ ë°œí™” ì¸ì‹ ì´ë²¤íŠ¸ ì²˜ë¦¬."""
            try:
                if evt.result.reason == speechsdk.ResultReason.RecognizedSpeech:
                    text = evt.result.text
                    speaker_id = evt.result.speaker_id  # ì‹¤ì œ í™”ì ID (Guest-1, Guest-2, etc.)

                    if text and text.strip():
                        offset_ticks = evt.result.offset
                        duration_ticks = evt.result.duration

                        # 100ë‚˜ë…¸ì´ˆ â†’ ë°€ë¦¬ì´ˆ
                        start_ms = offset_ticks // 10000
                        duration_ms = duration_ticks // 10000

                        with lock:
                            speaker_set.add(speaker_id)
                            utterances.append(Utterance(
                                speaker_id=speaker_id,
                                text=text.strip(),
                                start_time_ms=start_ms,
                                end_time_ms=start_ms + duration_ms,
                                confidence=0.9,
                                sequence_number=len(utterances)
                            ))
                            count = len(utterances)
                            num_speakers = len(speaker_set)

                        logger.info(
                            f"âœ… [{speaker_id}] ë°œí™” ì¸ì‹ [{start_ms}ms]: {text[:50]}..."
                        )

                        if progress_callback:
                            progress = min(90, 30 + count * 2)
                            progress_callback(
                                progress,
                                f"ë°œí™” {count}ê°œ ì¸ì‹, í™”ì {num_speakers}ëª… ê°ì§€..."
                            )

                elif evt.result.reason == speechsdk.ResultReason.NoMatch:
                    logger.debug(f"ë§¤ì¹­ ì—†ìŒ: {evt.result.no_match_details}")

            except Exception as e:
                logger.error(f"ì¸ì‹ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")

        def handle_canceled(evt):
            """ì·¨ì†Œ/ì˜¤ë¥˜ ì²˜ë¦¬."""
            try:
                # ConversationTranscriberì˜ canceled ì´ë²¤íŠ¸ ì²˜ë¦¬
                cancellation = speechsdk.CancellationDetails(evt.result)
                logger.info(f"ğŸ”´ Canceled: reason={cancellation.reason}")

                if cancellation.reason == speechsdk.CancellationReason.Error:
                    error_msg = f"ì½”ë“œ: {cancellation.error_code}, ìƒì„¸: {cancellation.error_details}"
                    with lock:
                        errors.append(error_msg)
                    logger.error(f"âŒ í™”ì ë¶„ë¦¬ ì˜¤ë¥˜: {error_msg}")
                elif cancellation.reason == speechsdk.CancellationReason.EndOfStream:
                    logger.info("âœ… ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ ì¢…ë£Œ (ì •ìƒ)")
            except Exception as e:
                logger.error(f"âŒ canceled ì´ë²¤íŠ¸ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")

            done.set()

        def handle_session_stopped(evt):
            """ì„¸ì…˜ ì¢…ë£Œ ì²˜ë¦¬."""
            logger.info("ğŸ”µ ì„¸ì…˜ ì¢…ë£Œë¨")
            done.set()

        def handle_session_started(evt):
            """ì„¸ì…˜ ì‹œì‘ ì²˜ë¦¬."""
            logger.info(f"ğŸŸ¢ ConversationTranscriber ì„¸ì…˜ ì‹œì‘ë¨: {evt.session_id}")

        # ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ ì—°ê²°
        transcriber.transcribed.connect(handle_transcribed)
        transcriber.canceled.connect(handle_canceled)
        transcriber.session_stopped.connect(handle_session_stopped)
        transcriber.session_started.connect(handle_session_started)

        # ë¹„ë™ê¸° í™”ì ë¶„ë¦¬ ì‹œì‘
        logger.info(f"ğŸš€ ConversationTranscriber í™”ì ë¶„ë¦¬ ì‹œì‘: {wav_path}")
        try:
            start_future = transcriber.start_transcribing_async()
            logger.info("â³ start_transcribing_async() í˜¸ì¶œ ì™„ë£Œ, ê²°ê³¼ ëŒ€ê¸° ì¤‘...")
            start_future.get()
            logger.info("âœ… í™”ì ë¶„ë¦¬ ì‹œì‘ë¨")
        except Exception as e:
            logger.error(f"âŒ start_transcribing_async() ì‹¤íŒ¨: {e}")
            raise

        # ì™„ë£Œ ëŒ€ê¸° (threading.Event ì‚¬ìš©)
        logger.info("â³ í™”ì ë¶„ë¦¬ ì™„ë£Œ ëŒ€ê¸° ì¤‘...")
        completed = done.wait(timeout=600)  # ìµœëŒ€ 10ë¶„

        if not completed:
            logger.warning("âš ï¸ í™”ì ë¶„ë¦¬ íƒ€ì„ì•„ì›ƒ (10ë¶„)")
            with lock:
                errors.append("íƒ€ì„ì•„ì›ƒ (10ë¶„)")
        else:
            logger.info("âœ… í™”ì ë¶„ë¦¬ ì´ë²¤íŠ¸ ìˆ˜ì‹  ì™„ë£Œ")

        # ì¸ì‹ ì¢…ë£Œ
        logger.info("ğŸ›‘ í™”ì ë¶„ë¦¬ ì¤‘ì§€ ì¤‘...")
        try:
            transcriber.stop_transcribing_async().get()
            logger.info("âœ… í™”ì ë¶„ë¦¬ ì¤‘ì§€ë¨")
        except Exception as e:
            logger.warning(f"âš ï¸ stop_transcribing_async() ê²½ê³ : {e}")

        # ì—ëŸ¬ í™•ì¸
        with lock:
            if errors and "EndOfStream" not in str(errors):
                logger.error(f"í™”ì ë¶„ë¦¬ ì˜¤ë¥˜: {errors}")

        # ê²°ê³¼ ê³„ì‚°
        with lock:
            result_duration = 0.0
            if utterances:
                result_duration = max(u.end_time_ms for u in utterances) / 1000.0

            # í™”ì IDë¥¼ ìˆ«ìë¡œ ë³€í™˜ (Guest-1 â†’ 1, Guest-2 â†’ 2)
            speaker_mapping = {}
            for i, spk in enumerate(sorted(speaker_set), start=1):
                speaker_mapping[spk] = i

            unique_speakers = len(speaker_set)
            utterance_count = len(utterances)

            logger.info(
                f"ğŸ“Š í™”ì ë¶„ë¦¬ ì™„ë£Œ: {utterance_count}ê°œ ë°œí™”, "
                f"{unique_speakers}ëª… í™”ì, {result_duration:.1f}ì´ˆ"
            )

            return {
                "utterances": [
                    {
                        "speaker_id": speaker_mapping.get(u.speaker_id, 1),
                        "speaker_label": u.speaker_id,  # ì›ë³¸ í™”ì ë ˆì´ë¸” (Guest-1 ë“±)
                        "text": u.text,
                        "start_time_ms": u.start_time_ms,
                        "end_time_ms": u.end_time_ms,
                        "confidence": u.confidence,
                        "sequence_number": u.sequence_number
                    }
                    for u in utterances
                ],
                "speaker_count": unique_speakers,
                "duration_seconds": result_duration
            }

    def get_supported_languages(self) -> List[str]:
        """ì§€ì›ë˜ëŠ” ì–¸ì–´ ì½”ë“œ ëª©ë¡ ë°˜í™˜."""
        return [
            "en-US", "en-GB", "en-AU", "en-IN", "en-NZ", "en-CA",
            "ko-KR",
            "ja-JP",
            "zh-CN", "zh-TW", "zh-HK",
            "de-DE", "de-AT", "de-CH",
            "fr-FR", "fr-CA",
            "es-ES", "es-MX",
            "it-IT",
            "pt-BR", "pt-PT",
            "nl-NL",
            "ru-RU",
            "ar-SA", "ar-EG",
            "hi-IN",
            "th-TH",
            "vi-VN"
        ]

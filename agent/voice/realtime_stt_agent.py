"""
ì‹¤ì‹œê°„ ìŒì„±-í…ìŠ¤íŠ¸ ë³€í™˜ Agent (OpenAI Whisper API)

ìµœì í™” ê¸°ë²•:
- ì‘ì€ ì²­í¬ ì²˜ë¦¬ (500ms - 2ì´ˆ)
- ì„ì‹œ íŒŒì¼ ì¦‰ì‹œ ì‚­ì œ
- ì—ëŸ¬ ì²˜ë¦¬ ê°•í™”
"""
import tempfile
import base64
import os
from typing import Dict
from agent.base_agent import BaseAgent


class RealtimeSTTAgent(BaseAgent):
    """
    ì‹¤ì‹œê°„ STT Agent

    OpenAI Whisper APIë¥¼ ì‚¬ìš©í•˜ì—¬ ì˜¤ë””ì˜¤ë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    ì‹¤ì‹œê°„ ì²˜ë¦¬ë¥¼ ìœ„í•´ ì‘ì€ ì²­í¬ ë‹¨ìœ„ë¡œ ìµœì í™”ë˜ì—ˆìŠµë‹ˆë‹¤.
    """

    def __init__(self):
        super().__init__()
        self.supported_languages = {
            'ko': 'í•œêµ­ì–´',
            'en': 'ì˜ì–´',
            'vi': 'ë² íŠ¸ë‚¨ì–´'
        }

    async def process(
        self,
        audio_data,  # bytes ë˜ëŠ” str (base64) ëª¨ë‘ í—ˆìš©
        input_language: str = 'ko',
        audio_format: Dict = None
    ) -> Dict[str, any]:
        """
        ì˜¤ë””ì˜¤ ì²­í¬ë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜

        Args:
            audio_data: ì˜¤ë””ì˜¤ ë°ì´í„° (bytes ë˜ëŠ” base64 ì¸ì½”ë”©ëœ ë¬¸ìì—´)
            input_language: ì…ë ¥ ì–¸ì–´ ì½”ë“œ (ko, en, vi)
            audio_format: ì˜¤ë””ì˜¤ í˜•ì‹ ì •ë³´ (mimeType, extension)
                ì˜ˆ: {"mimeType": "audio/webm;codecs=opus", "extension": "webm"}

        Returns:
            {
                "text": "ë³€í™˜ëœ í…ìŠ¤íŠ¸",
                "confidence": 0.95,
                "language": "ko",
                "duration": 1.5  # ì˜¤ë””ì˜¤ ê¸¸ì´ (ì´ˆ)
            }

        Raises:
            ValueError: ì§€ì›í•˜ì§€ ì•ŠëŠ” ì–¸ì–´ì¼ ë•Œ
            Exception: Whisper API í˜¸ì¶œ ì‹¤íŒ¨ ì‹œ
        """
        # 1. ì–¸ì–´ ê²€ì¦
        if input_language not in self.supported_languages:
            raise ValueError(
                f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì–¸ì–´ì…ë‹ˆë‹¤: {input_language}. "
                f"ì§€ì› ì–¸ì–´: {list(self.supported_languages.keys())}"
            )

        # 2. audio_data íƒ€ì…ì— ë”°ë¼ ì²˜ë¦¬
        import logging
        logger = logging.getLogger(__name__)
        logger.debug(f"ğŸ” RealtimeSTTAgent.process: type={type(audio_data)}, isinstance(str)={isinstance(audio_data, str)}, isinstance(bytes)={isinstance(audio_data, bytes)}")

        if isinstance(audio_data, str):
            # base64 ì¸ì½”ë”©ëœ ë¬¸ìì—´ì¸ ê²½ìš°
            logger.debug(f"ğŸ” Attempting base64 decode of string (length={len(audio_data)})")
            try:
                audio_bytes = base64.b64decode(audio_data)
                logger.debug(f"ğŸ” Successfully decoded base64, resulting bytes length={len(audio_bytes)}")
            except Exception as e:
                logger.error(f"ğŸ” Base64 decode failed: {str(e)}")
                raise ValueError(f"ì˜¤ë””ì˜¤ ë°ì´í„° ë””ì½”ë”© ì‹¤íŒ¨: {str(e)}")
        elif isinstance(audio_data, bytes):
            # ì´ë¯¸ bytesì¸ ê²½ìš° (WebSocket binary message)
            logger.debug(f"ğŸ” Using raw bytes (length={len(audio_data)})")
            audio_bytes = audio_data
        else:
            raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì˜¤ë””ì˜¤ ë°ì´í„° íƒ€ì…: {type(audio_data)}")

        # ì˜¤ë””ì˜¤ê°€ ë„ˆë¬´ ì‘ìœ¼ë©´ ë¬´ì‹œ (< 0.5ì´ˆ, ëŒ€ëµ 8KB)
        if len(audio_bytes) < 8000:
            return {
                "text": "",
                "confidence": 0.0,
                "language": input_language,
                "duration": 0.0
            }

        # 3. ì˜¤ë””ì˜¤ í˜•ì‹ì— ë§ëŠ” í™•ì¥ì ê²°ì •
        # Whisper APIëŠ” mp3, mp4, mpeg, mpga, m4a, wav, webm ëª¨ë‘ ì§€ì›
        if audio_format and "extension" in audio_format:
            file_extension = audio_format["extension"]
        else:
            # ê¸°ë³¸ê°’: webm
            file_extension = "webm"

        # 4. ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
        temp_file_path = None
        try:
            with tempfile.NamedTemporaryFile(
                suffix=f'.{file_extension}',
                delete=False
            ) as temp_file:
                temp_file.write(audio_bytes)
                temp_file_path = temp_file.name

            # 4. Whisper API í˜¸ì¶œ
            with open(temp_file_path, 'rb') as audio_file:
                transcript = await self.client.audio.transcriptions.create(
                    model="whisper-1",
                    file=audio_file,
                    language=input_language,
                    response_format="verbose_json",  # ìƒì„¸ ì •ë³´ í¬í•¨
                    temperature=0.0,  # ê²°ì •ë¡ ì  ê²°ê³¼
                    prompt="ì´ê²ƒì€ ì¼ìƒ ëŒ€í™”ì…ë‹ˆë‹¤."  # Hallucination ë°©ì§€ í”„ë¡¬í”„íŠ¸
                )

            # 5. ê²°ê³¼ íŒŒì‹±
            text = transcript.text.strip()

            # Hallucination ê°ì§€: segmentsì˜ no_speech_prob ì²´í¬
            segments = getattr(transcript, 'segments', [])
            if segments:
                # ëª¨ë“  segmentì˜ í‰ê·  no_speech_prob ê³„ì‚°
                # TranscriptionSegment ê°ì²´ì´ë¯€ë¡œ getattr ì‚¬ìš©
                avg_no_speech_prob = sum(
                    getattr(seg, 'no_speech_prob', 0.0) for seg in segments
                ) / len(segments)

                # no_speech_probê°€ 0.85 ì´ìƒì´ë©´ ë¬´ìŒ/hallucinationìœ¼ë¡œ ê°„ì£¼
                if avg_no_speech_prob > 0.85:
                    return {
                        "text": "",
                        "confidence": 0.0,
                        "language": input_language,
                        "duration": getattr(transcript, 'duration', 0.0)
                    }

            # Confidence ê³„ì‚°
            confidence = 0.9 if text else 0.0

            return {
                "text": text,
                "confidence": confidence,
                "language": transcript.language or input_language,
                "duration": getattr(transcript, 'duration', 0.0)
            }

        except Exception as e:
            # Whisper API ì—ëŸ¬ ì²˜ë¦¬
            error_msg = str(e)

            # ì¼ë°˜ì ì¸ ì—ëŸ¬ ë©”ì‹œì§€ë¥¼ í•œê¸€ë¡œ ë³€í™˜
            if "Invalid file format" in error_msg or "invalid_file_format" in error_msg.lower():
                raise Exception(
                    f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì˜¤ë””ì˜¤ í˜•ì‹ì…ë‹ˆë‹¤. "
                    f"í˜•ì‹: {audio_format.get('mimeType', 'unknown') if audio_format else 'unknown'}, "
                    f"í™•ì¥ì: {file_extension}. "
                    f"Whisper APIëŠ” mp3, mp4, wav, webm ë“±ì„ ì§€ì›í•©ë‹ˆë‹¤. "
                    f"ì›ë³¸ ì—ëŸ¬: {error_msg}"
                )
            elif "File too large" in error_msg:
                raise Exception("ì˜¤ë””ì˜¤ íŒŒì¼ì´ ë„ˆë¬´ í½ë‹ˆë‹¤. (ìµœëŒ€ 25MB)")
            elif "No audio data" in error_msg:
                # ë¬´ìŒ êµ¬ê°„ì€ ë¹ˆ ê²°ê³¼ ë°˜í™˜
                return {
                    "text": "",
                    "confidence": 0.0,
                    "language": input_language,
                    "duration": 0.0
                }
            else:
                raise Exception(f"ìŒì„± ì¸ì‹ ì‹¤íŒ¨: {error_msg}")

        finally:
            # 6. ì„ì‹œ íŒŒì¼ ì¦‰ì‹œ ì‚­ì œ (ë³´ì•ˆ ë° ë””ìŠ¤í¬ ê³µê°„ ê´€ë¦¬)
            if temp_file_path and os.path.exists(temp_file_path):
                try:
                    os.unlink(temp_file_path)
                except Exception:
                    pass  # ì‚­ì œ ì‹¤íŒ¨ëŠ” ë¬´ì‹œ

    def get_supported_languages(self) -> Dict[str, str]:
        """
        ì§€ì›í•˜ëŠ” ì–¸ì–´ ëª©ë¡ ë°˜í™˜

        Returns:
            {
                'ko': 'í•œêµ­ì–´',
                'en': 'ì˜ì–´',
                'vi': 'ë² íŠ¸ë‚¨ì–´'
            }
        """
        return self.supported_languages.copy()

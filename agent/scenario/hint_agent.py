"""
íšŒí™” ì—°ìŠµì„ ìœ„í•œ íŒíŠ¸ ìƒì„± ì—ì´ì „íŠ¸.

ë‹¤ìŒì„ ê¸°ë°˜ìœ¼ë¡œ ë§¥ë½ì— ì í•©í•œ ì‘ë‹µ ì œì•ˆì„ ìƒì„±í•©ë‹ˆë‹¤:
- ì‹œë‚˜ë¦¬ì˜¤ ì»¨í…ìŠ¤íŠ¸ (ì—­í• , ì£¼ì œ, ë‚œì´ë„)
- ëŒ€í™” íˆìŠ¤í† ë¦¬
- í•„ìˆ˜ ì „ë¬¸ìš©ì–´
- ëŒ€í™”ì—ì„œì˜ ì‚¬ìš©ì ì—­í• 
"""
import logging
from typing import List, Dict, Any, Optional

from agent.base_agent import BaseAgent

logger = logging.getLogger(__name__)


class HintAgent(BaseAgent):
    """
    ëŒ€í™” íŒíŠ¸/ì œì•ˆì„ ìƒì„±í•˜ëŠ” AI ì—ì´ì „íŠ¸.

    GPT-4oë¥¼ ì‚¬ìš©í•˜ì—¬ ë§¥ë½ì— ì í•©í•œ ì‘ë‹µ ì œì•ˆì„ ìƒì„±í•©ë‹ˆë‹¤.
    ì‚¬ìš©ìê°€ í•„ìˆ˜ ì „ë¬¸ìš©ì–´ë¥¼ ì‚¬ìš©í•˜ê³  ì ì ˆí•œ ë‚œì´ë„ë¥¼ ìœ ì§€í•˜ë©´ì„œ
    ëŒ€í™”ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ ì´ì–´ê°ˆ ìˆ˜ ìˆë„ë¡ ë•ìŠµë‹ˆë‹¤.

    Example:
        >>> agent = HintAgent()
        >>> hints = await agent.process(
        ...     scenario_context={
        ...         "title": "í”„ë¡œì íŠ¸ í‚¥ì˜¤í”„ ë¯¸íŒ…",
        ...         "description": "ìƒˆ í”„ë¡œì íŠ¸ ì‹œì‘ íšŒì˜",
        ...         "scenario_text": "PMê³¼ ê°œë°œìê°€ í”„ë¡œì íŠ¸ ë²”ìœ„ë¥¼ ë…¼ì˜",
        ...         "roles": {"user": "ê°œë°œì", "ai": "PM"},
        ...         "required_terminology": ["scope", "timeline", "deliverables"],
        ...         "difficulty": "intermediate",
        ...         "language": "en"
        ...     },
        ...     conversation_history=[
        ...         {"speaker": "ai", "message": "Hi! Ready to discuss the project?"},
        ...         {"speaker": "user", "message": "Yes, I have some questions."}
        ...     ],
        ...     last_ai_message="Sure, what would you like to know?"
        ... )
        >>> print(hints)
    """

    # í”„ë¡¬í”„íŠ¸ìš© ì–¸ì–´ ë§¤í•‘
    LANG_MAP = {
        "en": "English",
        "ko": "Korean (í•œêµ­ì–´)",
        "zh": "Chinese (ä¸­æ–‡)",
        "ja": "Japanese (æ—¥æœ¬èª)",
        "vi": "Vietnamese (Tiáº¿ng Viá»‡t)"
    }

    # ë‚œì´ë„ë³„ ë³µì¡ë„ ê°€ì´ë“œë¼ì¸
    DIFFICULTY_GUIDELINES = {
        "beginner": {
            "sentence_length": "5-10ë‹¨ì–´",
            "complexity": "ë‹¨ìˆœ ë¬¸ì¥ êµ¬ì¡° (ì£¼ì–´ + ë™ì‚¬ + ëª©ì ì–´)",
            "vocabulary": "ê¸°ë³¸ ì¼ìƒ ì–´íœ˜",
            "grammar": "í˜„ì¬/ê³¼ê±° ì‹œì œë§Œ, ê°„ë‹¨í•œ ì§ˆë¬¸",
            "style": "ì§ì ‘ì ì´ê³  ëª…í™•í•˜ê²Œ, ê´€ìš©êµ¬ í”¼í•˜ê¸°"
        },
        "intermediate": {
            "sentence_length": "10-20ë‹¨ì–´",
            "complexity": "ë³µí•©ë¬¸, ì¡°ê±´ì ˆ í—ˆìš©",
            "vocabulary": "ë¹„ì¦ˆë‹ˆìŠ¤ ìš©ì–´, ì¼ë°˜ì ì¸ í‘œí˜„",
            "grammar": "ë‹¤ì–‘í•œ ì‹œì œ, ê³µì†í•œ í˜•íƒœ, ê°„ì ‘ ì§ˆë¬¸",
            "style": "ì „ë¬¸ì ì´ì§€ë§Œ ëŒ€í™”ì ìœ¼ë¡œ, ì¼ë¶€ ê´€ìš©êµ¬ ê°€ëŠ¥"
        },
        "advanced": {
            "sentence_length": "15-30ë‹¨ì–´",
            "complexity": "ì—¬ëŸ¬ ì ˆì´ ìˆëŠ” ë³µì¡í•œ ë¬¸ì¥",
            "vocabulary": "ì„¸ë ¨ëœ ë¹„ì¦ˆë‹ˆìŠ¤ ì–´íœ˜, ë‰˜ì•™ìŠ¤ ìˆëŠ” í‘œí˜„",
            "grammar": "ëª¨ë“  ì‹œì œ, ê°€ì •ë²•, ë³µì¡í•œ ì¡°ë™ì‚¬",
            "style": "ë‰˜ì•™ìŠ¤ ìˆê³ , ì™¸êµì ìœ¼ë¡œ, ê´€ìš©ì  í‘œí˜„ ê¶Œì¥"
        }
    }

    async def process(
        self,
        scenario_context: Dict[str, Any],
        conversation_history: List[Dict[str, str]],
        last_ai_message: str,
        hint_count: int = 3
    ) -> Dict[str, Any]:
        """
        ë§¥ë½ì— ì í•©í•œ ì‘ë‹µ íŒíŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

        Args:
            scenario_context: ë‹¤ìŒì„ í¬í•¨í•˜ëŠ” ì‹œë‚˜ë¦¬ì˜¤ ì •ë³´:
                - title: ì‹œë‚˜ë¦¬ì˜¤ ì œëª©
                - description: ê°„ë‹¨í•œ ì„¤ëª…
                - scenario_text: ìƒì„¸í•œ ì‹œë‚˜ë¦¬ì˜¤ ìƒí™©
                - roles: {"user": "ì—­í• ", "ai": "ì—­í• "}
                - required_terminology: ì‚¬ìš©í•  ìš©ì–´ ë¦¬ìŠ¤íŠ¸
                - difficulty: beginner/intermediate/advanced
                - language: ëª©í‘œ ì–¸ì–´ ì½”ë“œ (en, ko ë“±)
                - category: ì‹œë‚˜ë¦¬ì˜¤ ì¹´í…Œê³ ë¦¬ (ì„ íƒì‚¬í•­)
            conversation_history: ëŒ€í™” ë‚´ ì´ì „ ë©”ì‹œì§€ë“¤
            last_ai_message: ì‘ë‹µí•  ê°€ì¥ ìµœê·¼ AI ë©”ì‹œì§€
            hint_count: ìƒì„±í•  íŒíŠ¸ ê°œìˆ˜ (ê¸°ë³¸ê°’: 3)

        Returns:
            ë‹¤ìŒì„ í¬í•¨í•˜ëŠ” ë”•ì…”ë„ˆë¦¬:
                - hints: ì œì•ˆëœ ì‘ë‹µ ë¦¬ìŠ¤íŠ¸
                - hint_explanations: ê° íŒíŠ¸ì— ëŒ€í•œ ê°„ë‹¨í•œ ì„¤ëª… (í•œêµ­ì–´)
                - terminology_suggestions: ì‚¬ìš© ê°€ëŠ¥í•œ ìš©ì–´ë“¤
                - difficulty_appropriate: íŒíŠ¸ê°€ ë‚œì´ë„ì— ì í•©í•œì§€ ì—¬ë¶€

        Raises:
            ValueError: scenario_contextì— í•„ìˆ˜ í•„ë“œê°€ ëˆ„ë½ëœ ê²½ìš°
        """
        # í•„ìˆ˜ í•„ë“œ ê²€ì¦
        required_fields = ["roles", "difficulty", "language"]
        for field in required_fields:
            if field not in scenario_context:
                raise ValueError(f"Missing required field: {field}")

        target_lang = self.LANG_MAP.get(
            scenario_context.get("language", "en"),
            "English"
        )
        difficulty = scenario_context.get("difficulty", "intermediate")
        guidelines = self.DIFFICULTY_GUIDELINES.get(difficulty, self.DIFFICULTY_GUIDELINES["intermediate"])

        # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        system_prompt = self._build_system_prompt(
            scenario_context,
            target_lang,
            guidelines
        )
        user_prompt = self._build_user_prompt(
            scenario_context,
            conversation_history,
            last_ai_message,
            hint_count
        )

        logger.info(f"ğŸ¯ Generating {hint_count} hints for scenario: {scenario_context.get('title', 'Unknown')}")

        try:
            response = await self.client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                response_format={"type": "json_object"},
                temperature=0.8,  # Higher for variety in suggestions
                max_tokens=800
            )

            import json
            result = json.loads(response.choices[0].message.content)

            # ì‘ë‹µ ê²€ì¦ ë° êµ¬ì¡°í™”
            hints = result.get("hints", [])
            if not hints:
                logger.warning("GPT-4o returned no hints, using fallback")
                hints = self._generate_fallback_hints(
                    scenario_context,
                    last_ai_message
                )

            logger.info(f"âœ… Generated {len(hints)} hints successfully")

            return {
                "hints": hints,
                "hint_explanations": result.get("hint_explanations", []),
                "terminology_suggestions": result.get("terminology_suggestions", []),
                "difficulty_appropriate": True
            }

        except Exception as e:
            logger.error(f"Error generating hints: {str(e)}")
            # ì˜¤ë¥˜ ì‹œ ëŒ€ì²´ íŒíŠ¸ ë°˜í™˜
            return {
                "hints": self._generate_fallback_hints(scenario_context, last_ai_message),
                "hint_explanations": ["ê¸°ë³¸ ì‘ë‹µ ì œì•ˆì…ë‹ˆë‹¤."],
                "terminology_suggestions": scenario_context.get("required_terminology", [])[:2],
                "difficulty_appropriate": False
            }

    def _build_system_prompt(
        self,
        scenario_context: Dict[str, Any],
        target_lang: str,
        guidelines: Dict[str, str]
    ) -> str:
        """íŒíŠ¸ ìƒì„±ì„ ìœ„í•œ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ë¥¼ êµ¬ì„±í•©ë‹ˆë‹¤."""

        user_role = scenario_context.get("roles", {}).get("user", "User")
        ai_role = scenario_context.get("roles", {}).get("ai", "AI Partner")
        category = scenario_context.get("category", "Business")

        # ë¹„ì¦ˆë‹ˆìŠ¤ ì‹œë‚˜ë¦¬ì˜¤ì¸ì§€ ì¼ìƒ ì‹œë‚˜ë¦¬ì˜¤ì¸ì§€ íŒë³„
        is_business = category not in ["Restaurant", "Hotel", "Shopping", "Hospital",
                                        "Bank", "Post Office", "Cafe", "Transportation",
                                        "Fitness", "Beauty", "Real Estate", "Car Rental",
                                        "Daily Life"]

        scenario_type = "ë¹„ì¦ˆë‹ˆìŠ¤" if is_business else "ì¼ìƒ"

        return f"""ë‹¹ì‹ ì€ {target_lang} íšŒí™” ì—°ìŠµì„ ë•ëŠ” ì–¸ì–´ íŠœí„°ì…ë‹ˆë‹¤.
ì‚¬ìš©ìê°€ ëŒ€í™”ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ ì´ì–´ê°ˆ ìˆ˜ ìˆë„ë¡ ì‘ë‹µ íŒíŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

## ì‹œë‚˜ë¦¬ì˜¤ ì •ë³´
- ì œëª©: {scenario_context.get('title', 'N/A')}
- ì„¤ëª…: {scenario_context.get('description', 'N/A')}
- ìƒí™©: {scenario_context.get('scenario_text', 'N/A')}
- ìœ í˜•: {scenario_type} ì‹œë‚˜ë¦¬ì˜¤
- ì¹´í…Œê³ ë¦¬: {category}

## ì—­í• 
- ì‚¬ìš©ì ì—­í• : {user_role}
- ëŒ€í™” ìƒëŒ€ ì—­í• : {ai_role}

## ë‚œì´ë„: {scenario_context.get('difficulty', 'intermediate').upper()}
- ë¬¸ì¥ ê¸¸ì´: {guidelines['sentence_length']}
- ë¬¸ì¥ êµ¬ì¡°: {guidelines['complexity']}
- ì–´íœ˜ ìˆ˜ì¤€: {guidelines['vocabulary']}
- ë¬¸ë²• ë²”ìœ„: {guidelines['grammar']}
- ìŠ¤íƒ€ì¼: {guidelines['style']}

## í•„ìˆ˜ ì „ë¬¸ìš©ì–´/í‘œí˜„
{', '.join(scenario_context.get('required_terminology', [])) or 'ì—†ìŒ'}

## íŒíŠ¸ ìƒì„± ê·œì¹™
1. ëª¨ë“  íŒíŠ¸ëŠ” **ë°˜ë“œì‹œ {target_lang}**ë¡œ ì‘ì„±
2. ì‚¬ìš©ì ì—­í• ({user_role})ì˜ ê´€ì ì—ì„œ ì‘ë‹µ ì‘ì„±
3. ëŒ€í™” ë§¥ë½ê³¼ ì‹œë‚˜ë¦¬ì˜¤ ìƒí™©ì— ìì—°ìŠ¤ëŸ½ê²Œ ë§ì•„ì•¼ í•¨
4. ë‚œì´ë„ì— ë§ëŠ” ë¬¸ì¥ ë³µì¡ë„ ìœ ì§€
5. ê°€ëŠ¥í•˜ë©´ í•„ìˆ˜ ì „ë¬¸ìš©ì–´ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ í¬í•¨
6. ëŒ€í™”ê°€ ì•ìœ¼ë¡œ ì§„í–‰ë  ìˆ˜ ìˆë„ë¡ ì§ˆë¬¸ì´ë‚˜ ì˜ê²¬ ì œì‹œ
7. ê° íŒíŠ¸ëŠ” ì„œë¡œ ë‹¤ë¥¸ ë°©í–¥ì˜ ì‘ë‹µ ì œì•ˆ (ë™ì˜/ì§ˆë¬¸/ì œì•ˆ/ëª…í™•í™” ìš”ì²­ ë“±)
8. íŒíŠ¸ ì„¤ëª…ì€ ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ ì‘ì„±"""

    def _build_user_prompt(
        self,
        scenario_context: Dict[str, Any],
        conversation_history: List[Dict[str, str]],
        last_ai_message: str,
        hint_count: int
    ) -> str:
        """Build the user prompt with conversation context."""

        # Format conversation history (last 6 messages for context)
        history_text = ""
        recent_history = conversation_history[-6:] if len(conversation_history) > 6 else conversation_history

        for msg in recent_history:
            speaker = "AI" if msg.get("speaker") == "ai" else "User"
            history_text += f"{speaker}: {msg.get('message', '')}\n"

        required_terms = scenario_context.get("required_terminology", [])
        unused_terms = self._find_unused_terms(required_terms, conversation_history)

        return f"""## ëŒ€í™” íˆìŠ¤í† ë¦¬
{history_text if history_text else "(ëŒ€í™” ì‹œì‘)"}

## ë§ˆì§€ë§‰ AI ë©”ì‹œì§€ (ì´ê²ƒì— ëŒ€í•œ ì‘ë‹µ íŒíŠ¸ ìƒì„±)
AI: {last_ai_message}

## ì•„ì§ ì‚¬ìš©í•˜ì§€ ì•Šì€ í•„ìˆ˜ ìš©ì–´
{', '.join(unused_terms) if unused_terms else '(ëª¨ë“  ìš©ì–´ ì‚¬ìš©ë¨)'}

---

ìœ„ ëŒ€í™” ë§¥ë½ì„ ë°”íƒ•ìœ¼ë¡œ, ì‚¬ìš©ìê°€ ìì—°ìŠ¤ëŸ½ê²Œ ì‘ë‹µí•  ìˆ˜ ìˆëŠ” {hint_count}ê°œì˜ íŒíŠ¸ë¥¼ ìƒì„±í•˜ì„¸ìš”.

ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”:
{{
  "hints": [
    "ì‘ë‹µ íŒíŠ¸ 1 (ëª©í‘œ ì–¸ì–´ë¡œ)",
    "ì‘ë‹µ íŒíŠ¸ 2 (ëª©í‘œ ì–¸ì–´ë¡œ)",
    "ì‘ë‹µ íŒíŠ¸ 3 (ëª©í‘œ ì–¸ì–´ë¡œ)"
  ],
  "hint_explanations": [
    "ì´ í‘œí˜„ì˜ ì‚¬ìš© ìƒí™©/ë§¥ë½ ì„¤ëª… (í•œêµ­ì–´)",
    "ì´ í‘œí˜„ì˜ ì‚¬ìš© ìƒí™©/ë§¥ë½ ì„¤ëª… (í•œêµ­ì–´)",
    "ì´ í‘œí˜„ì˜ ì‚¬ìš© ìƒí™©/ë§¥ë½ ì„¤ëª… (í•œêµ­ì–´)"
  ],
  "terminology_suggestions": ["ì´ ëŒ€í™”ì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ìš©ì–´1", "ìš©ì–´2"]
}}

ì¤‘ìš”:
- hints ë°°ì—´ì˜ ê° í•­ëª©ì€ **ëª©í‘œ ì–¸ì–´**ë¡œ ì‘ì„±
- hint_explanationsëŠ” **ë°˜ë“œì‹œ í•œêµ­ì–´**ë¡œ ì‘ì„±í•˜ë˜, "ì²« ë²ˆì§¸ íŒíŠ¸ëŠ”", "ë‘ ë²ˆì§¸ íŒíŠ¸ëŠ”" ê°™ì€ ìˆœì„œ í‘œí˜„ ì—†ì´ ë°”ë¡œ ì„¤ëª…ë§Œ ì‘ì„±
- ê° íŒíŠ¸ëŠ” ì„œë¡œ ë‹¤ë¥¸ ëŒ€í™” ë°©í–¥ì„ ì œì•ˆ (ì˜ˆ: ë™ì˜, ì§ˆë¬¸, ì œì•ˆ, ì˜ê²¬ í‘œí˜„ ë“±)"""

    def _find_unused_terms(
        self,
        required_terms: List[str],
        conversation_history: List[Dict[str, str]]
    ) -> List[str]:
        """Find terms that haven't been used in user messages yet."""
        if not required_terms:
            return []

        # Combine all user messages
        user_messages = " ".join([
            msg.get("message", "").lower()
            for msg in conversation_history
            if msg.get("speaker") == "user"
        ])

        # Find unused terms
        unused = []
        for term in required_terms:
            if term.lower() not in user_messages:
                unused.append(term)

        return unused

    def _generate_fallback_hints(
        self,
        scenario_context: Dict[str, Any],
        last_ai_message: str
    ) -> List[str]:
        """Generate basic fallback hints when AI generation fails."""
        language = scenario_context.get("language", "en")
        difficulty = scenario_context.get("difficulty", "intermediate")

        # Language-specific fallbacks
        fallbacks = {
            "en": {
                "beginner": [
                    "Yes, I agree with you.",
                    "Could you explain more?",
                    "I have a question about that."
                ],
                "intermediate": [
                    "That's a great point. I think we should also consider...",
                    "Could you elaborate on that aspect?",
                    "I see what you mean. From my perspective..."
                ],
                "advanced": [
                    "I appreciate your insight on this matter. However, I'd like to propose an alternative approach...",
                    "That's a compelling argument. Could you elaborate on the potential implications?",
                    "While I understand your perspective, I believe we should also factor in..."
                ]
            },
            "ko": {
                "beginner": [
                    "ë„¤, ì•Œê² ìŠµë‹ˆë‹¤.",
                    "ì¡°ê¸ˆ ë” ì„¤ëª…í•´ ì£¼ì‹œê² ì–´ìš”?",
                    "ì§ˆë¬¸ì´ ìˆìŠµë‹ˆë‹¤."
                ],
                "intermediate": [
                    "ì¢‹ì€ ì˜ê²¬ì´ë„¤ìš”. ì €ë„ ìƒê°í•´ë³´ë©´...",
                    "ê·¸ ë¶€ë¶„ì— ëŒ€í•´ ì¢€ ë” ìì„¸íˆ ë§ì”€í•´ ì£¼ì‹œê² ì–´ìš”?",
                    "ë§ì”€í•˜ì‹  ë‚´ìš© ì´í•´í–ˆìŠµë‹ˆë‹¤. ì œ ìƒê°ì—ëŠ”..."
                ],
                "advanced": [
                    "íƒì›”í•œ í†µì°°ì´ì‹­ë‹ˆë‹¤. ë‹¤ë§Œ, ë‹¤ë¥¸ ê´€ì ì—ì„œ ì ‘ê·¼í•´ ë³´ë©´...",
                    "ì„¤ë“ë ¥ ìˆëŠ” ë…¼ì ì´ë„¤ìš”. ê·¸ì— ë”°ë¥¸ íŒŒê¸‰íš¨ê³¼ì— ëŒ€í•´ ì¢€ ë” ì„¤ëª…í•´ ì£¼ì‹œê² ìŠµë‹ˆê¹Œ?",
                    "ë§ì”€í•˜ì‹  ê´€ì ì€ ì´í•´í•˜ì§€ë§Œ, ì¶”ê°€ì ìœ¼ë¡œ ê³ ë ¤í•´ì•¼ í•  ìš”ì†Œê°€..."
                ]
            }
        }

        lang_fallbacks = fallbacks.get(language, fallbacks["en"])
        return lang_fallbacks.get(difficulty, lang_fallbacks["intermediate"])

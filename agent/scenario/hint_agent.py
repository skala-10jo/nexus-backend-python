"""
Hint generation agent for conversation practice.

Generates contextually appropriate response suggestions based on:
- Scenario context (roles, topic, difficulty)
- Conversation history
- Required terminology
- User's role in the conversation
"""
import logging
from typing import List, Dict, Any, Optional

from agent.base_agent import BaseAgent

logger = logging.getLogger(__name__)


class HintAgent(BaseAgent):
    """
    AI agent for generating conversation hints/suggestions.

    Uses GPT-4o to create contextually appropriate response suggestions
    that help users continue the conversation naturally while using
    required terminology and maintaining appropriate difficulty level.

    Example:
        >>> agent = HintAgent()
        >>> hints = await agent.process(
        ...     scenario_context={
        ...         "title": "í”„ë¡œì íŠ¸ í‚¥ì˜¤í”„ ë¯¸íŒ…",
        ...         "description": "ìƒˆ í”„ë¡œì íŠ¸ ì‹œì‘ íšŒì˜",
        ...         "scenario_text": "PMê³¼ ê°œë°œìê°€ í”„ë¡œì íŠ¸ ë²”ìœ„ë¥¼ ë…¼ì˜",
        ...         "roles": {"user": "ê°œë°œì", "ai": "PM"},
        ...         "required_terminology": ["scope", "timeline", "deliverables"],
        ...         "difficulty": "intermediate",
        ...         "language": "en"
        ...     },
        ...     conversation_history=[
        ...         {"speaker": "ai", "message": "Hi! Ready to discuss the project?"},
        ...         {"speaker": "user", "message": "Yes, I have some questions."}
        ...     ],
        ...     last_ai_message="Sure, what would you like to know?"
        ... )
        >>> print(hints)
    """

    # Language mapping for prompts
    LANG_MAP = {
        "en": "English",
        "ko": "Korean (í•œêµ­ì–´)",
        "zh": "Chinese (ä¸­æ–‡)",
        "ja": "Japanese (æ—¥æœ¬èª)",
        "vi": "Vietnamese (Tiáº¿ng Viá»‡t)"
    }

    # Difficulty-based complexity guidelines
    DIFFICULTY_GUIDELINES = {
        "beginner": {
            "sentence_length": "5-10 words",
            "complexity": "simple sentence structures (subject + verb + object)",
            "vocabulary": "basic everyday vocabulary",
            "grammar": "present/past tense only, simple questions",
            "style": "direct and clear, avoid idioms"
        },
        "intermediate": {
            "sentence_length": "10-20 words",
            "complexity": "compound sentences, conditional clauses allowed",
            "vocabulary": "business terminology, common expressions",
            "grammar": "various tenses, polite forms, indirect questions",
            "style": "professional but conversational, some idioms okay"
        },
        "advanced": {
            "sentence_length": "15-30 words",
            "complexity": "complex sentences with multiple clauses",
            "vocabulary": "sophisticated business vocabulary, nuanced expressions",
            "grammar": "all tenses, subjunctive mood, complex modals",
            "style": "nuanced, diplomatic, idiomatic expressions encouraged"
        }
    }

    async def process(
        self,
        scenario_context: Dict[str, Any],
        conversation_history: List[Dict[str, str]],
        last_ai_message: str,
        hint_count: int = 3
    ) -> Dict[str, Any]:
        """
        Generate contextually appropriate response hints.

        Args:
            scenario_context: Scenario information containing:
                - title: Scenario title
                - description: Brief description
                - scenario_text: Detailed scenario situation
                - roles: {"user": "role", "ai": "role"}
                - required_terminology: List of terms to use
                - difficulty: beginner/intermediate/advanced
                - language: Target language code (en, ko, etc.)
                - category: Scenario category (optional)
            conversation_history: Previous messages in the conversation
            last_ai_message: The most recent AI message to respond to
            hint_count: Number of hints to generate (default: 3)

        Returns:
            Dictionary containing:
                - hints: List of suggested responses
                - hint_explanations: Brief explanation for each hint (in Korean)
                - terminology_suggestions: Terms that could be used
                - difficulty_appropriate: Whether hints match difficulty level

        Raises:
            ValueError: If scenario_context is missing required fields
        """
        # Validate required fields
        required_fields = ["roles", "difficulty", "language"]
        for field in required_fields:
            if field not in scenario_context:
                raise ValueError(f"Missing required field: {field}")

        target_lang = self.LANG_MAP.get(
            scenario_context.get("language", "en"),
            "English"
        )
        difficulty = scenario_context.get("difficulty", "intermediate")
        guidelines = self.DIFFICULTY_GUIDELINES.get(difficulty, self.DIFFICULTY_GUIDELINES["intermediate"])

        # Build the prompt
        system_prompt = self._build_system_prompt(
            scenario_context,
            target_lang,
            guidelines
        )
        user_prompt = self._build_user_prompt(
            scenario_context,
            conversation_history,
            last_ai_message,
            hint_count
        )

        logger.info(f"ğŸ¯ Generating {hint_count} hints for scenario: {scenario_context.get('title', 'Unknown')}")

        try:
            response = await self.client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                response_format={"type": "json_object"},
                temperature=0.8,  # Higher for variety in suggestions
                max_tokens=800
            )

            import json
            result = json.loads(response.choices[0].message.content)

            # Validate and structure the response
            hints = result.get("hints", [])
            if not hints:
                logger.warning("GPT-4o returned no hints, using fallback")
                hints = self._generate_fallback_hints(
                    scenario_context,
                    last_ai_message
                )

            logger.info(f"âœ… Generated {len(hints)} hints successfully")

            return {
                "hints": hints,
                "hint_explanations": result.get("hint_explanations", []),
                "terminology_suggestions": result.get("terminology_suggestions", []),
                "difficulty_appropriate": True
            }

        except Exception as e:
            logger.error(f"Error generating hints: {str(e)}")
            # Return fallback hints on error
            return {
                "hints": self._generate_fallback_hints(scenario_context, last_ai_message),
                "hint_explanations": ["ê¸°ë³¸ ì‘ë‹µ ì œì•ˆì…ë‹ˆë‹¤."],
                "terminology_suggestions": scenario_context.get("required_terminology", [])[:2],
                "difficulty_appropriate": False
            }

    def _build_system_prompt(
        self,
        scenario_context: Dict[str, Any],
        target_lang: str,
        guidelines: Dict[str, str]
    ) -> str:
        """Build the system prompt for hint generation."""

        user_role = scenario_context.get("roles", {}).get("user", "User")
        ai_role = scenario_context.get("roles", {}).get("ai", "AI Partner")
        category = scenario_context.get("category", "Business")

        # Determine if this is a business or everyday scenario
        is_business = category not in ["Restaurant", "Hotel", "Shopping", "Hospital",
                                        "Bank", "Post Office", "Cafe", "Transportation",
                                        "Fitness", "Beauty", "Real Estate", "Car Rental",
                                        "Daily Life"]

        scenario_type = "ë¹„ì¦ˆë‹ˆìŠ¤" if is_business else "ì¼ìƒ"

        return f"""ë‹¹ì‹ ì€ {target_lang} íšŒí™” ì—°ìŠµì„ ë•ëŠ” ì–¸ì–´ íŠœí„°ì…ë‹ˆë‹¤.
ì‚¬ìš©ìê°€ ëŒ€í™”ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ ì´ì–´ê°ˆ ìˆ˜ ìˆë„ë¡ ì‘ë‹µ íŒíŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

## ì‹œë‚˜ë¦¬ì˜¤ ì •ë³´
- ì œëª©: {scenario_context.get('title', 'N/A')}
- ì„¤ëª…: {scenario_context.get('description', 'N/A')}
- ìƒí™©: {scenario_context.get('scenario_text', 'N/A')}
- ìœ í˜•: {scenario_type} ì‹œë‚˜ë¦¬ì˜¤
- ì¹´í…Œê³ ë¦¬: {category}

## ì—­í• 
- ì‚¬ìš©ì ì—­í• : {user_role}
- ëŒ€í™” ìƒëŒ€ ì—­í• : {ai_role}

## ë‚œì´ë„: {scenario_context.get('difficulty', 'intermediate').upper()}
- ë¬¸ì¥ ê¸¸ì´: {guidelines['sentence_length']}
- ë¬¸ì¥ êµ¬ì¡°: {guidelines['complexity']}
- ì–´íœ˜ ìˆ˜ì¤€: {guidelines['vocabulary']}
- ë¬¸ë²• ë²”ìœ„: {guidelines['grammar']}
- ìŠ¤íƒ€ì¼: {guidelines['style']}

## í•„ìˆ˜ ì „ë¬¸ìš©ì–´/í‘œí˜„
{', '.join(scenario_context.get('required_terminology', [])) or 'ì—†ìŒ'}

## íŒíŠ¸ ìƒì„± ê·œì¹™
1. ëª¨ë“  íŒíŠ¸ëŠ” **ë°˜ë“œì‹œ {target_lang}**ë¡œ ì‘ì„±
2. ì‚¬ìš©ì ì—­í• ({user_role})ì˜ ê´€ì ì—ì„œ ì‘ë‹µ ì‘ì„±
3. ëŒ€í™” ë§¥ë½ê³¼ ì‹œë‚˜ë¦¬ì˜¤ ìƒí™©ì— ìì—°ìŠ¤ëŸ½ê²Œ ë§ì•„ì•¼ í•¨
4. ë‚œì´ë„ì— ë§ëŠ” ë¬¸ì¥ ë³µì¡ë„ ìœ ì§€
5. ê°€ëŠ¥í•˜ë©´ í•„ìˆ˜ ì „ë¬¸ìš©ì–´ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ í¬í•¨
6. ëŒ€í™”ê°€ ì•ìœ¼ë¡œ ì§„í–‰ë  ìˆ˜ ìˆë„ë¡ ì§ˆë¬¸ì´ë‚˜ ì˜ê²¬ ì œì‹œ
7. ê° íŒíŠ¸ëŠ” ì„œë¡œ ë‹¤ë¥¸ ë°©í–¥ì˜ ì‘ë‹µ ì œì•ˆ (ë™ì˜/ì§ˆë¬¸/ì œì•ˆ/ëª…í™•í™” ìš”ì²­ ë“±)
8. íŒíŠ¸ ì„¤ëª…ì€ ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ ì‘ì„±"""

    def _build_user_prompt(
        self,
        scenario_context: Dict[str, Any],
        conversation_history: List[Dict[str, str]],
        last_ai_message: str,
        hint_count: int
    ) -> str:
        """Build the user prompt with conversation context."""

        # Format conversation history (last 6 messages for context)
        history_text = ""
        recent_history = conversation_history[-6:] if len(conversation_history) > 6 else conversation_history

        for msg in recent_history:
            speaker = "AI" if msg.get("speaker") == "ai" else "User"
            history_text += f"{speaker}: {msg.get('message', '')}\n"

        required_terms = scenario_context.get("required_terminology", [])
        unused_terms = self._find_unused_terms(required_terms, conversation_history)

        return f"""## ëŒ€í™” íˆìŠ¤í† ë¦¬
{history_text if history_text else "(ëŒ€í™” ì‹œì‘)"}

## ë§ˆì§€ë§‰ AI ë©”ì‹œì§€ (ì´ê²ƒì— ëŒ€í•œ ì‘ë‹µ íŒíŠ¸ ìƒì„±)
AI: {last_ai_message}

## ì•„ì§ ì‚¬ìš©í•˜ì§€ ì•Šì€ í•„ìˆ˜ ìš©ì–´
{', '.join(unused_terms) if unused_terms else '(ëª¨ë“  ìš©ì–´ ì‚¬ìš©ë¨)'}

---

ìœ„ ëŒ€í™” ë§¥ë½ì„ ë°”íƒ•ìœ¼ë¡œ, ì‚¬ìš©ìê°€ ìì—°ìŠ¤ëŸ½ê²Œ ì‘ë‹µí•  ìˆ˜ ìˆëŠ” {hint_count}ê°œì˜ íŒíŠ¸ë¥¼ ìƒì„±í•˜ì„¸ìš”.

ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”:
{{
  "hints": [
    "ì‘ë‹µ íŒíŠ¸ 1 (ëª©í‘œ ì–¸ì–´ë¡œ)",
    "ì‘ë‹µ íŒíŠ¸ 2 (ëª©í‘œ ì–¸ì–´ë¡œ)",
    "ì‘ë‹µ íŒíŠ¸ 3 (ëª©í‘œ ì–¸ì–´ë¡œ)"
  ],
  "hint_explanations": [
    "ì´ í‘œí˜„ì˜ ì‚¬ìš© ìƒí™©/ë§¥ë½ ì„¤ëª… (í•œêµ­ì–´)",
    "ì´ í‘œí˜„ì˜ ì‚¬ìš© ìƒí™©/ë§¥ë½ ì„¤ëª… (í•œêµ­ì–´)",
    "ì´ í‘œí˜„ì˜ ì‚¬ìš© ìƒí™©/ë§¥ë½ ì„¤ëª… (í•œêµ­ì–´)"
  ],
  "terminology_suggestions": ["ì´ ëŒ€í™”ì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ìš©ì–´1", "ìš©ì–´2"]
}}

ì¤‘ìš”:
- hints ë°°ì—´ì˜ ê° í•­ëª©ì€ **ëª©í‘œ ì–¸ì–´**ë¡œ ì‘ì„±
- hint_explanationsëŠ” **ë°˜ë“œì‹œ í•œêµ­ì–´**ë¡œ ì‘ì„±í•˜ë˜, "ì²« ë²ˆì§¸ íŒíŠ¸ëŠ”", "ë‘ ë²ˆì§¸ íŒíŠ¸ëŠ”" ê°™ì€ ìˆœì„œ í‘œí˜„ ì—†ì´ ë°”ë¡œ ì„¤ëª…ë§Œ ì‘ì„±
- ê° íŒíŠ¸ëŠ” ì„œë¡œ ë‹¤ë¥¸ ëŒ€í™” ë°©í–¥ì„ ì œì•ˆ (ì˜ˆ: ë™ì˜, ì§ˆë¬¸, ì œì•ˆ, ì˜ê²¬ í‘œí˜„ ë“±)"""

    def _find_unused_terms(
        self,
        required_terms: List[str],
        conversation_history: List[Dict[str, str]]
    ) -> List[str]:
        """Find terms that haven't been used in user messages yet."""
        if not required_terms:
            return []

        # Combine all user messages
        user_messages = " ".join([
            msg.get("message", "").lower()
            for msg in conversation_history
            if msg.get("speaker") == "user"
        ])

        # Find unused terms
        unused = []
        for term in required_terms:
            if term.lower() not in user_messages:
                unused.append(term)

        return unused

    def _generate_fallback_hints(
        self,
        scenario_context: Dict[str, Any],
        last_ai_message: str
    ) -> List[str]:
        """Generate basic fallback hints when AI generation fails."""
        language = scenario_context.get("language", "en")
        difficulty = scenario_context.get("difficulty", "intermediate")

        # Language-specific fallbacks
        fallbacks = {
            "en": {
                "beginner": [
                    "Yes, I agree with you.",
                    "Could you explain more?",
                    "I have a question about that."
                ],
                "intermediate": [
                    "That's a great point. I think we should also consider...",
                    "Could you elaborate on that aspect?",
                    "I see what you mean. From my perspective..."
                ],
                "advanced": [
                    "I appreciate your insight on this matter. However, I'd like to propose an alternative approach...",
                    "That's a compelling argument. Could you elaborate on the potential implications?",
                    "While I understand your perspective, I believe we should also factor in..."
                ]
            },
            "ko": {
                "beginner": [
                    "ë„¤, ì•Œê² ìŠµë‹ˆë‹¤.",
                    "ì¡°ê¸ˆ ë” ì„¤ëª…í•´ ì£¼ì‹œê² ì–´ìš”?",
                    "ì§ˆë¬¸ì´ ìˆìŠµë‹ˆë‹¤."
                ],
                "intermediate": [
                    "ì¢‹ì€ ì˜ê²¬ì´ë„¤ìš”. ì €ë„ ìƒê°í•´ë³´ë©´...",
                    "ê·¸ ë¶€ë¶„ì— ëŒ€í•´ ì¢€ ë” ìì„¸íˆ ë§ì”€í•´ ì£¼ì‹œê² ì–´ìš”?",
                    "ë§ì”€í•˜ì‹  ë‚´ìš© ì´í•´í–ˆìŠµë‹ˆë‹¤. ì œ ìƒê°ì—ëŠ”..."
                ],
                "advanced": [
                    "íƒì›”í•œ í†µì°°ì´ì‹­ë‹ˆë‹¤. ë‹¤ë§Œ, ë‹¤ë¥¸ ê´€ì ì—ì„œ ì ‘ê·¼í•´ ë³´ë©´...",
                    "ì„¤ë“ë ¥ ìˆëŠ” ë…¼ì ì´ë„¤ìš”. ê·¸ì— ë”°ë¥¸ íŒŒê¸‰íš¨ê³¼ì— ëŒ€í•´ ì¢€ ë” ì„¤ëª…í•´ ì£¼ì‹œê² ìŠµë‹ˆê¹Œ?",
                    "ë§ì”€í•˜ì‹  ê´€ì ì€ ì´í•´í•˜ì§€ë§Œ, ì¶”ê°€ì ìœ¼ë¡œ ê³ ë ¤í•´ì•¼ í•  ìš”ì†Œê°€..."
                ]
            }
        }

        lang_fallbacks = fallbacks.get(language, fallbacks["en"])
        return lang_fallbacks.get(difficulty, lang_fallbacks["intermediate"])
